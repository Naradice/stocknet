{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352d3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a63e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "OS_DIR_BASE = 'L:\\data/bc/NextBoaderPossibility/'\n",
    "LINUX_MNT = '/mnt/landisk/data/bc/NextBoaderPossibility/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0df24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_BASE = LINUX_MNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d475e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'High':np.load('../bc_boader_5_mean_2days_High_normalized.npy'),\n",
    "        'Low':np.load('../bc_boader_5_mean_2days_Low_normalized.npy'),\n",
    "        'Open':np.load('../bc_boader_5_mean_2days_Open_normalized.npy'),\n",
    "        'Close':np.load('../bc_boader_5_mean_2days_Close_normalized.npy')\n",
    "        #'BoaderValue': np.load('../bc_boader_5_mean_2days_BoaderValue_normalized.npy')\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b20f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# normalize rate\n",
    "# try 1: max value of the range\n",
    "toIndex = len(data['High'])-1\n",
    "dataLength = len(data['High'][0])\n",
    "progress = -1\n",
    "inputData = []\n",
    "\n",
    "for index in range(0,toIndex):\n",
    "    currentProgress = int((index/toIndex)*100)\n",
    "    if int(currentProgress/10) != int(progress/10):\n",
    "        progress = currentProgress\n",
    "        print(progress)\n",
    "        npInputData = np.array(inputData, dtype=np.float32)\n",
    "        np.save(f'bc_MAboaderPossibility_5_2days_input_anormalized_{progress}', npInputData)\n",
    "        del npInputData\n",
    "        inputData = []\n",
    "    inputData.append([data['High'][index], data['Low'][index], data['Open'][index], data['Close'][index]])\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c5276d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1ee04ab9b6df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnpInputData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'bc_MAboaderPossibility_5_2days_input_anormalized_100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpInputData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputData' is not defined"
     ]
    }
   ],
   "source": [
    "npInputData = np.array(inputData, dtype=np.float32)\n",
    "np.save(f'bc_MAboaderPossibility_5_2days_input_anormalized_100', npInputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8711f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'BoaderValue': np.load('../bc_boader_5_mean_2days_BoaderValue_normalized.npy')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425a9a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# normalize rate\n",
    "# try 1: max value of the range\n",
    "toIndex = len(data['BoaderValue'])-1\n",
    "dataLength = len(data['BoaderValue'][0])\n",
    "progress = -1\n",
    "ansData  = []\n",
    "\n",
    "for index in range(0,toIndex):\n",
    "    currentProgress = int((index/toIndex)*100)\n",
    "    if int(currentProgress/10) != int(progress/10):\n",
    "        progress = currentProgress\n",
    "        print(progress)\n",
    "        npAnsData = np.array(ansData, dtype=np.float32)\n",
    "        np.save(f'bc_MAboaderPossibility_5_2days_ans_anormalized_{progress}', npAnsData)\n",
    "        del npAnsData\n",
    "        ansData = []\n",
    "    ansData.append(data['BoaderValue'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be2291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "npAnsData = np.array(ansData, dtype=np.float32)\n",
    "np.save(f'bc_MAboaderPossibility_5_2days_ans_anormalized_100', npAnsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f7fd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "npInputData = np.load(f'{DIR_BASE}input/bc_MAboaderPossibility_5_2days_input_anormalized_10.npy')\n",
    "\n",
    "#for num in range(20,110, 10):\n",
    "#    npInputData2 = np.load(f'bc_MAboaderPossibility_5_2days_input_anormalized_{num}.npy')\n",
    "#    npInputData = np.append(npInputData,npInputData2,axis=0)\n",
    "#\n",
    "#del npInputData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ad11198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363167, 4, 577)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npInputData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20433faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "842c985a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((1.15 - 0.85)*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd44b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9755c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialIndex = 50\n",
    "class BCBoaderDataset:\n",
    "    def __init__(self, isTraining = True, seed=0):\n",
    "        random.seed(seed)\n",
    "        inputData =  np.load(f'{DIR_BASE}input/bc_MAboaderPossibility_5_2days_input_anormalized_{initialIndex}.npy')\n",
    "        for num in range(initialIndex+10,110, 10):\n",
    "            npInputData2 = np.load(f'{DIR_BASE}input/bc_MAboaderPossibility_5_2days_input_anormalized_{num}.npy')\n",
    "            inputData = np.append(inputData,npInputData2,axis=0)\n",
    "        npInputData2 = None\n",
    "        del npInputData2\n",
    "        all_data = torch.from_numpy(inputData).to(dtype)\n",
    "        inputData = None\n",
    "        del inputData\n",
    "        length = len(all_data)\n",
    "        indexes = random.sample(range(0, length-1), k=length-1)\n",
    "        if isTraining:\n",
    "            fromIndex = 0\n",
    "            toIndex = int(length*0.7)\n",
    "        else:\n",
    "            fromIndex = int(length*0.7)+1\n",
    "            toIndex = length+1\n",
    "        indexes = indexes[fromIndex:toIndex]\n",
    "        self.data = all_data[indexes]\n",
    "        ansData = np.load(f'{DIR_BASE}input/bc_MAboaderPossibility_5_2days_ans_anormalized_{initialIndex}.npy')\n",
    "        for num in range(initialIndex+10,110, 10):\n",
    "            npAnsData2 = np.load(f'{DIR_BASE}input/bc_MAboaderPossibility_5_2days_ans_anormalized_{num}.npy')\n",
    "            ansData = np.append(ansData,npAnsData2,axis=0)\n",
    "        npAnsData2 = None\n",
    "        del npAnsData2\n",
    "        index = 0\n",
    "        length = round((1.15 - 0.85)*10000)\n",
    "        self.ans = np.zeros((len(ansData),length), dtype='float32')\n",
    "        for value in ansData:\n",
    "            i = round((value[-1] -0.85)*10000)\n",
    "            if i >= 3000:\n",
    "                i = 2999\n",
    "            if i < 0:\n",
    "                i = 0\n",
    "            self.ans[index][i] = 1\n",
    "            index = index+1\n",
    "        ansData = None\n",
    "        del ansData\n",
    "        self.ans = torch.from_numpy(self.ans).to(dtype)[indexes]\n",
    "        self.dataRange = datetime.timedelta(days=2)\n",
    "        self.dims = 5\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, ndx):\n",
    "            \n",
    "        return self.data[ndx].to(device), self.ans[ndx].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "332252ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCBoaderDataset:\n",
    "    def __init__(self, isTraining = True, seed=0, mode=\"default\"):\n",
    "        random.seed(seed)\n",
    "        self.all_data = pd.read_csv(f'{DIR_BASE}/input/bitcoin_boader_5_mean_filled15.csv',  header=0, index_col=0, parse_dates=True)\n",
    "        self.all_data = self.all_data.sort_index()\n",
    "        length = len(self.all_data)\n",
    "        \n",
    "        ##select random indices.\n",
    "        self.indices = random.sample(range(0, length-1), k=length-1)\n",
    "        if isTraining:\n",
    "            self.fromIndex = 0\n",
    "            self.toIndex = int(length*0.7)\n",
    "        else:\n",
    "            self.fromIndex = int(length*0.7)+1\n",
    "            self.toIndex = length+1\n",
    "            \n",
    "        self.dataRange = datetime.timedelta(days=2)\n",
    "        self.dims = 5\n",
    "        self.mode = mode\n",
    "        INTERVAL_DAYS = 2\n",
    "        MINUTES_SPAN = 5\n",
    "\n",
    "        totalMinutes = INTERVAL_DAYS * 24 * 60\n",
    "        self.span  = int(totalMinutes/MINUTES_SPAN)+1\n",
    "        \n",
    "        if self.mode == \"nrate\":\n",
    "            self.outputFunc = self.__getNormalizedAnsRates__\n",
    "        elif self.mode == \"default\":\n",
    "            self.outputFunc = self.__getAnsRates__\n",
    "        elif self.mode == \"array\":\n",
    "            self.outputFunc = self.__getAnsArray__\n",
    "        \n",
    "    def __rateToArray__(self, value):\n",
    "        output = [0 for i in range(0,3000)]\n",
    "        i = round((value -0.85)*10000)\n",
    "        if i >= 3000:\n",
    "            i = 2999\n",
    "        elif i < 0:\n",
    "            i = 0\n",
    "        output[i] = 1\n",
    "        return output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.toIndex - self.fromIndex\n",
    "    \n",
    "    def __getAnsRates__(self,ndx):\n",
    "        ans = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                currentValue = self.all_data['Close'].iloc[index]\n",
    "                ans.append(self.all_data['BoaderValue'].iloc[index]/currentValue)\n",
    "        else:\n",
    "            index = ndx\n",
    "            currentValue = self.all_data['Close'].iloc[index]\n",
    "            ans = [self.all_data['BoaderValue'].iloc[index]/currentValue]\n",
    "        return ans\n",
    "    \n",
    "    def __getNormalizedAnsRates__(self,ndx):\n",
    "        ans = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                maxValue = self.all_data['High'].iloc[index:index+self.span].values.max()\n",
    "                ans.append(self.all_data['BoaderValue'].iloc[index]/maxValue)\n",
    "        else:\n",
    "            index = ndx\n",
    "            maxValue = self.all_data['High'].iloc[index:index+self.span].values.max()\n",
    "            ans = [self.all_data['BoaderValue'].iloc[index]/maxValue]\n",
    "        return ans\n",
    "    \n",
    "    def __getAnsArray__(self, ndx):\n",
    "        ans = []\n",
    "        for value in self.__getNormalizedAnsRates__(ndx):\n",
    "            ans.append(\n",
    "                self.__rateToArray__(value)\n",
    "            )\n",
    "        return ans\n",
    "    \n",
    "    def __getInputs__(self, ndx):\n",
    "        inputs = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                maxValue = self.all_data['High'].iloc[index:index+self.span].values.max()\n",
    "                inputs.append([\n",
    "                    self.all_data['High'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['Low'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['Open'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['Close'].iloc[index:index+self.span].values/maxValue]\n",
    "                )\n",
    "        else:\n",
    "            index = ndx\n",
    "            maxValue = self.all_data['High'].iloc[index:index+self.span].values.max()\n",
    "            inputs = [\n",
    "                    self.all_data['High'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['Low'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['Open'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['Close'].iloc[index:index+self.span].values/maxValue\n",
    "            ]\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "    def __getitem__(self, ndx):\n",
    "        inputs = numpy.array(self.__getInputs__(ndx))\n",
    "        outputs = numpy.array(self.outputFunc(ndx))\n",
    "        return torch.tensor(inputs, device=device).to(dtype=dtype), torch.tensor(outputs, device=device).to(dtype=dtype)\n",
    "    \n",
    "    def changeMode(self, mode):\n",
    "        self.mode = mode\n",
    "        if self.mode == \"nrate\":\n",
    "            self.outputFunc = self.__getNormalizedAnsRates__\n",
    "        elif self.mode == \"default\":\n",
    "            self.outputFunc = self.__getAnsRates__\n",
    "        elif self.mode == \"array\":\n",
    "            self.outputFunc = self.__getAnsArray__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d8b507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daace9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BCBoaderDataset(True, 1017, \"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eec15476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c796a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size = batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015690d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e124d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "class FXBoaderDataset:\n",
    "    def __init__(self, data, isTraining = True, seed=0, mode=\"default\"):\n",
    "        random.seed(seed)\n",
    "        self.all_data = data\n",
    "        self.all_data = self.all_data.sort_index()\n",
    "        length = len(self.all_data)\n",
    "        \n",
    "        ##select random indices.\n",
    "        self.indices = random.sample(range(0, length-1), k=length-1)\n",
    "        if isTraining:\n",
    "            self.fromIndex = 0\n",
    "            self.toIndex = int(length*0.7)\n",
    "        else:\n",
    "            self.fromIndex = int(length*0.7)+1\n",
    "            self.toIndex = length+1\n",
    "            \n",
    "        self.dataRange = datetime.timedelta(days=2)\n",
    "        self.dims = 5\n",
    "        self.mode = mode\n",
    "        INTERVAL_DAYS = 2\n",
    "        MINUTES_SPAN = 5\n",
    "\n",
    "        totalMinutes = INTERVAL_DAYS * 24 * 60\n",
    "        self.span  = int(totalMinutes/MINUTES_SPAN)+1\n",
    "        \n",
    "        if self.mode == \"nrate\":\n",
    "            self.outputFunc = self.__getNormalizedAnsRates__\n",
    "        elif self.mode == \"default\":\n",
    "            self.outputFunc = self.__getAnsRates__\n",
    "        elif self.mode == \"array\":\n",
    "            self.outputFunc = self.__getAnsArray__\n",
    "        \n",
    "    def __rateToArray__(self, value):\n",
    "        output = [0 for i in range(0,3000)]\n",
    "        i = round((value -0.85)*10000)\n",
    "        if i >= 3000:\n",
    "            i = 2999\n",
    "        elif i < 0:\n",
    "            i = 0\n",
    "        output[i] = 1\n",
    "        return output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.toIndex - self.fromIndex\n",
    "    \n",
    "    def __getAnsRates__(self,ndx):\n",
    "        ans = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                currentValue = self.all_data['close'].iloc[index]\n",
    "                ans.append(self.all_data['BoaderValue'].iloc[index]/currentValue)\n",
    "        else:\n",
    "            index = ndx\n",
    "            currentValue = self.all_data['close'].iloc[index]\n",
    "            ans = [self.all_data['BoaderValue'].iloc[index]/currentValue]\n",
    "        return ans\n",
    "    \n",
    "    def __getNormalizedAnsRates__(self,ndx):\n",
    "        ans = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                maxValue = self.all_data['high'].iloc[index:index+self.span].values.max()\n",
    "                ans.append(self.all_data['BoaderValue'].iloc[index]/maxValue)\n",
    "        else:\n",
    "            index = ndx\n",
    "            maxValue = self.all_data['high'].iloc[index:index+self.span].values.max()\n",
    "            ans = [self.all_data['BoaderValue'].iloc[index]/maxValue]\n",
    "        return ans\n",
    "    \n",
    "    def __getAnsArray__(self, ndx):\n",
    "        ans = []\n",
    "        for value in self.__getNormalizedAnsRates__(ndx):\n",
    "            ans.append(\n",
    "                self.__rateToArray__(value)\n",
    "            )\n",
    "        return ans\n",
    "    \n",
    "    def __getInputs__(self, ndx):\n",
    "        inputs = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                maxValue = self.all_data['high'].iloc[index:index+self.span].values.max()\n",
    "                inputs.append([\n",
    "                    self.all_data['high'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['low'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['open'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['close'].iloc[index:index+self.span].values/maxValue]\n",
    "                )\n",
    "        else:\n",
    "            index = ndx\n",
    "            maxValue = self.all_data['high'].iloc[index:index+self.span].values.max()\n",
    "            inputs = [\n",
    "                    self.all_data['high'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['low'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['open'].iloc[index:index+self.span].values/maxValue,\n",
    "                    self.all_data['close'].iloc[index:index+self.span].values/maxValue\n",
    "            ]\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "    def __getitem__(self, ndx):\n",
    "        inputs = numpy.array(self.__getInputs__(ndx))\n",
    "        outputs = numpy.array(self.outputFunc(ndx))\n",
    "        return torch.tensor(inputs, device=device).to(dtype=dtype), torch.tensor(outputs, device=device).to(dtype=dtype)\n",
    "        #return inputs, outputs\n",
    "    \n",
    "    def changeMode(self, mode):\n",
    "        self.mode = mode\n",
    "        if self.mode == \"nrate\":\n",
    "            self.outputFunc = self.__getNormalizedAnsRates__\n",
    "        elif self.mode == \"default\":\n",
    "            self.outputFunc = self.__getAnsRates__\n",
    "        elif self.mode == \"array\":\n",
    "            self.outputFunc = self.__getAnsArray__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8842933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddBoaderValue(rates, frame, removeNan=True):\n",
    "    def updateNextBoaders(start, end, value):\n",
    "        for i in range(start, end+1):\n",
    "            nextBoaders.append(value)\n",
    "        \n",
    "    data = rates.copy()\n",
    "    ma = data.close.rolling(frame).mean()\n",
    "    if ma[frame-1] == numpy.NaN:\n",
    "        print(\"invalid\")\n",
    "        return None\n",
    "    data[\"EMA\"] = ma\n",
    "    initial = frame\n",
    "    startIndex = initial\n",
    "    nextBoaders = [numpy.NaN for i in range(0,initial)]\n",
    "    trend = 0\n",
    "    \n",
    "    for index in range(initial, len(data)):\n",
    "        diff = data.EMA[index-1] - data.EMA[index]\n",
    "        if diff >= 0:\n",
    "            if trend == -1:\n",
    "                updateNextBoaders(startIndex, index, data.EMA[index])\n",
    "                startIndex = index+1\n",
    "            trend = 1\n",
    "        else:\n",
    "            if trend == 1:\n",
    "                updateNextBoaders(startIndex, index, data.EMA[index])\n",
    "                startIndex = index+1\n",
    "            trend = -1\n",
    "\n",
    "    updateNextBoaders(startIndex, len(data)-1, numpy.NaN)\n",
    "    result = len(data) == len(nextBoaders)\n",
    "    print(f\"Result:{result}\")\n",
    "    if result:\n",
    "        data[\"BoaderValue\"] = nextBoaders\n",
    "        if removeNan:\n",
    "            return data[frame:startIndex]\n",
    "        else:\n",
    "            return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed5a008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:True\n"
     ]
    }
   ],
   "source": [
    "rates = AddBoaderValue(pd.read_csv(f'/mnt/landisk/data/fx/NextBoaderPossibility/fx_USDJPY_5_2020-08-03T23-05-00_to_2021-12-04T07-50-00.csv'), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53fdcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = AddBoaderValue(pd.read_csv(f'/mnt/landisk/data/fx/NextBoaderPossibility/fx_USDJPY_5_2020-08-03T23-05-00_to_2021-12-04T07-50-00.csv'), 10)\n",
    "train_ds = FXBoaderDataset(rates, True, 1017, \"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67e1e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,o = train_ds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee87f399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 577])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aaa13a",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a62abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b94deed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = inputData.shape[0]\n",
    "size =577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1538a383",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2eaca526b1e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24802075",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = round((1.15 - 0.85)*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3223de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(4,16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16,32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(32,16, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(16,8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(16*size, length)\n",
    "        self.fc1_2 = nn.Linear(16*size, 8*size)\n",
    "        self.fc2 = nn.Linear(8*size, length)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.relu(self.conv3(out))\n",
    "        #out = torch.tanh(self.conv4(out))\n",
    "        #out = out.view(-1, 16*size)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        #out = out.view(-1, 8*size)\n",
    "        #out = F.relu(self.fc2(out))\n",
    "        out = self.softmax(out)\n",
    "        #out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b857f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "477053ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData, outputData = train_ds[0:10]\n",
    "out = model(inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1095b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3000])\n",
      "torch.Size([10, 3000])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(outputData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762a8d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.0004, 0.0004, 0.0004],\n",
       "        [0.0004, 0.0004, 0.0004],\n",
       "        [0.0004, 0.0004, 0.0004],\n",
       "        [0.0004, 0.0004, 0.0004],\n",
       "        [0.0004, 0.0004, 0.0004],\n",
       "        [0.0004, 0.0004, 0.0004],\n",
       "        [0.0004, 0.0004, 0.0004],\n",
       "        [0.0004, 0.0004, 0.0004],\n",
       "        [0.0004, 0.0004, 0.0004],\n",
       "        [0.0004, 0.0004, 0.0004]], device='cuda:0', grad_fn=<TopkBackward0>),\n",
       "indices=tensor([[1226, 2500, 2237],\n",
       "        [1226, 2500, 2237],\n",
       "        [1226, 2500, 2237],\n",
       "        [1226, 2500, 2237],\n",
       "        [1226, 2500, 2237],\n",
       "        [1226, 2500, 2237],\n",
       "        [1226, 2500, 2237],\n",
       "        [1226, 2500, 2237],\n",
       "        [1226, 2500, 2237],\n",
       "        [1226, 2500, 2237]], device='cuda:0'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.topk(out,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05f00953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffd2a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "422b6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c2c8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "    \n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, mode=\"graph\"):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.ion()\n",
    "\n",
    "    fig.show()\n",
    "    fig.canvas.draw()\n",
    "    losses = []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_train  = 0.0\n",
    "        \n",
    "        for inputValues, ansValue in train_loader:\n",
    "            outputs = model(inputValues)\n",
    "            #print(f'output {outputs.shape}, ansValue {ansValue.shape}')\n",
    "            loss = loss_fn(outputs, ansValue)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        if mode == \"graph\":\n",
    "            losses.append(loss_train/len(train_loader))\n",
    "            ax.clear()\n",
    "            ax.plot(losses)\n",
    "            fig.canvas.draw()\n",
    "        else:\n",
    "            if epoch == 1 or epoch % 10 == 0:\n",
    "                print(f'{datetime.datetime.now()} Epoch {epoch}, Training loss {loss_train/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7c600",
   "metadata": {},
   "source": [
    "### BitCoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc2d1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BCBoaderDataset(True, 2056)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2aa794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size,  drop_last = True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ced4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "037e3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "589ced7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a2767495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-04 14:07:36.606388 Epoch 1, Training loss 0.0003331648174955459\n",
      "2021-12-04 15:42:40.466771 Epoch 10, Training loss 0.0003330560226754241\n",
      "2021-12-04 17:32:05.463300 Epoch 20, Training loss 0.0003330489131283257\n",
      "2021-12-04 19:27:00.093167 Epoch 30, Training loss 0.0003330483321692024\n",
      "2021-12-04 21:36:14.122407 Epoch 40, Training loss 0.00033304800627447493\n",
      "2021-12-05 01:08:38.539143 Epoch 50, Training loss 0.00033304774696503843\n",
      "2021-12-05 02:47:40.290454 Epoch 60, Training loss 0.00033304766998853443\n",
      "2021-12-05 04:27:16.736211 Epoch 70, Training loss 0.0003330475189135797\n",
      "2021-12-05 06:06:18.807785 Epoch 80, Training loss 0.0003330473889302925\n",
      "2021-12-05 07:45:23.799927 Epoch 90, Training loss 0.0003330473243199294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-910ead4f7c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-5177ad87b28f>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_loader)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mloss_train\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mansValue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m#print(f'output {outputs.shape}, ansValue {ansValue.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-cdbb32b414c3>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, ndx)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getInputs__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-cdbb32b414c3>\u001b[0m in \u001b[0;36m__getInputs__\u001b[0;34m(self, ndx)\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Low'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmaxValue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmaxValue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmaxValue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             ]\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_positional_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;31m# axis kwarg is retained for compat with NDFrame method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;31m#  _slice is *always* positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;31m# mpl compat if we look up e.g. ser[:, np.newaxis];\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0mblk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block_same_class\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmgr_locs\u001b[0;34m(self, new_mgr_locs)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmgr_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibinternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlockPlacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlockPlacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs =300, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "39a97c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'bc_boaderRatePossibility_5_2days_adam_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cde8bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'{DIR_BASE}/model/bc_boaderPossibility_5_2days_adam_v4', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11c8e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input, dummy_output = train_ds[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1ff1382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 577])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6db67b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, dummy_input, 'bc_boaderPossibility_5_2days_adam_v4.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c57c1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = BCBoaderDataset(False, 1017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1c59f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = DataLoader(val_ds, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b55f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = DataLoader(val_ds, batch_size = 10)\n",
    "def rateCal(index):\n",
    "    return index/10000  + 0.85\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"val\", val_loader)]:\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            count = 0\n",
    "            for values, anses in loader:\n",
    "                outputs = model(values)\n",
    "                for index in range(0, len(outputs)-1):\n",
    "                    count = count + 1\n",
    "                    result = torch.topk(outputs[index], 3)\n",
    "                    print(result)\n",
    "                    ans = torch.topk(anses[index], 1)\n",
    "                    candidate1 = rateCal(result[1][0])\n",
    "                    candidate2 = rateCal(result[1][1])\n",
    "                    candidate3 = rateCal(result[1][2])\n",
    "                    total = result[0][0] +  result[0][1] + result[0][2]\n",
    "                    mean = candidate1 * (result[0][0]/total) + candidate2*(result[0][1]/total) + candidate3*(result[0][2]/total)\n",
    "                    ansValue = rateCal(ans[1])\n",
    "                    correct = correct + mean/ansValue\n",
    "                        \n",
    "    \n",
    "    print('--------------------------------------------------')\n",
    "    print(f'{correct/count}')\n",
    "    print('--------------------------------------------------')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e070f361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.9569, 0.0260, 0.0046]),\n",
      "indices=tensor([1378, 1330, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1415, 0.0767, 0.0456]),\n",
      "indices=tensor([1550, 1394, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1109, 0.0659, 0.0556]),\n",
      "indices=tensor([1383, 1387, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1029, 0.0849, 0.0614]),\n",
      "indices=tensor([1110, 1321, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3731, 0.1136, 0.0519]),\n",
      "indices=tensor([1022, 1009, 1436]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9798, 0.0016, 0.0012]),\n",
      "indices=tensor([1319, 1375, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2616, 0.0396, 0.0370]),\n",
      "indices=tensor([1110, 1218, 1082]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9875, 0.0057, 0.0015]),\n",
      "indices=tensor([1266, 1359, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9920e-01, 5.5859e-05, 4.6387e-05]),\n",
      "indices=tensor([1110, 1022, 1120]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7895, 0.0174, 0.0153]),\n",
      "indices=tensor([1379, 1385, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0765, 0.0599, 0.0564]),\n",
      "indices=tensor([1292, 1456, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8858, 0.0097, 0.0092]),\n",
      "indices=tensor([1295, 1403, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4223, 0.0384, 0.0326]),\n",
      "indices=tensor([1031, 1382,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9803, 0.0021, 0.0012]),\n",
      "indices=tensor([1213, 1284, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4024, 0.0798, 0.0614]),\n",
      "indices=tensor([1375, 1408, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6586, 0.0813, 0.0222]),\n",
      "indices=tensor([1387, 1413, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9791e-01, 1.1336e-04, 9.6804e-05]),\n",
      "indices=tensor([1110, 1313, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9783e-01, 3.3246e-04, 1.8064e-04]),\n",
      "indices=tensor([1139, 1152, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9474, 0.0027, 0.0025]),\n",
      "indices=tensor([ 946, 1145, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0650, 0.0425, 0.0355]),\n",
      "indices=tensor([1178,  941, 1082]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0575, 0.0557, 0.0541]),\n",
      "indices=tensor([1674, 1154, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9452, 0.0060, 0.0032]),\n",
      "indices=tensor([1142, 1067, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9676, 0.0196, 0.0021]),\n",
      "indices=tensor([1410, 1386, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4278, 0.2414, 0.0171]),\n",
      "indices=tensor([1438, 1406, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0614, 0.0487, 0.0457]),\n",
      "indices=tensor([ 983, 1522, 1233]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8692e-01, 1.0075e-03, 8.6460e-04]),\n",
      "indices=tensor([1039, 1286, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0703, 0.0506, 0.0422]),\n",
      "indices=tensor([1492, 1145, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1022, 0.0571, 0.0443]),\n",
      "indices=tensor([1164, 1063, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9843e-01, 3.0567e-04, 1.0211e-04]),\n",
      "indices=tensor([1498, 1436, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9999e-01, 2.4706e-06, 4.3961e-07]),\n",
      "indices=tensor([1240, 1186, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9388e-01, 4.3313e-04, 2.6730e-04]),\n",
      "indices=tensor([1280, 1332, 1270]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9363, 0.0371, 0.0056]),\n",
      "indices=tensor([1331, 1359, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9877, 0.0025, 0.0013]),\n",
      "indices=tensor([1408, 1460,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9941, 0.0010, 0.0010]),\n",
      "indices=tensor([1350, 1405, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9132, 0.0052, 0.0050]),\n",
      "indices=tensor([1009, 1189, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0970, 0.0624, 0.0457]),\n",
      "indices=tensor([1448, 1126, 1278]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1491, 0.0685, 0.0354]),\n",
      "indices=tensor([1348, 1439, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9825, 0.0049, 0.0017]),\n",
      "indices=tensor([1315, 1341, 1156]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9507, 0.0050, 0.0039]),\n",
      "indices=tensor([1297, 1319, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0558, 0.0465, 0.0411]),\n",
      "indices=tensor([1265, 1158, 1325]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5831, 0.0451, 0.0300]),\n",
      "indices=tensor([1092, 1276, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8755e-01, 2.8451e-03, 5.4662e-04]),\n",
      "indices=tensor([1251, 1209, 1273]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8747e-01, 5.0600e-03, 7.4807e-04]),\n",
      "indices=tensor([1325, 1386, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9877e-01, 6.0912e-05, 5.2631e-05]),\n",
      "indices=tensor([1354, 1408, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9875e-01, 3.9598e-04, 1.2551e-04]),\n",
      "indices=tensor([1158, 1674, 1123]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6949, 0.0274, 0.0192]),\n",
      "indices=tensor([1421, 1438, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3930, 0.0551, 0.0471]),\n",
      "indices=tensor([1343, 1380, 1209]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0663, 0.0368, 0.0314]),\n",
      "indices=tensor([1310, 1492, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7781, 0.1103, 0.0103]),\n",
      "indices=tensor([1243, 1309, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0559, 0.0445, 0.0421]),\n",
      "indices=tensor([1413, 1344, 1500]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0557, 0.0555, 0.0454]),\n",
      "indices=tensor([1357, 1045, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0931, 0.0650, 0.0509]),\n",
      "indices=tensor([1223, 1409, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9347, 0.0168, 0.0032]),\n",
      "indices=tensor([1370, 1309, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9746, 0.0102, 0.0021]),\n",
      "indices=tensor([1413, 1436, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0463, 0.0422, 0.0373]),\n",
      "indices=tensor([1385, 1438, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1286, 0.0699, 0.0661]),\n",
      "indices=tensor([1403, 1383, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0875, 0.0415, 0.0374]),\n",
      "indices=tensor([1347, 1514, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9767, 0.0045, 0.0018]),\n",
      "indices=tensor([1283, 1273, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0967, 0.0741, 0.0403]),\n",
      "indices=tensor([1393, 1382, 1022]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0856, 0.0447, 0.0414]),\n",
      "indices=tensor([1403, 1112, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9119e-01, 5.9451e-04, 4.5391e-04]),\n",
      "indices=tensor([1082, 1038, 1371]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3080, 0.0797, 0.0514]),\n",
      "indices=tensor([1330,  927, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8864e-01, 7.1121e-04, 6.7484e-04]),\n",
      "indices=tensor([1426, 1344,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2757, 0.0294, 0.0290]),\n",
      "indices=tensor([1398, 1674, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9580, 0.0070, 0.0050]),\n",
      "indices=tensor([1096,  986,  956]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9029, 0.0251, 0.0060]),\n",
      "indices=tensor([1262, 1282, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1105, 0.0548, 0.0506]),\n",
      "indices=tensor([1403,  941, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0878, 0.0825, 0.0466]),\n",
      "indices=tensor([1308, 1370, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1929, 0.1314, 0.0680]),\n",
      "indices=tensor([1403, 1447, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1100, 0.0567, 0.0475]),\n",
      "indices=tensor([1409, 1421, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9885, 0.0020, 0.0015]),\n",
      "indices=tensor([1194, 1255, 1167]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1118, 0.0706, 0.0620]),\n",
      "indices=tensor([1194, 1347, 1179]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1428, 0.0436, 0.0406]),\n",
      "indices=tensor([1218, 1178, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4340, 0.0459, 0.0318]),\n",
      "indices=tensor([1387, 1357, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8201, 0.0120, 0.0107]),\n",
      "indices=tensor([1219, 1167, 1270]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0552, 0.0496, 0.0460]),\n",
      "indices=tensor([1403, 1283, 1096]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9960e-01, 3.4090e-05, 3.0530e-05]),\n",
      "indices=tensor([ 800, 1031, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0844, 0.0609, 0.0377]),\n",
      "indices=tensor([1448, 1348, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8129, 0.0833, 0.0188]),\n",
      "indices=tensor([1309, 1370, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5384, 0.0354, 0.0229]),\n",
      "indices=tensor([1092, 1276, 1390]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9295, 0.0040, 0.0033]),\n",
      "indices=tensor([1063, 1178, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0524, 0.0457, 0.0407]),\n",
      "indices=tensor([1096, 1339, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0504, 0.0436, 0.0389]),\n",
      "indices=tensor([1262, 1496, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5025, 0.4817, 0.0020]),\n",
      "indices=tensor([1292, 1255, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9578, 0.0028, 0.0028]),\n",
      "indices=tensor([1417, 1489, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0596, 0.0580, 0.0554]),\n",
      "indices=tensor([1382, 1460, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9429e-01, 2.0017e-03, 3.6581e-04]),\n",
      "indices=tensor([1301, 1257, 1156]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9145, 0.0094, 0.0071]),\n",
      "indices=tensor([1310, 1433, 1276]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8291, 0.0145, 0.0102]),\n",
      "indices=tensor([1330, 1397,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3415, 0.0436, 0.0429]),\n",
      "indices=tensor([1145, 1155,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9910e-01, 6.0783e-05, 5.6220e-05]),\n",
      "indices=tensor([1045, 1285, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7750, 0.0199, 0.0178]),\n",
      "indices=tensor([1454, 1403, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9061, 0.0288, 0.0070]),\n",
      "indices=tensor([1406, 1350, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9368, 0.0036, 0.0029]),\n",
      "indices=tensor([1123, 1117, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8939, 0.0077, 0.0071]),\n",
      "indices=tensor([ 970, 1145, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0659, 0.0619, 0.0405]),\n",
      "indices=tensor([1386, 1403, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8908, 0.0380, 0.0067]),\n",
      "indices=tensor([1375, 1338, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9412, 0.0233, 0.0063]),\n",
      "indices=tensor([1193, 1209, 1346]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0474, 0.0402, 0.0366]),\n",
      "indices=tensor([1296, 1189, 1039]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.9716, 0.0025, 0.0020]),\n",
      "indices=tensor([1421, 1496, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1972, 0.0781, 0.0370]),\n",
      "indices=tensor([1421, 1329, 1493]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9821e-01, 3.7379e-04, 1.7534e-04]),\n",
      "indices=tensor([1156, 1338, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9587, 0.0115, 0.0058]),\n",
      "indices=tensor([1304, 1282, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3174, 0.0415, 0.0383]),\n",
      "indices=tensor([1272, 1403, 1303]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9796, 0.0020, 0.0014]),\n",
      "indices=tensor([1213, 1219, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0763, 0.0653, 0.0535]),\n",
      "indices=tensor([1244, 1152,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9550, 0.0322, 0.0017]),\n",
      "indices=tensor([1117, 1164, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9563e-01, 2.9737e-03, 6.3365e-04]),\n",
      "indices=tensor([1180, 1346, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9984e-01, 1.7978e-05, 1.7251e-05]),\n",
      "indices=tensor([1362, 1380, 1423]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5600, 0.3446, 0.0131]),\n",
      "indices=tensor([1391, 1445, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7712, 0.0348, 0.0162]),\n",
      "indices=tensor([1350, 1329, 1407]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9608e-01, 4.1247e-04, 3.0937e-04]),\n",
      "indices=tensor([ 930, 1047, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9668e-01, 8.0135e-04, 6.0422e-04]),\n",
      "indices=tensor([1048, 1295, 1332]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7985, 0.0182, 0.0125]),\n",
      "indices=tensor([1400, 1382, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9137, 0.0091, 0.0064]),\n",
      "indices=tensor([1045, 1058, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9277e-01, 6.6789e-04, 6.0369e-04]),\n",
      "indices=tensor([1326, 1398, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9810e-01, 1.8997e-04, 1.1609e-04]),\n",
      "indices=tensor([1227, 1380, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9543, 0.0049, 0.0021]),\n",
      "indices=tensor([1514, 1498, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0442, 0.0360, 0.0336]),\n",
      "indices=tensor([1382, 1357, 1348]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9883, 0.0030, 0.0013]),\n",
      "indices=tensor([1350, 1433, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0508, 0.0304, 0.0279]),\n",
      "indices=tensor([1438, 1445,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7235, 0.0549, 0.0446]),\n",
      "indices=tensor([1419, 1448, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1608, 0.0830, 0.0795]),\n",
      "indices=tensor([1284, 1304, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0500, 0.0384, 0.0374]),\n",
      "indices=tensor([1357, 1322, 1262]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9964e-01, 4.7336e-05, 3.5400e-05]),\n",
      "indices=tensor([1081, 1433, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9227, 0.0507, 0.0035]),\n",
      "indices=tensor([1313, 1356, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9592e-01, 3.9518e-04, 3.5346e-04]),\n",
      "indices=tensor([1227, 1313, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0759, 0.0596, 0.0491]),\n",
      "indices=tensor([1492, 1178, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1442, 0.0471, 0.0439]),\n",
      "indices=tensor([1134, 1196, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9980e-01, 3.0732e-05, 2.0811e-05]),\n",
      "indices=tensor([1058, 1230, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9914, 0.0012, 0.0011]),\n",
      "indices=tensor([1475, 1396, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1629, 0.0756, 0.0436]),\n",
      "indices=tensor([1214, 1345, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1088, 0.0638, 0.0509]),\n",
      "indices=tensor([1067,  988, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0919, 0.0542, 0.0370]),\n",
      "indices=tensor([1117, 1500, 1022]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6355, 0.2698, 0.0090]),\n",
      "indices=tensor([1357, 1386, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3189, 0.1215, 0.0303]),\n",
      "indices=tensor([1437, 1413, 1257]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3763, 0.1749, 0.0338]),\n",
      "indices=tensor([1495, 1415, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9597, 0.0030, 0.0026]),\n",
      "indices=tensor([1462, 1498, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0424, 0.0360, 0.0310]),\n",
      "indices=tensor([1492, 1178, 1478]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9098, 0.0356, 0.0055]),\n",
      "indices=tensor([1343, 1453, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6775, 0.2663, 0.0049]),\n",
      "indices=tensor([1315, 1359, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8448, 0.1133, 0.0058]),\n",
      "indices=tensor([1284, 1202, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0753, 0.0580, 0.0457]),\n",
      "indices=tensor([1438,  988, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9508e-01, 1.8846e-03, 3.6401e-04]),\n",
      "indices=tensor([1193, 1031, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9876, 0.0019, 0.0018]),\n",
      "indices=tensor([1419, 1285, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0924, 0.0621, 0.0468]),\n",
      "indices=tensor([1489, 1493, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0724, 0.0622, 0.0533]),\n",
      "indices=tensor([ 988, 1214, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0684, 0.0609, 0.0554]),\n",
      "indices=tensor([1243, 1257, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2421, 0.0467, 0.0419]),\n",
      "indices=tensor([1058, 1031, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9998e-01, 2.5040e-06, 1.6833e-06]),\n",
      "indices=tensor([1148, 1134, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9285, 0.0064, 0.0062]),\n",
      "indices=tensor([1393, 1382, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5877, 0.0459, 0.0204]),\n",
      "indices=tensor([1092, 1152, 1186]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0987, 0.0838, 0.0602]),\n",
      "indices=tensor([1284, 1192,  990]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2837, 0.0715, 0.0287]),\n",
      "indices=tensor([1387, 1395, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1426, 0.0864, 0.0412]),\n",
      "indices=tensor([1376, 1382, 1273]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0911, 0.0720, 0.0686]),\n",
      "indices=tensor([1110, 1297, 1257]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4524, 0.3554, 0.0861]),\n",
      "indices=tensor([1067, 1063, 1295]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9998e-01, 2.9943e-06, 2.1893e-06]),\n",
      "indices=tensor([ 930, 1357, 1340]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9764, 0.0043, 0.0015]),\n",
      "indices=tensor([1346, 1550, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8100, 0.1624, 0.0048]),\n",
      "indices=tensor([1158, 1123, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5053, 0.0300, 0.0259]),\n",
      "indices=tensor([1375, 1357, 1409]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0567, 0.0552, 0.0541]),\n",
      "indices=tensor([1112, 1445, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0927, 0.0906, 0.0819]),\n",
      "indices=tensor([1380, 1437, 1493]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7108, 0.2676, 0.0031]),\n",
      "indices=tensor([1257, 1301, 1156]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0943, 0.0614, 0.0526]),\n",
      "indices=tensor([1389, 1203, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5729, 0.0911, 0.0561]),\n",
      "indices=tensor([1396, 1413, 1343]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1478, 0.0789, 0.0626]),\n",
      "indices=tensor([1403, 1460, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1563, 0.0564, 0.0447]),\n",
      "indices=tensor([1395, 1445, 1348]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7510, 0.1751, 0.0081]),\n",
      "indices=tensor([1390, 1366, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9836, 0.0033, 0.0032]),\n",
      "indices=tensor([1252, 1413, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3304, 0.1875, 0.0412]),\n",
      "indices=tensor([1406, 1313, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9045e-01, 9.1386e-04, 7.1544e-04]),\n",
      "indices=tensor([1304, 1406, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9980e-01, 4.1185e-05, 1.6292e-05]),\n",
      "indices=tensor([1152, 1500, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8660, 0.0431, 0.0062]),\n",
      "indices=tensor([1248,  985, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9975e-01, 3.5388e-05, 1.2033e-05]),\n",
      "indices=tensor([1330, 1380, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0907, 0.0566, 0.0490]),\n",
      "indices=tensor([1110, 1339, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0830, 0.0823, 0.0621]),\n",
      "indices=tensor([1110, 1297, 1257]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2284, 0.1366, 0.0458]),\n",
      "indices=tensor([1385, 1405, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9926e-01, 2.1365e-04, 5.5109e-05]),\n",
      "indices=tensor([1155, 1120, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9943e-01, 8.2340e-05, 5.0091e-05]),\n",
      "indices=tensor([1212, 1266, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9516, 0.0027, 0.0026]),\n",
      "indices=tensor([1218, 1154, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9817, 0.0027, 0.0014]),\n",
      "indices=tensor([1064, 1454, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1297, 0.0711, 0.0560]),\n",
      "indices=tensor([1448, 1359, 1454]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0794, 0.0749, 0.0529]),\n",
      "indices=tensor([1403, 1112, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9882e-01, 3.6514e-04, 5.2550e-05]),\n",
      "indices=tensor([ 985, 1248, 1258]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1608, 0.0749, 0.0579]),\n",
      "indices=tensor([1403, 1440, 1446]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0667, 0.0664, 0.0574]),\n",
      "indices=tensor([1395, 1154, 1114]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8965, 0.0087, 0.0086]),\n",
      "indices=tensor([1393, 1382, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9910, 0.0030, 0.0015]),\n",
      "indices=tensor([1548, 1413, 1366]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0544, 0.0478, 0.0450]),\n",
      "indices=tensor([1403, 1460, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8476, 0.0084, 0.0067]),\n",
      "indices=tensor([1418, 1403, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0748, 0.0599, 0.0370]),\n",
      "indices=tensor([1189, 1238, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0987, 0.0599, 0.0487]),\n",
      "indices=tensor([1393, 1413, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9540, 0.0070, 0.0028]),\n",
      "indices=tensor([1308, 1326, 1347]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1233, 0.1038, 0.0577]),\n",
      "indices=tensor([1489, 1522, 1209]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0738, 0.0623, 0.0478]),\n",
      "indices=tensor([1380, 1387, 1039]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.8972, 0.0066, 0.0059]),\n",
      "indices=tensor([1355, 1154, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6511, 0.0544, 0.0278]),\n",
      "indices=tensor([1227, 1403, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4943, 0.0622, 0.0455]),\n",
      "indices=tensor([1262, 1308, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0857, 0.0681, 0.0611]),\n",
      "indices=tensor([1496, 1313, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1362, 0.0523, 0.0511]),\n",
      "indices=tensor([1409, 1496, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8944, 0.0102, 0.0091]),\n",
      "indices=tensor([1081, 1433, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2149, 0.1251, 0.0485]),\n",
      "indices=tensor([1395, 1064, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4062, 0.0711, 0.0212]),\n",
      "indices=tensor([1269, 1112,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9421e-01, 1.4490e-03, 5.3779e-04]),\n",
      "indices=tensor([1258, 1296, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9936e-01, 3.3094e-05, 2.7171e-05]),\n",
      "indices=tensor([1047, 1156, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4132, 0.1334, 0.0950]),\n",
      "indices=tensor([1274, 1218, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1325, 0.0691, 0.0363]),\n",
      "indices=tensor([1403, 1058, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9807, 0.0031, 0.0022]),\n",
      "indices=tensor([1407, 1453, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0910, 0.0468, 0.0395]),\n",
      "indices=tensor([1413, 1489, 1419]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0471, 0.0420, 0.0398]),\n",
      "indices=tensor([1193, 1278, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9529e-01, 5.5673e-04, 2.5423e-04]),\n",
      "indices=tensor([1332, 1406, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0654, 0.0558, 0.0507]),\n",
      "indices=tensor([1230, 1313, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2125, 0.1319, 0.0959]),\n",
      "indices=tensor([1403, 1394, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1968, 0.0997, 0.0459]),\n",
      "indices=tensor([1403, 1383, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9630, 0.0149, 0.0016]),\n",
      "indices=tensor([1480, 1394,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9790e-01, 1.5252e-04, 9.2386e-05]),\n",
      "indices=tensor([1395, 1403, 1429]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0558, 0.0483, 0.0441]),\n",
      "indices=tensor([1407, 1489,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9535, 0.0204, 0.0065]),\n",
      "indices=tensor([1359, 1327, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7447, 0.0609, 0.0281]),\n",
      "indices=tensor([1252, 1218, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1001, 0.0563, 0.0475]),\n",
      "indices=tensor([1213, 1313, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8718e-01, 1.0656e-03, 7.1091e-04]),\n",
      "indices=tensor([1189, 1156, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8185, 0.0171, 0.0084]),\n",
      "indices=tensor([1164, 1148, 1276]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9741, 0.0032, 0.0015]),\n",
      "indices=tensor([1194, 1167,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8432, 0.0249, 0.0121]),\n",
      "indices=tensor([1435, 1403, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1414, 0.0662, 0.0571]),\n",
      "indices=tensor([1395, 1460, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8166e-01, 2.9105e-03, 8.9868e-04]),\n",
      "indices=tensor([1068, 1082, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7744e-01, 1.5911e-02, 5.4218e-04]),\n",
      "indices=tensor([1396, 1413, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1500, 0.0646, 0.0503]),\n",
      "indices=tensor([1478, 1403, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9655e-01, 3.6501e-04, 1.4363e-04]),\n",
      "indices=tensor([1332, 1357, 1323]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0540, 0.0490, 0.0476]),\n",
      "indices=tensor([1189, 1403, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9825e-01, 2.1266e-04, 2.0897e-04]),\n",
      "indices=tensor([1142, 1283, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0681, 0.0345, 0.0344]),\n",
      "indices=tensor([1310, 1297, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1454, 0.0747, 0.0425]),\n",
      "indices=tensor([1403, 1343, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9970e-01, 3.3951e-05, 3.0810e-05]),\n",
      "indices=tensor([1022,  983, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0476, 0.0381, 0.0377]),\n",
      "indices=tensor([1243, 1276, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9830, 0.0016, 0.0010]),\n",
      "indices=tensor([1276, 1178, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9237e-01, 2.8965e-03, 4.7273e-04]),\n",
      "indices=tensor([1401, 1387, 1446]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9723e-01, 3.8750e-04, 2.4119e-04]),\n",
      "indices=tensor([1341, 1315, 1156]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9754, 0.0064, 0.0018]),\n",
      "indices=tensor([1385, 1379, 1347]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9873, 0.0012, 0.0011]),\n",
      "indices=tensor([ 996, 1112, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9828, 0.0031, 0.0011]),\n",
      "indices=tensor([1480, 1394, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8508e-01, 5.6335e-03, 5.6171e-04]),\n",
      "indices=tensor([1428, 1452,  987]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0538, 0.0386, 0.0279]),\n",
      "indices=tensor([1550, 1114, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1374, 0.0736, 0.0591]),\n",
      "indices=tensor([1462, 1499, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0668, 0.0455, 0.0441]),\n",
      "indices=tensor([1499,  946, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2319, 0.0895, 0.0713]),\n",
      "indices=tensor([1421, 1496, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9926e-01, 7.9950e-05, 7.9884e-05]),\n",
      "indices=tensor([1355, 1485, 1346]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3688, 0.0552, 0.0380]),\n",
      "indices=tensor([1421, 1438, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9427, 0.0150, 0.0092]),\n",
      "indices=tensor([1395, 1400, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9734, 0.0071, 0.0065]),\n",
      "indices=tensor([1435, 1421, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9129, 0.0168, 0.0049]),\n",
      "indices=tensor([1332, 1357, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0948, 0.0537, 0.0518]),\n",
      "indices=tensor([1438, 1213, 1096]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9958e-01, 1.0029e-04, 5.5709e-05]),\n",
      "indices=tensor([1058, 1439, 1117]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9669, 0.0022, 0.0017]),\n",
      "indices=tensor([1186, 1291, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1649, 0.0424, 0.0396]),\n",
      "indices=tensor([1058, 1472, 1060]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0637, 0.0529, 0.0390]),\n",
      "indices=tensor([1403, 1096,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3796, 0.0692, 0.0583]),\n",
      "indices=tensor([1500, 1478, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9863e-01, 5.6661e-04, 4.1684e-04]),\n",
      "indices=tensor([1405, 1350, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2455, 0.1961, 0.1337]),\n",
      "indices=tensor([1431, 1500, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1893, 0.0441, 0.0392]),\n",
      "indices=tensor([1403, 1550, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0682, 0.0672, 0.0516]),\n",
      "indices=tensor([ 996, 1154, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1073, 0.1057, 0.0893]),\n",
      "indices=tensor([1417, 1420, 1344]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0476, 0.0342, 0.0340]),\n",
      "indices=tensor([1403, 1438, 1303]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3332, 0.1188, 0.0412]),\n",
      "indices=tensor([1423, 1380, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1240, 0.0399, 0.0385]),\n",
      "indices=tensor([1400, 1499,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0885, 0.0498, 0.0485]),\n",
      "indices=tensor([ 988, 1112, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1348, 0.0608, 0.0324]),\n",
      "indices=tensor([1112, 1045, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2458, 0.0601, 0.0482]),\n",
      "indices=tensor([1403, 1550, 1227]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9812e-01, 8.6763e-04, 9.4529e-05]),\n",
      "indices=tensor([1425, 1435, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0728, 0.0673, 0.0416]),\n",
      "indices=tensor([1403, 1308, 1376]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0850, 0.0639, 0.0613]),\n",
      "indices=tensor([1248, 1415,  956]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0533, 0.0530, 0.0511]),\n",
      "indices=tensor([1308, 1284, 1310]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0878, 0.0782, 0.0384]),\n",
      "indices=tensor([1258, 1310, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4552, 0.0320, 0.0254]),\n",
      "indices=tensor([1493, 1478, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0801, 0.0468, 0.0461]),\n",
      "indices=tensor([1460, 1283, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9143, 0.0040, 0.0032]),\n",
      "indices=tensor([1310, 1274, 1233]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0878, 0.0587, 0.0518]),\n",
      "indices=tensor([1403, 1448, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0418, 0.0280, 0.0279]),\n",
      "indices=tensor([1112, 1096, 1272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9857, 0.0032, 0.0012]),\n",
      "indices=tensor([1439, 1403, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1160, 0.0498, 0.0479]),\n",
      "indices=tensor([1357, 1486, 1269]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.2013, 0.0538, 0.0459]),\n",
      "indices=tensor([1413, 1354, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8841, 0.0106, 0.0062]),\n",
      "indices=tensor([1168, 1330, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9043, 0.0099, 0.0054]),\n",
      "indices=tensor([1403, 1409, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8533e-01, 9.6123e-03, 8.1234e-04]),\n",
      "indices=tensor([1194, 1168, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1808, 0.1297, 0.0920]),\n",
      "indices=tensor([1550, 1406, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9796, 0.0022, 0.0019]),\n",
      "indices=tensor([1380, 1308, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0656, 0.0593, 0.0543]),\n",
      "indices=tensor([1413, 1550, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2937, 0.0335, 0.0301]),\n",
      "indices=tensor([1114, 1238, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2726, 0.0361, 0.0331]),\n",
      "indices=tensor([1495, 1498, 1499]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1073, 0.0807, 0.0616]),\n",
      "indices=tensor([1448, 1359, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7035, 0.0191, 0.0129]),\n",
      "indices=tensor([1227, 1400, 1117]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4888, 0.0608, 0.0417]),\n",
      "indices=tensor([1438, 1440, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1069, 0.0684, 0.0660]),\n",
      "indices=tensor([1496, 1283, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1743, 0.0424, 0.0383]),\n",
      "indices=tensor([1403, 1296, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9845, 0.0024, 0.0018]),\n",
      "indices=tensor([1375, 1496, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8383, 0.1263, 0.0046]),\n",
      "indices=tensor([1370, 1436, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4371, 0.3897, 0.0485]),\n",
      "indices=tensor([1462, 1419, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0896, 0.0809, 0.0454]),\n",
      "indices=tensor([1413, 1495, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9777, 0.0031, 0.0023]),\n",
      "indices=tensor([1401, 1456, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0931, 0.0811, 0.0566]),\n",
      "indices=tensor([1460, 1382, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9709, 0.0059, 0.0020]),\n",
      "indices=tensor([1494, 1223, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8435, 0.0841, 0.0071]),\n",
      "indices=tensor([1031, 1193, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2297, 0.0670, 0.0377]),\n",
      "indices=tensor([1421, 1403, 1500]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1268, 0.0568, 0.0561]),\n",
      "indices=tensor([1438, 1386, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5002, 0.0371, 0.0310]),\n",
      "indices=tensor([1392, 1278, 1142]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9986e-01, 3.1694e-05, 8.2925e-06]),\n",
      "indices=tensor([1255, 1292, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8827, 0.0325, 0.0078]),\n",
      "indices=tensor([1421, 1386, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0417, 0.0404, 0.0332]),\n",
      "indices=tensor([1445,  970, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0527, 0.0446, 0.0424]),\n",
      "indices=tensor([1218, 1168, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0933, 0.0851, 0.0543]),\n",
      "indices=tensor([1218, 1382, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1098, 0.0571, 0.0523]),\n",
      "indices=tensor([1058, 1030,  986]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9616, 0.0134, 0.0093]),\n",
      "indices=tensor([1366, 1340, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9681e-01, 4.8665e-04, 3.0264e-04]),\n",
      "indices=tensor([1252, 1489, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0669, 0.0596, 0.0540]),\n",
      "indices=tensor([1445, 1409, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1378, 0.0484, 0.0484]),\n",
      "indices=tensor([1496, 1283, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9519, 0.0104, 0.0063]),\n",
      "indices=tensor([1417, 1439, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9498, 0.0037, 0.0035]),\n",
      "indices=tensor([1359, 1489, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9185e-01, 1.4944e-03, 9.4711e-04]),\n",
      "indices=tensor([1258, 1193, 1243]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9944e-01, 2.2105e-04, 2.6434e-05]),\n",
      "indices=tensor([1437, 1448, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0584, 0.0492, 0.0437]),\n",
      "indices=tensor([1345, 1489, 1291]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0804, 0.0616, 0.0307]),\n",
      "indices=tensor([1395, 1154, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9354, 0.0088, 0.0069]),\n",
      "indices=tensor([1130, 1313, 1238]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3455, 0.1373, 0.0426]),\n",
      "indices=tensor([1445, 1413, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0615, 0.0608, 0.0570]),\n",
      "indices=tensor([1448, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4945, 0.0227, 0.0183]),\n",
      "indices=tensor([1319, 1308, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0739, 0.0619, 0.0376]),\n",
      "indices=tensor([1489, 1403, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9426e-01, 3.7902e-04, 2.9891e-04]),\n",
      "indices=tensor([1433, 1403, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0477, 0.0389, 0.0386]),\n",
      "indices=tensor([1255, 1145, 1282]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9938e-01, 8.7115e-05, 5.8047e-05]),\n",
      "indices=tensor([1081, 1433, 1274]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1358, 0.0568, 0.0484]),\n",
      "indices=tensor([1394, 1496,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9635, 0.0059, 0.0039]),\n",
      "indices=tensor([1452, 1428, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1181, 0.0674, 0.0601]),\n",
      "indices=tensor([1496, 1403, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9933e-01, 7.6327e-05, 7.2812e-05]),\n",
      "indices=tensor([1313, 1437, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9651, 0.0049, 0.0020]),\n",
      "indices=tensor([1550, 1496, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3651, 0.0753, 0.0439]),\n",
      "indices=tensor([1500, 1168, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7397, 0.0247, 0.0108]),\n",
      "indices=tensor([1391, 1413, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2346, 0.1560, 0.0815]),\n",
      "indices=tensor([1371, 1438, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0621, 0.0516, 0.0440]),\n",
      "indices=tensor([1496,  941, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1595, 0.0445, 0.0373]),\n",
      "indices=tensor([1496, 1317, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9279, 0.0053, 0.0031]),\n",
      "indices=tensor([1194, 1167,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1373, 0.0554, 0.0476]),\n",
      "indices=tensor([1248,  956, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9998e-01, 2.3435e-06, 1.7314e-06]),\n",
      "indices=tensor([ 927, 1193, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3806, 0.0216, 0.0202]),\n",
      "indices=tensor([1341, 1120, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6389, 0.0356, 0.0260]),\n",
      "indices=tensor([1233, 1277, 1310]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1512, 0.0785, 0.0442]),\n",
      "indices=tensor([1227, 1244, 1117]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8872e-01, 1.3693e-03, 8.5397e-04]),\n",
      "indices=tensor([1359, 1403, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5743, 0.0240, 0.0239]),\n",
      "indices=tensor([1120,  983, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9990e-01, 1.0474e-05, 1.0320e-05]),\n",
      "indices=tensor([1346, 1550, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9777, 0.0023, 0.0014]),\n",
      "indices=tensor([1009, 1284,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7269, 0.0224, 0.0188]),\n",
      "indices=tensor([1393, 1382, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9881e-01, 3.9349e-04, 1.6750e-04]),\n",
      "indices=tensor([1295, 1202, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1125, 0.0704, 0.0446]),\n",
      "indices=tensor([1496, 1550, 1063]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9998e-01, 3.2283e-06, 2.3883e-06]),\n",
      "indices=tensor([ 800, 1053, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8258, 0.1105, 0.0053]),\n",
      "indices=tensor([1227, 1265, 1039]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1566, 0.0533, 0.0374]),\n",
      "indices=tensor([1496, 1374, 1493]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0935, 0.0586, 0.0529]),\n",
      "indices=tensor([1400, 1394, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8735e-01, 1.1461e-03, 7.2507e-04]),\n",
      "indices=tensor([1142, 1067, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1079, 0.0924, 0.0399]),\n",
      "indices=tensor([1218, 1110, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1396, 0.1180, 0.0424]),\n",
      "indices=tensor([1296, 1403,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8993e-01, 1.3077e-03, 8.5183e-04]),\n",
      "indices=tensor([1433, 1403, 1203]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0485, 0.0450, 0.0413]),\n",
      "indices=tensor([1278, 1674,  983]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8751, 0.0224, 0.0057]),\n",
      "indices=tensor([1403, 1389, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9069e-01, 7.3492e-04, 4.0839e-04]),\n",
      "indices=tensor([1110,  956, 1203]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7022, 0.0844, 0.0303]),\n",
      "indices=tensor([1475, 1396, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8776, 0.0096, 0.0087]),\n",
      "indices=tensor([1414, 1332, 1344]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9089, 0.0366, 0.0036]),\n",
      "indices=tensor([1472, 1400, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0925, 0.0677, 0.0526]),\n",
      "indices=tensor([1310, 1291, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3732, 0.0570, 0.0298]),\n",
      "indices=tensor([ 988, 1214, 1309]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9705, 0.0202, 0.0012]),\n",
      "indices=tensor([1269, 1292, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0424, 0.0411, 0.0369]),\n",
      "indices=tensor([1445, 1233, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9391, 0.0160, 0.0064]),\n",
      "indices=tensor([1399, 1403, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9499, 0.0046, 0.0038]),\n",
      "indices=tensor([ 930, 1448, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0606, 0.0596, 0.0563]),\n",
      "indices=tensor([1380, 1348, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0623, 0.0477, 0.0424]),\n",
      "indices=tensor([1058, 1330, 1297]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0887, 0.0718, 0.0393]),\n",
      "indices=tensor([1313, 1345, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0556, 0.0520, 0.0472]),\n",
      "indices=tensor([1403, 1154, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9682e-01, 7.2005e-04, 3.4500e-04]),\n",
      "indices=tensor([1310, 1674, 1291]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.9139, 0.0056, 0.0055]),\n",
      "indices=tensor([1214, 1413,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8347, 0.0111, 0.0088]),\n",
      "indices=tensor([1248,  956, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8443, 0.0127, 0.0093]),\n",
      "indices=tensor([1030, 1110, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9649, 0.0025, 0.0022]),\n",
      "indices=tensor([1417, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9714, 0.0041, 0.0020]),\n",
      "indices=tensor([1438, 1406, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5821, 0.2760, 0.0175]),\n",
      "indices=tensor([1421, 1455, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0681, 0.0614, 0.0504]),\n",
      "indices=tensor([1403, 1550,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5510, 0.3551, 0.0123]),\n",
      "indices=tensor([1269, 1305, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9363, 0.0066, 0.0042]),\n",
      "indices=tensor([1417, 1496, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9188, 0.0054, 0.0043]),\n",
      "indices=tensor([1418, 1386, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8758, 0.0108, 0.0070]),\n",
      "indices=tensor([1158, 1126, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0447, 0.0432, 0.0430]),\n",
      "indices=tensor([1060, 1110,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1457, 0.0853, 0.0737]),\n",
      "indices=tensor([1403, 1383, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4405, 0.0431, 0.0285]),\n",
      "indices=tensor([1409, 1421, 1203]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7124, 0.0306, 0.0250]),\n",
      "indices=tensor([1313, 1265, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8719e-01, 5.9168e-03, 4.0959e-04]),\n",
      "indices=tensor([1322, 1345, 1273]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9419e-01, 3.9762e-04, 3.0283e-04]),\n",
      "indices=tensor([1415, 1456, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9846, 0.0065, 0.0027]),\n",
      "indices=tensor([1417, 1438, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2225, 0.0845, 0.0669]),\n",
      "indices=tensor([1313, 1406, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9773, 0.0116, 0.0017]),\n",
      "indices=tensor([1370, 1439, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9654e-01, 6.7581e-04, 4.4890e-04]),\n",
      "indices=tensor([1180, 1347, 1398]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0992, 0.0780, 0.0614]),\n",
      "indices=tensor([1308, 1415, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4350, 0.0564, 0.0468]),\n",
      "indices=tensor([1276, 1395, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9946e-01, 5.7690e-05, 5.0212e-05]),\n",
      "indices=tensor([1224, 1438, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9343e-01, 2.9850e-04, 2.6317e-04]),\n",
      "indices=tensor([1339, 1456, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9981e-01, 1.3084e-04, 3.7223e-06]),\n",
      "indices=tensor([1255, 1292, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1579, 0.0648, 0.0591]),\n",
      "indices=tensor([1224, 1227, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0549, 0.0456, 0.0417]),\n",
      "indices=tensor([1375, 1321, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8072, 0.0106, 0.0103]),\n",
      "indices=tensor([ 983, 1022, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0473, 0.0429, 0.0396]),\n",
      "indices=tensor([1448, 1439, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9999e-01, 1.2901e-06, 1.0685e-06]),\n",
      "indices=tensor([ 930, 1357, 1340]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9801, 0.0035, 0.0028]),\n",
      "indices=tensor([1265, 1227, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0482, 0.0441, 0.0438]),\n",
      "indices=tensor([1309, 1238, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7374, 0.0660, 0.0175]),\n",
      "indices=tensor([1380, 1440, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0634, 0.0555, 0.0484]),\n",
      "indices=tensor([1641, 1196, 1139]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9972e-01, 1.2893e-04, 1.2905e-05]),\n",
      "indices=tensor([1378, 1395, 1039]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9597, 0.0090, 0.0056]),\n",
      "indices=tensor([1374, 1398, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0939, 0.0580, 0.0377]),\n",
      "indices=tensor([1437, 1440, 1429]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9877, 0.0039, 0.0033]),\n",
      "indices=tensor([1269, 1297, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9515e-01, 9.7840e-04, 4.0836e-04]),\n",
      "indices=tensor([1387, 1413, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9740, 0.0029, 0.0021]),\n",
      "indices=tensor([1530, 1485, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1962, 0.0570, 0.0490]),\n",
      "indices=tensor([1387, 1357, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9867, 0.0023, 0.0015]),\n",
      "indices=tensor([1339, 1455, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2033, 0.0902, 0.0634]),\n",
      "indices=tensor([1308, 1273, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0946, 0.0918, 0.0729]),\n",
      "indices=tensor([1317, 1313, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9689e-01, 1.0921e-03, 6.3737e-04]),\n",
      "indices=tensor([1305, 1219, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8287e-01, 1.0818e-03, 8.7651e-04]),\n",
      "indices=tensor([1325, 1496, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0994, 0.0543, 0.0419]),\n",
      "indices=tensor([1496, 1283, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0670, 0.0589, 0.0335]),\n",
      "indices=tensor([1112, 1053,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9606e-01, 2.5295e-04, 2.3236e-04]),\n",
      "indices=tensor([1142, 1067, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8364, 0.0562, 0.0545]),\n",
      "indices=tensor([1126, 1154, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9075, 0.0479, 0.0157]),\n",
      "indices=tensor([1332, 1305, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9778e-01, 1.9624e-04, 1.3645e-04]),\n",
      "indices=tensor([1446, 1248, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9407e-01, 7.1555e-04, 4.3491e-04]),\n",
      "indices=tensor([1194, 1387, 1379]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9259, 0.0169, 0.0066]),\n",
      "indices=tensor([1398, 1326, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5588, 0.0235, 0.0210]),\n",
      "indices=tensor([1418, 1403, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8763e-01, 1.1067e-03, 9.8183e-04]),\n",
      "indices=tensor([1278, 1232, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9674e-01, 4.6889e-04, 3.3732e-04]),\n",
      "indices=tensor([1152, 1308, 1130]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9549, 0.0034, 0.0029]),\n",
      "indices=tensor([1143, 1641, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0937, 0.0785, 0.0622]),\n",
      "indices=tensor([1362, 1297, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8473, 0.0897, 0.0115]),\n",
      "indices=tensor([1448, 1316, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0586, 0.0506, 0.0467]),\n",
      "indices=tensor([1218, 1357, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1256, 0.0527, 0.0501]),\n",
      "indices=tensor([1403, 1152,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8470e-01, 1.4127e-03, 8.3716e-04]),\n",
      "indices=tensor([1435,  988, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9531e-01, 7.4404e-04, 5.0188e-04]),\n",
      "indices=tensor([1674, 1433, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0719, 0.0429, 0.0405]),\n",
      "indices=tensor([1067, 1053, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3644, 0.0347, 0.0303]),\n",
      "indices=tensor([1123,  970, 1117]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0952, 0.0765, 0.0600]),\n",
      "indices=tensor([1403, 1390, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7141, 0.2698, 0.0015]),\n",
      "indices=tensor([1322, 1345,  985]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9240, 0.0088, 0.0033]),\n",
      "indices=tensor([1269, 1415, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2551, 0.0519, 0.0488]),\n",
      "indices=tensor([1370, 1292, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0845, 0.0658, 0.0605]),\n",
      "indices=tensor([1493, 1496, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0759, 0.0584, 0.0500]),\n",
      "indices=tensor([1437, 1496, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9317e-01, 9.4205e-04, 6.3172e-04]),\n",
      "indices=tensor([1227, 1395, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9634e-01, 3.3563e-04, 3.1327e-04]),\n",
      "indices=tensor([1530, 1485, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9823, 0.0020, 0.0012]),\n",
      "indices=tensor([1395, 1196, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6901, 0.0998, 0.0148]),\n",
      "indices=tensor([1272, 1288, 1291]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9817e-01, 2.1331e-04, 1.5155e-04]),\n",
      "indices=tensor([1343, 1413, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1280, 0.0718, 0.0327]),\n",
      "indices=tensor([1152, 1308,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1472, 0.0436, 0.0431]),\n",
      "indices=tensor([1403, 1445, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8669, 0.0593, 0.0044]),\n",
      "indices=tensor([1396, 1413, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0846, 0.0559, 0.0515]),\n",
      "indices=tensor([1460, 1154, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1432, 0.0641, 0.0364]),\n",
      "indices=tensor([1406, 1489, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9795e-01, 2.8459e-04, 1.3339e-04]),\n",
      "indices=tensor([1154, 1288, 1309]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9963e-01, 2.5133e-05, 2.1953e-05]),\n",
      "indices=tensor([ 996, 1196, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0904, 0.0584, 0.0532]),\n",
      "indices=tensor([1030, 1178, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9599, 0.0057, 0.0054]),\n",
      "indices=tensor([1317, 1308, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0555, 0.0420, 0.0375]),\n",
      "indices=tensor([1385, 1438, 1393]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1273, 0.0993, 0.0465]),\n",
      "indices=tensor([1403, 1343, 1459]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4407, 0.0801, 0.0421]),\n",
      "indices=tensor([1355, 1485, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9815e-01, 1.5092e-04, 1.1040e-04]),\n",
      "indices=tensor([1446, 1248,  986]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9262e-01, 5.0936e-04, 3.6464e-04]),\n",
      "indices=tensor([1031, 1126, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3378, 0.1165, 0.0566]),\n",
      "indices=tensor([1269, 1436, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9997e-01, 4.3892e-06, 3.2946e-06]),\n",
      "indices=tensor([ 930, 1472, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2032, 0.1516, 0.0504]),\n",
      "indices=tensor([1218, 1308, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8804e-01, 7.1818e-04, 6.5772e-04]),\n",
      "indices=tensor([1244, 1433, 1231]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8009, 0.0404, 0.0187]),\n",
      "indices=tensor([1460, 1452, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0827, 0.0444, 0.0427]),\n",
      "indices=tensor([1293, 1110, 1131]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4970, 0.0413, 0.0287]),\n",
      "indices=tensor([1022, 1382, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2990, 0.0331, 0.0307]),\n",
      "indices=tensor([1272, 1341, 1303]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9913e-01, 4.1317e-04, 7.1872e-05]),\n",
      "indices=tensor([1446, 1413, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2626, 0.0628, 0.0397]),\n",
      "indices=tensor([1112, 1053, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0522, 0.0321, 0.0279]),\n",
      "indices=tensor([1310, 1273, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9683e-01, 5.6189e-04, 2.7572e-04]),\n",
      "indices=tensor([1486, 1437, 1423]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0691, 0.0503, 0.0419]),\n",
      "indices=tensor([1284, 1308, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9850e-01, 6.0136e-04, 1.7726e-04]),\n",
      "indices=tensor([1145, 1455, 1414]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9567, 0.0019, 0.0014]),\n",
      "indices=tensor([1341, 1053, 1120]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0808, 0.0523, 0.0340]),\n",
      "indices=tensor([1341, 1058, 1243]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.8360, 0.0127, 0.0089]),\n",
      "indices=tensor([1319, 1448, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9251, 0.0698, 0.0019]),\n",
      "indices=tensor([1134, 1268, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9997e-01, 9.2714e-06, 3.2025e-06]),\n",
      "indices=tensor([1134, 1386, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0854, 0.0718, 0.0673]),\n",
      "indices=tensor([1145, 1022, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0847, 0.0565, 0.0484]),\n",
      "indices=tensor([1117, 1009, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1690, 0.1336, 0.1210]),\n",
      "indices=tensor([1421, 1435, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0726, 0.0646, 0.0642]),\n",
      "indices=tensor([1325, 1433, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6350, 0.0685, 0.0144]),\n",
      "indices=tensor([1380, 1496, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9976e-01, 1.2023e-04, 1.9844e-05]),\n",
      "indices=tensor([1436, 1413, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9679, 0.0069, 0.0029]),\n",
      "indices=tensor([1063, 1248, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8704, 0.0119, 0.0083]),\n",
      "indices=tensor([1380, 1496, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2344, 0.0548, 0.0355]),\n",
      "indices=tensor([1030, 1178, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0789, 0.0443, 0.0407]),\n",
      "indices=tensor([1400, 1395, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0494, 0.0442, 0.0354]),\n",
      "indices=tensor([1407, 1382, 1348]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0721, 0.0600, 0.0410]),\n",
      "indices=tensor([1445, 1284, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0706, 0.0519, 0.0492]),\n",
      "indices=tensor([1421, 1437, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5899, 0.0227, 0.0218]),\n",
      "indices=tensor([1445, 1397, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0704, 0.0507, 0.0477]),\n",
      "indices=tensor([1329, 1357, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0875, 0.0857, 0.0497]),\n",
      "indices=tensor([1403, 1308, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0840, 0.0640, 0.0488]),\n",
      "indices=tensor([1403, 1448, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6508, 0.0247, 0.0242]),\n",
      "indices=tensor([1110, 1009, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0609, 0.0349, 0.0269]),\n",
      "indices=tensor([1403, 1317, 1257]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4956, 0.2229, 0.0556]),\n",
      "indices=tensor([1437, 1421, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1151, 0.0598, 0.0581]),\n",
      "indices=tensor([1218, 1258, 1498]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8646e-01, 1.4467e-03, 7.2369e-04]),\n",
      "indices=tensor([1202, 1413, 1396]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0520, 0.0382, 0.0314]),\n",
      "indices=tensor([1436, 1387, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5407, 0.0626, 0.0304]),\n",
      "indices=tensor([1238, 1278, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5253, 0.0325, 0.0248]),\n",
      "indices=tensor([1308, 1382, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2695, 0.0456, 0.0441]),\n",
      "indices=tensor([1219, 1078, 1270]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9400e-01, 1.1035e-03, 9.0658e-04]),\n",
      "indices=tensor([1194,  988, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0952, 0.0574, 0.0404]),\n",
      "indices=tensor([1496, 1550, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3427, 0.3174, 0.0300]),\n",
      "indices=tensor([1495, 1480, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0988, 0.0692, 0.0624]),\n",
      "indices=tensor([1413, 1403, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9804, 0.0017, 0.0014]),\n",
      "indices=tensor([1276, 1395, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8603, 0.1050, 0.0040]),\n",
      "indices=tensor([ 987, 1038, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0691, 0.0495, 0.0450]),\n",
      "indices=tensor([1393, 1383,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1642, 0.1242, 0.0480]),\n",
      "indices=tensor([1403, 1394, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9593, 0.0269, 0.0010]),\n",
      "indices=tensor([ 985, 1248, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1527, 0.1176, 0.0357]),\n",
      "indices=tensor([1403, 1395, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1078, 0.0710, 0.0657]),\n",
      "indices=tensor([1452, 1448, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0680, 0.0399, 0.0304]),\n",
      "indices=tensor([1218, 1460, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9662, 0.0042, 0.0029]),\n",
      "indices=tensor([1227, 1297, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9146, 0.0069, 0.0035]),\n",
      "indices=tensor([1380, 1421, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0727, 0.0407, 0.0398]),\n",
      "indices=tensor([1112, 1438, 1251]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0622, 0.0469, 0.0458]),\n",
      "indices=tensor([1112, 1145, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7935, 0.0235, 0.0211]),\n",
      "indices=tensor([1375, 1496, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9993e-01, 9.2492e-06, 4.2199e-06]),\n",
      "indices=tensor([1078, 1500, 1117]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1328, 0.0655, 0.0417]),\n",
      "indices=tensor([1186, 1291, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0723, 0.0629, 0.0430]),\n",
      "indices=tensor([1395, 1445, 1131]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9284e-01, 2.2484e-03, 2.3474e-04]),\n",
      "indices=tensor([1258, 1296, 1164]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0708, 0.0562, 0.0552]),\n",
      "indices=tensor([1224, 1386, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0817, 0.0457, 0.0443]),\n",
      "indices=tensor([1126,  970, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3581, 0.0549, 0.0279]),\n",
      "indices=tensor([1393, 1214, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9795, 0.0019, 0.0012]),\n",
      "indices=tensor([1218, 1123, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1253, 0.1025, 0.0501]),\n",
      "indices=tensor([1284, 1045, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0711, 0.0488, 0.0430]),\n",
      "indices=tensor([1168, 1218, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1290, 0.0349, 0.0337]),\n",
      "indices=tensor([1400, 1196, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9797, 0.0016, 0.0015]),\n",
      "indices=tensor([1480, 1394, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8799e-01, 1.6210e-03, 9.5781e-04]),\n",
      "indices=tensor([1411, 1403, 1408]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9926e-01, 3.4335e-04, 1.0950e-04]),\n",
      "indices=tensor([1297, 1447, 1356]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9213e-01, 7.3801e-04, 3.4021e-04]),\n",
      "indices=tensor([1009,  927, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9820e-01, 2.9418e-04, 1.1454e-04]),\n",
      "indices=tensor([1326, 1142, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9643e-01, 3.4504e-04, 2.5973e-04]),\n",
      "indices=tensor([1433, 1203, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6531, 0.0635, 0.0161]),\n",
      "indices=tensor([1550, 1496, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6252, 0.1250, 0.0922]),\n",
      "indices=tensor([1233, 1186, 1202]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8906e-01, 1.0075e-03, 6.1651e-04]),\n",
      "indices=tensor([1325, 1386, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8645e-01, 9.0934e-04, 8.1042e-04]),\n",
      "indices=tensor([1431, 1674,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9819e-01, 3.4480e-04, 1.5784e-04]),\n",
      "indices=tensor([1156, 1338, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2491, 0.0438, 0.0405]),\n",
      "indices=tensor([1227, 1395, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9552e-01, 7.8291e-04, 6.0344e-04]),\n",
      "indices=tensor([1180, 1347, 1398]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1321, 0.0684, 0.0534]),\n",
      "indices=tensor([1112,  988, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1474, 0.0740, 0.0593]),\n",
      "indices=tensor([1383, 1168, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9981e-01, 3.6237e-05, 1.5539e-05]),\n",
      "indices=tensor([1394, 1550, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9998e-01, 1.8100e-06, 1.5958e-06]),\n",
      "indices=tensor([ 927, 1339, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1482, 0.0711, 0.0529]),\n",
      "indices=tensor([1123, 1395,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9897e-01, 1.2517e-04, 1.2395e-04]),\n",
      "indices=tensor([1419, 1445, 1462]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9886, 0.0043, 0.0011]),\n",
      "indices=tensor([1371, 1550, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9784e-01, 1.5554e-04, 1.2673e-04]),\n",
      "indices=tensor([1332, 1406, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0487, 0.0471, 0.0377]),\n",
      "indices=tensor([1297, 1112, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0632, 0.0621, 0.0615]),\n",
      "indices=tensor([1413, 1310, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1116, 0.0483, 0.0434]),\n",
      "indices=tensor([1438, 1403,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0570, 0.0431, 0.0406]),\n",
      "indices=tensor([1123, 1403, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8867e-01, 2.2979e-03, 8.4678e-04]),\n",
      "indices=tensor([1448, 1437, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4410, 0.0499, 0.0487]),\n",
      "indices=tensor([1414, 1455, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9522, 0.0023, 0.0018]),\n",
      "indices=tensor([1380, 1421, 1209]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0737, 0.0654, 0.0326]),\n",
      "indices=tensor([1496, 1460, 1178]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0420, 0.0333, 0.0325]),\n",
      "indices=tensor([1045, 1192, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9868e-01, 8.4328e-05, 6.8326e-05]),\n",
      "indices=tensor([1383, 1403, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7043, 0.0211, 0.0156]),\n",
      "indices=tensor([1421, 1445, 1293]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2610, 0.1211, 0.0636]),\n",
      "indices=tensor([1465, 1453, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9263, 0.0069, 0.0059]),\n",
      "indices=tensor([1120, 1255, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0764, 0.0534, 0.0396]),\n",
      "indices=tensor([1448, 1348, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0937, 0.0646, 0.0471]),\n",
      "indices=tensor([1403,  941, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0583, 0.0567, 0.0543]),\n",
      "indices=tensor([1465, 1489, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0474, 0.0461, 0.0413]),\n",
      "indices=tensor([1214, 1110, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3678, 0.0463, 0.0461]),\n",
      "indices=tensor([1498, 1309, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0713, 0.0700, 0.0680]),\n",
      "indices=tensor([1285, 1460, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2577, 0.0504, 0.0386]),\n",
      "indices=tensor([1344, 1489, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9034e-01, 5.2662e-03, 8.3006e-04]),\n",
      "indices=tensor([1454, 1413, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9991e-01, 1.1454e-05, 9.3832e-06]),\n",
      "indices=tensor([1078, 1500, 1117]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0582, 0.0497, 0.0464]),\n",
      "indices=tensor([1053, 1112, 1389]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0870, 0.0542, 0.0456]),\n",
      "indices=tensor([1403, 1379, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8000, 0.0133, 0.0132]),\n",
      "indices=tensor([1452, 1550, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1367, 0.0483, 0.0482]),\n",
      "indices=tensor([1218, 1403, 1410]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0906, 0.0706, 0.0674]),\n",
      "indices=tensor([1112, 1445, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8665e-01, 3.7800e-03, 7.9724e-04]),\n",
      "indices=tensor([1433, 1403, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1388, 0.1342, 0.0567]),\n",
      "indices=tensor([1218, 1308, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9885e-01, 1.7082e-04, 7.2224e-05]),\n",
      "indices=tensor([1142, 1415, 1301]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2973, 0.0736, 0.0513]),\n",
      "indices=tensor([1266, 1453, 1407]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7784, 0.0381, 0.0097]),\n",
      "indices=tensor([1550, 1496, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0692, 0.0518, 0.0501]),\n",
      "indices=tensor([1498, 1393, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3260, 0.0432, 0.0378]),\n",
      "indices=tensor([1154, 1243, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0970, 0.0527, 0.0443]),\n",
      "indices=tensor([1445, 1421, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9093, 0.0287, 0.0108]),\n",
      "indices=tensor([1266, 1359, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2050, 0.0851, 0.0839]),\n",
      "indices=tensor([1284, 1496, 1304]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1063, 0.0797, 0.0415]),\n",
      "indices=tensor([1437, 1496, 1471]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9169e-01, 1.2341e-03, 7.5977e-04]),\n",
      "indices=tensor([1375, 1448, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0564, 0.0490, 0.0490]),\n",
      "indices=tensor([1045, 1053, 1389]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0524, 0.0470, 0.0420]),\n",
      "indices=tensor([1131, 1233, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0882, 0.0510, 0.0427]),\n",
      "indices=tensor([1395,  941, 1453]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5008, 0.0566, 0.0526]),\n",
      "indices=tensor([1401, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9122e-01, 1.4055e-03, 9.1822e-04]),\n",
      "indices=tensor([1227, 1395, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7790, 0.1888, 0.0161]),\n",
      "indices=tensor([1297, 1356, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6867, 0.0265, 0.0229]),\n",
      "indices=tensor([1357, 1340, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9342, 0.0189, 0.0115]),\n",
      "indices=tensor([ 983, 1022, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9674, 0.0040, 0.0023]),\n",
      "indices=tensor([1329, 1328, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7060, 0.0327, 0.0214]),\n",
      "indices=tensor([1251, 1394, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0713, 0.0678, 0.0635]),\n",
      "indices=tensor([1321, 1145, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2904, 0.0938, 0.0362]),\n",
      "indices=tensor([1415, 1495, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9883e-01, 1.5785e-04, 6.0023e-05]),\n",
      "indices=tensor([1355, 1383, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0870, 0.0632, 0.0583]),\n",
      "indices=tensor([1489, 1641, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1083, 0.0708, 0.0392]),\n",
      "indices=tensor([1244, 1348, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2879, 0.1064, 0.0663]),\n",
      "indices=tensor([1420, 1394, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2310, 0.0687, 0.0441]),\n",
      "indices=tensor([1218, 1112, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6921, 0.0419, 0.0354]),\n",
      "indices=tensor([1359, 1448, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0824, 0.0776, 0.0397]),\n",
      "indices=tensor([1486, 1154, 1389]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9650e-01, 3.5791e-04, 3.1082e-04]),\n",
      "indices=tensor([1367, 1321, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9891e-01, 8.4370e-05, 7.7207e-05]),\n",
      "indices=tensor([1447, 1343, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9824e-01, 1.0785e-03, 3.8732e-05]),\n",
      "indices=tensor([1317, 1252, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9969e-01, 4.8905e-05, 3.2301e-05]),\n",
      "indices=tensor([1479, 1459, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0575, 0.0392, 0.0337]),\n",
      "indices=tensor([1448, 1060, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0979, 0.0671, 0.0510]),\n",
      "indices=tensor([1418, 1383, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0722, 0.0620, 0.0367]),\n",
      "indices=tensor([1395, 1154, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9860e-01, 1.7374e-04, 1.0841e-04]),\n",
      "indices=tensor([1383, 1403, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9890, 0.0025, 0.0023]),\n",
      "indices=tensor([1371, 1550, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9322e-01, 1.8792e-03, 4.5153e-04]),\n",
      "indices=tensor([1465, 1317, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0424, 0.0404, 0.0372]),\n",
      "indices=tensor([ 987, 1269, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0550, 0.0492, 0.0479]),\n",
      "indices=tensor([1496, 1308, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0748, 0.0646, 0.0406]),\n",
      "indices=tensor([1308,  941, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0653, 0.0479, 0.0378]),\n",
      "indices=tensor([1550, 1339, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0892, 0.0381, 0.0335]),\n",
      "indices=tensor([1448, 1248,  951]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7175, 0.0180, 0.0142]),\n",
      "indices=tensor([1218, 1397, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0956, 0.0682, 0.0468]),\n",
      "indices=tensor([1496, 1283, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1551, 0.0999, 0.0607]),\n",
      "indices=tensor([1421, 1438, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9311e-01, 3.8224e-03, 2.5683e-04]),\n",
      "indices=tensor([1219, 1255, 1291]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8519, 0.0627, 0.0044]),\n",
      "indices=tensor([1258, 1178, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2048, 0.0716, 0.0341]),\n",
      "indices=tensor([1152, 1139, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2752, 0.0541, 0.0536]),\n",
      "indices=tensor([1550, 1223, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9696, 0.0023, 0.0018]),\n",
      "indices=tensor([1398, 1338, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1143, 0.0410, 0.0408]),\n",
      "indices=tensor([1496, 1395, 1224]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2068, 0.1060, 0.0644]),\n",
      "indices=tensor([1421, 1496, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9876, 0.0031, 0.0010]),\n",
      "indices=tensor([1390, 1340, 1366]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9870, 0.0017, 0.0011]),\n",
      "indices=tensor([1343, 1453, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9997e-01, 4.3713e-06, 3.2335e-06]),\n",
      "indices=tensor([1436, 1438, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0799, 0.0793, 0.0485]),\n",
      "indices=tensor([1219, 1313,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2544, 0.0524, 0.0354]),\n",
      "indices=tensor([1359, 1327, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3538, 0.0368, 0.0311]),\n",
      "indices=tensor([1280, 1058, 1270]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1826, 0.0436, 0.0405]),\n",
      "indices=tensor([1445, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0570, 0.0504, 0.0489]),\n",
      "indices=tensor([1110, 1293, 1131]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0861, 0.0683, 0.0454]),\n",
      "indices=tensor([1213, 1112, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9788, 0.0016, 0.0011]),\n",
      "indices=tensor([1053, 1439, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9119, 0.0626, 0.0019]),\n",
      "indices=tensor([1350, 1375, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7979, 0.1634, 0.0034]),\n",
      "indices=tensor([1293, 1244, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0755, 0.0412, 0.0353]),\n",
      "indices=tensor([1357, 1308, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1139, 0.1056, 0.0673]),\n",
      "indices=tensor([1433, 1272, 1288]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0892, 0.0716, 0.0525]),\n",
      "indices=tensor([1308, 1460, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9664, 0.0229, 0.0011]),\n",
      "indices=tensor([1255, 1213, 1258]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0575, 0.0536, 0.0472]),\n",
      "indices=tensor([1112, 1196, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9723e-01, 5.8917e-04, 3.1155e-04]),\n",
      "indices=tensor([1180, 1347, 1398]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1484, 0.1384, 0.1220]),\n",
      "indices=tensor([1419, 1448, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9572, 0.0078, 0.0027]),\n",
      "indices=tensor([1227, 1297, 1243]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9830, 0.0016, 0.0010]),\n",
      "indices=tensor([1435,  988, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7342, 0.0193, 0.0167]),\n",
      "indices=tensor([1214, 1413,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9132e-01, 5.3815e-04, 4.0998e-04]),\n",
      "indices=tensor([1395, 1382, 1278]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7054, 0.0354, 0.0185]),\n",
      "indices=tensor([1407, 1380, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9996e-01, 5.5716e-06, 2.8837e-06]),\n",
      "indices=tensor([1354, 1530, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8757, 0.0108, 0.0094]),\n",
      "indices=tensor([1196, 1197, 1238]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9769, 0.0101, 0.0027]),\n",
      "indices=tensor([1471, 1413, 1288]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1904, 0.0489, 0.0382]),\n",
      "indices=tensor([1110, 1218, 1082]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9750, 0.0016, 0.0013]),\n",
      "indices=tensor([1359, 1522, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0508, 0.0386, 0.0332]),\n",
      "indices=tensor([1386, 1154, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9810e-01, 5.6060e-04, 1.0485e-04]),\n",
      "indices=tensor([1143, 1244, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8481, 0.0077, 0.0076]),\n",
      "indices=tensor([1132, 1196, 1514]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7215, 0.2034, 0.0065]),\n",
      "indices=tensor([1359, 1315, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1605, 0.0572, 0.0555]),\n",
      "indices=tensor([1438, 1496, 1209]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1428, 0.0719, 0.0581]),\n",
      "indices=tensor([1403, 1433, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5240, 0.0389, 0.0279]),\n",
      "indices=tensor([1313, 1338, 1347]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8585, 0.0200, 0.0082]),\n",
      "indices=tensor([1203, 1218, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8778e-01, 7.1264e-03, 3.1272e-04]),\n",
      "indices=tensor([1322, 1345,  985]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1760, 0.1141, 0.0337]),\n",
      "indices=tensor([1454, 1403, 1348]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1488, 0.0820, 0.0748]),\n",
      "indices=tensor([1439, 1317, 1479]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0750, 0.0600, 0.0536]),\n",
      "indices=tensor([1114, 1154, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0762, 0.0435, 0.0415]),\n",
      "indices=tensor([1152, 1067, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9766, 0.0025, 0.0024]),\n",
      "indices=tensor([1011, 1285,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9722, 0.0066, 0.0034]),\n",
      "indices=tensor([1350, 1433, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9541e-01, 3.8644e-04, 3.4371e-04]),\n",
      "indices=tensor([1355, 1448, 1480]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1886, 0.0504, 0.0492]),\n",
      "indices=tensor([1152, 1092, 1120]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0734, 0.0558, 0.0501]),\n",
      "indices=tensor([1375, 1321, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8738e-01, 1.5208e-03, 7.6458e-04]),\n",
      "indices=tensor([1401, 1455, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9757, 0.0119, 0.0019]),\n",
      "indices=tensor([1366, 1315, 1340]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5865, 0.0305, 0.0302]),\n",
      "indices=tensor([1197, 1410, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9759e-01, 1.3586e-04, 1.2161e-04]),\n",
      "indices=tensor([1134, 1126, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9695e-01, 6.5173e-04, 4.9926e-04]),\n",
      "indices=tensor([1265, 1317, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9981e-01, 9.2478e-05, 9.6795e-06]),\n",
      "indices=tensor([1189, 1156, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0762, 0.0480, 0.0363]),\n",
      "indices=tensor([1215, 1189, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9998e-01, 4.8630e-06, 2.1205e-06]),\n",
      "indices=tensor([1134, 1386, 1288]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9220e-01, 9.7533e-04, 5.2053e-04]),\n",
      "indices=tensor([1426, 1344,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9973e-01, 3.0964e-05, 2.1672e-05]),\n",
      "indices=tensor([1067, 1152,  930]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9613e-01, 5.2398e-04, 4.1244e-04]),\n",
      "indices=tensor([1475, 1440, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0698, 0.0646, 0.0431]),\n",
      "indices=tensor([1330, 1058, 1297]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5748, 0.0340, 0.0205]),\n",
      "indices=tensor([1485, 1494, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4450, 0.0511, 0.0379]),\n",
      "indices=tensor([1292, 1341, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9986e-01, 1.7746e-05, 1.3094e-05]),\n",
      "indices=tensor([1403, 1429, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9747, 0.0013, 0.0010]),\n",
      "indices=tensor([1224, 1178, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9661e-01, 1.9663e-03, 1.3034e-04]),\n",
      "indices=tensor([1048, 1332, 1270]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1954, 0.0770, 0.0354]),\n",
      "indices=tensor([1496, 1317, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8927, 0.0090, 0.0046]),\n",
      "indices=tensor([1243, 1179, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0724, 0.0440, 0.0323]),\n",
      "indices=tensor([1145, 1492, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7440, 0.1391, 0.0247]),\n",
      "indices=tensor([1437, 1397, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0703, 0.0622, 0.0469]),\n",
      "indices=tensor([1406, 1196, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1118, 0.1001, 0.0421]),\n",
      "indices=tensor([1243, 1395, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0836, 0.0507, 0.0425]),\n",
      "indices=tensor([1433, 1233, 1192]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9280, 0.0092, 0.0090]),\n",
      "indices=tensor([1419, 1285, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5629, 0.0328, 0.0262]),\n",
      "indices=tensor([1223, 1288, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0768, 0.0390, 0.0378]),\n",
      "indices=tensor([ 946, 1238, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1002, 0.0868, 0.0761]),\n",
      "indices=tensor([1421, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6774, 0.0213, 0.0140]),\n",
      "indices=tensor([1420, 1403, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0798, 0.0453, 0.0307]),\n",
      "indices=tensor([1403, 1223, 1304]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9966e-01, 1.4828e-04, 4.3130e-05]),\n",
      "indices=tensor([1346, 1202, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0566, 0.0468, 0.0393]),\n",
      "indices=tensor([1218, 1345, 1500]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0863, 0.0534, 0.0428]),\n",
      "indices=tensor([1112, 1674, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7298, 0.0207, 0.0104]),\n",
      "indices=tensor([1196, 1437, 1227]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0905, 0.0693, 0.0685]),\n",
      "indices=tensor([1387, 1383, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4945, 0.0418, 0.0349]),\n",
      "indices=tensor([1370, 1415, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1613, 0.1372, 0.1085]),\n",
      "indices=tensor([1413, 1496, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7332, 0.2048, 0.0094]),\n",
      "indices=tensor([1391, 1454, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9744e-01, 2.9944e-04, 2.3352e-04]),\n",
      "indices=tensor([1309, 1410, 1419]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8893e-01, 7.8094e-04, 5.9614e-04]),\n",
      "indices=tensor([1315, 1156, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3063, 0.0301, 0.0270]),\n",
      "indices=tensor([1310, 1233, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4697, 0.0270, 0.0246]),\n",
      "indices=tensor([1315, 1277,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9579, 0.0059, 0.0039]),\n",
      "indices=tensor([1266, 1212, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8504e-01, 8.8300e-04, 8.6887e-04]),\n",
      "indices=tensor([1156, 1154, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0488, 0.0415, 0.0389]),\n",
      "indices=tensor([1214,  970, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7450e-01, 1.8297e-02, 7.4655e-04]),\n",
      "indices=tensor([1248, 1280, 1202]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0659, 0.0641, 0.0479]),\n",
      "indices=tensor([1460, 1395, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8612, 0.0127, 0.0077]),\n",
      "indices=tensor([1280, 1202, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1872, 0.0435, 0.0361]),\n",
      "indices=tensor([1058, 1178,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9763e-01, 5.8781e-04, 1.3157e-04]),\n",
      "indices=tensor([1548, 1413, 1366]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2691, 0.0892, 0.0509]),\n",
      "indices=tensor([1395, 1380, 1123]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9979e-01, 1.6868e-05, 1.4015e-05]),\n",
      "indices=tensor([1330, 1380, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1525, 0.0507, 0.0494]),\n",
      "indices=tensor([1437, 1465, 1223]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.2064, 0.0860, 0.0734]),\n",
      "indices=tensor([1421, 1438, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2644, 0.0539, 0.0451]),\n",
      "indices=tensor([1390, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3324, 0.0487, 0.0423]),\n",
      "indices=tensor([1493, 1393, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1197, 0.0590, 0.0527]),\n",
      "indices=tensor([1123, 1218, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9827, 0.0081, 0.0029]),\n",
      "indices=tensor([1436, 1413, 1398]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0795, 0.0473, 0.0453]),\n",
      "indices=tensor([1403, 1329, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.2555e-01, 7.1943e-02, 3.6012e-04]),\n",
      "indices=tensor([1219, 1284, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0658, 0.0534, 0.0513]),\n",
      "indices=tensor([1203, 1345, 1389]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9551e-01, 3.6311e-04, 2.0779e-04]),\n",
      "indices=tensor([1243, 1309,  983]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4176, 0.0398, 0.0303]),\n",
      "indices=tensor([1435, 1060, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9741, 0.0045, 0.0022]),\n",
      "indices=tensor([1265, 1273, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0988, 0.0542, 0.0522]),\n",
      "indices=tensor([1313,  946, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1197, 0.1015, 0.0444]),\n",
      "indices=tensor([1403, 1395, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8679, 0.0140, 0.0091]),\n",
      "indices=tensor([1048, 1123, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9791e-01, 4.2112e-04, 2.1281e-04]),\n",
      "indices=tensor([1438, 1440, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9490e-01, 1.7056e-03, 2.0193e-04]),\n",
      "indices=tensor([1215, 1413, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1327, 0.0592, 0.0443]),\n",
      "indices=tensor([1395, 1460, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0839, 0.0526, 0.0456]),\n",
      "indices=tensor([1382, 1400, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1032, 0.0593, 0.0483]),\n",
      "indices=tensor([1112, 1178,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0872, 0.0595, 0.0363]),\n",
      "indices=tensor([1460, 1283, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9373, 0.0443, 0.0039]),\n",
      "indices=tensor([1327, 1359, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2479, 0.1241, 0.0337]),\n",
      "indices=tensor([1382, 1376, 1273]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5691, 0.0473, 0.0131]),\n",
      "indices=tensor([1500, 1439, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0516, 0.0469, 0.0393]),\n",
      "indices=tensor([1047, 1154, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3615, 0.1034, 0.0388]),\n",
      "indices=tensor([1500, 1437, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1112, 0.0857, 0.0666]),\n",
      "indices=tensor([1387, 1168, 1194]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0925, 0.0916, 0.0683]),\n",
      "indices=tensor([1417, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0483, 0.0405, 0.0381]),\n",
      "indices=tensor([1152, 1110, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9356e-01, 5.3982e-04, 5.1935e-04]),\n",
      "indices=tensor([1425, 1164, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1035, 0.0723, 0.0461]),\n",
      "indices=tensor([1445, 1489, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9215e-01, 4.1649e-03, 8.1817e-04]),\n",
      "indices=tensor([1325, 1295, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9359e-01, 5.0187e-04, 3.2904e-04]),\n",
      "indices=tensor([1332, 1323, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1477, 0.1168, 0.0388]),\n",
      "indices=tensor([1341, 1303, 1385]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9468, 0.0067, 0.0030]),\n",
      "indices=tensor([1044, 1674, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0625, 0.0565, 0.0390]),\n",
      "indices=tensor([1154, 1386, 1209]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8606, 0.0406, 0.0068]),\n",
      "indices=tensor([1223, 1288, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7791, 0.0102, 0.0100]),\n",
      "indices=tensor([1435, 1038, 1164]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8022, 0.0604, 0.0134]),\n",
      "indices=tensor([1380, 1313, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1174, 0.0850, 0.0632]),\n",
      "indices=tensor([1403, 1433, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9894e-01, 8.6805e-05, 8.4926e-05]),\n",
      "indices=tensor([1530, 1460, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000e+00, 6.6035e-07, 2.9436e-07]),\n",
      "indices=tensor([ 927, 1284, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0563, 0.0520, 0.0477]),\n",
      "indices=tensor([1460, 1308,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1125, 0.0454, 0.0437]),\n",
      "indices=tensor([1448, 1131, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8420e-01, 9.7039e-04, 9.3828e-04]),\n",
      "indices=tensor([1196, 1293, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1885, 0.0585, 0.0378]),\n",
      "indices=tensor([1496, 1317, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9610, 0.0041, 0.0031]),\n",
      "indices=tensor([1462, 1498, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9179e-01, 1.0605e-03, 5.8032e-04]),\n",
      "indices=tensor([1045, 1058, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9385e-01, 3.4120e-04, 3.4101e-04]),\n",
      "indices=tensor([1355, 1480, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8550, 0.0989, 0.0026]),\n",
      "indices=tensor([1377, 1319, 1376]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0499, 0.0495, 0.0481]),\n",
      "indices=tensor([1674, 1154, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1747, 0.0690, 0.0621]),\n",
      "indices=tensor([1403, 1400, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5923, 0.0390, 0.0362]),\n",
      "indices=tensor([1408, 1375, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9732e-01, 2.3676e-04, 1.6624e-04]),\n",
      "indices=tensor([1486, 1437, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0962, 0.0834, 0.0766]),\n",
      "indices=tensor([1357, 1276, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9777, 0.0067, 0.0031]),\n",
      "indices=tensor([1193, 1346, 1243]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7777, 0.0123, 0.0080]),\n",
      "indices=tensor([1301, 1309, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7841, 0.1660, 0.0064]),\n",
      "indices=tensor([1315, 1341, 1156]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9470, 0.0064, 0.0022]),\n",
      "indices=tensor([1347, 1448, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0937, 0.0573, 0.0366]),\n",
      "indices=tensor([1421, 1329, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9823e-01, 1.4608e-03, 1.9619e-05]),\n",
      "indices=tensor([1425, 1435, 1480]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9796, 0.0087, 0.0019]),\n",
      "indices=tensor([1446, 1486, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0922, 0.0779, 0.0696]),\n",
      "indices=tensor([1403, 1447, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0895, 0.0449, 0.0432]),\n",
      "indices=tensor([1479, 1209, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4960, 0.0651, 0.0243]),\n",
      "indices=tensor([1421, 1496, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0422, 0.0408, 0.0356]),\n",
      "indices=tensor([1112, 1492, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9985e-01, 2.2912e-05, 1.3259e-05]),\n",
      "indices=tensor([1081, 1168, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9936e-01, 1.1059e-04, 9.6048e-05]),\n",
      "indices=tensor([ 986, 1123, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1200, 0.0977, 0.0465]),\n",
      "indices=tensor([1403, 1445, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0853, 0.0771, 0.0704]),\n",
      "indices=tensor([1493, 1380, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1848, 0.1166, 0.0689]),\n",
      "indices=tensor([1218, 1112, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1358, 0.0646, 0.0380]),\n",
      "indices=tensor([1395, 1445, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9130, 0.0090, 0.0079]),\n",
      "indices=tensor([ 996, 1152, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5601, 0.0390, 0.0264]),\n",
      "indices=tensor([1438, 1214, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0667, 0.0495, 0.0485]),\n",
      "indices=tensor([1233, 1389, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0592, 0.0590, 0.0493]),\n",
      "indices=tensor([1308, 1340, 1022]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1613, 0.0492, 0.0449]),\n",
      "indices=tensor([1448, 1437, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9760e-01, 3.7067e-04, 1.0498e-04]),\n",
      "indices=tensor([1377, 1387, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1003, 0.0791, 0.0448]),\n",
      "indices=tensor([1357, 1403, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0779, 0.0412, 0.0411]),\n",
      "indices=tensor([1145, 1258,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0942, 0.0792, 0.0618]),\n",
      "indices=tensor([1446, 1308, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000e+00, 6.2291e-07, 4.4495e-07]),\n",
      "indices=tensor([ 927, 1284, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9631, 0.0022, 0.0021]),\n",
      "indices=tensor([1426, 1145, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0811, 0.0779, 0.0653]),\n",
      "indices=tensor([1445, 1313, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0463, 0.0402, 0.0323]),\n",
      "indices=tensor([1486, 1448, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5398, 0.0319, 0.0241]),\n",
      "indices=tensor([1309, 1393, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9969e-01, 6.2517e-05, 4.4291e-05]),\n",
      "indices=tensor([1346, 1202, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7531, 0.0593, 0.0096]),\n",
      "indices=tensor([1414, 1413, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1385, 0.1147, 0.1022]),\n",
      "indices=tensor([1331, 1380, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9252, 0.0043, 0.0038]),\n",
      "indices=tensor([1238, 1329, 1378]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9856e-01, 8.0758e-05, 6.2936e-05]),\n",
      "indices=tensor([1395, 1403, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9909e-01, 1.0594e-04, 6.8396e-05]),\n",
      "indices=tensor([1435, 1203, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.4579e-01, 5.1188e-02, 3.4633e-04]),\n",
      "indices=tensor([1255, 1292, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1445, 0.0557, 0.0545]),\n",
      "indices=tensor([1301, 1383, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7308, 0.0178, 0.0091]),\n",
      "indices=tensor([1145, 1154, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9746, 0.0109, 0.0021]),\n",
      "indices=tensor([1252, 1282, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0984, 0.0801, 0.0742]),\n",
      "indices=tensor([1393, 1445, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0503, 0.0463, 0.0411]),\n",
      "indices=tensor([1277, 1272,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1411, 0.0485, 0.0469]),\n",
      "indices=tensor([1382, 1268, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9247, 0.0065, 0.0052]),\n",
      "indices=tensor([1500, 1674, 1178]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.9549, 0.0159, 0.0017]),\n",
      "indices=tensor([1387, 1348, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9998e-01, 2.3651e-06, 1.7568e-06]),\n",
      "indices=tensor([ 800, 1053, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6957, 0.2313, 0.0086]),\n",
      "indices=tensor([1394, 1480, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0873, 0.0724, 0.0550]),\n",
      "indices=tensor([1126, 1154, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8905e-01, 1.1133e-03, 6.5192e-04]),\n",
      "indices=tensor([1011, 1395, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7355e-01, 3.3051e-03, 9.1259e-04]),\n",
      "indices=tensor([1387, 1348, 1446]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9941e-01, 8.7764e-05, 6.0823e-05]),\n",
      "indices=tensor([1370, 1415, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0878, 0.0760, 0.0629]),\n",
      "indices=tensor([1313,  996, 1219]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5869, 0.2444, 0.0120]),\n",
      "indices=tensor([1437, 1448, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7084, 0.0302, 0.0146]),\n",
      "indices=tensor([1276, 1357, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9813e-01, 5.1709e-04, 1.5862e-04]),\n",
      "indices=tensor([1548, 1413, 1366]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6674, 0.2828, 0.0071]),\n",
      "indices=tensor([1269, 1293, 1346]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9862, 0.0058, 0.0017]),\n",
      "indices=tensor([1356, 1313, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9883e-01, 5.2707e-04, 6.1216e-05]),\n",
      "indices=tensor([1392, 1308, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8239, 0.0155, 0.0121]),\n",
      "indices=tensor([1284, 1274, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9429e-01, 8.0682e-04, 5.3010e-04]),\n",
      "indices=tensor([1053, 1500, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9805e-01, 7.6252e-04, 3.8487e-04]),\n",
      "indices=tensor([1438, 1393, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000e+00, 5.6213e-07, 2.6697e-07]),\n",
      "indices=tensor([1240, 1186, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1095, 0.0529, 0.0522]),\n",
      "indices=tensor([1345, 1230, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0892, 0.0820, 0.0631]),\n",
      "indices=tensor([1452, 1496, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0673, 0.0425, 0.0411]),\n",
      "indices=tensor([1243, 1110, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0573, 0.0492, 0.0470]),\n",
      "indices=tensor([ 941, 1493, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0688, 0.0557, 0.0506]),\n",
      "indices=tensor([1058, 1126, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0808, 0.0465, 0.0379]),\n",
      "indices=tensor([1380, 1421, 1409]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0473, 0.0460, 0.0444]),\n",
      "indices=tensor([1438, 1496, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9010, 0.0652, 0.0032]),\n",
      "indices=tensor([ 996, 1196, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0380, 0.0293, 0.0290]),\n",
      "indices=tensor([1053, 1445, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9195, 0.0251, 0.0061]),\n",
      "indices=tensor([1400, 1252, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9955, 0.0018, 0.0013]),\n",
      "indices=tensor([1346, 1359, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0377, 0.0354, 0.0344]),\n",
      "indices=tensor([1202, 1131, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0463, 0.0429, 0.0424]),\n",
      "indices=tensor([1288, 1448, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9571, 0.0066, 0.0038]),\n",
      "indices=tensor([1374, 1397, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9786, 0.0017, 0.0016]),\n",
      "indices=tensor([1284, 1339, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9236e-01, 5.7556e-04, 4.7985e-04]),\n",
      "indices=tensor([1045, 1472,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1521, 0.0561, 0.0458]),\n",
      "indices=tensor([1489, 1359, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9822, 0.0016, 0.0014]),\n",
      "indices=tensor([1428, 1496, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6421, 0.2484, 0.0085]),\n",
      "indices=tensor([1178, 1258, 1123]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0550, 0.0479, 0.0380]),\n",
      "indices=tensor([1382, 1244, 1500]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9694e-01, 1.9094e-04, 1.7097e-04]),\n",
      "indices=tensor([1394, 1397, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9512e-01, 1.9384e-03, 6.8711e-04]),\n",
      "indices=tensor([1252, 1406, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1100, 0.0495, 0.0487]),\n",
      "indices=tensor([1313, 1213, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8842, 0.0733, 0.0105]),\n",
      "indices=tensor([1321, 1274, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0887, 0.0411, 0.0371]),\n",
      "indices=tensor([1145,  970, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1794, 0.0498, 0.0355]),\n",
      "indices=tensor([ 941, 1192, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0912, 0.0710, 0.0658]),\n",
      "indices=tensor([1433, 1396, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0912, 0.0812, 0.0655]),\n",
      "indices=tensor([1674, 1433, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9216, 0.0097, 0.0097]),\n",
      "indices=tensor([1244, 1270, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1902, 0.1512, 0.0623]),\n",
      "indices=tensor([1092, 1355, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0570, 0.0506, 0.0411]),\n",
      "indices=tensor([1045, 1053,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8964e-01, 1.0945e-03, 7.1989e-04]),\n",
      "indices=tensor([1338, 1403, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5362, 0.1597, 0.0278]),\n",
      "indices=tensor([1421, 1403, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0922, 0.0692, 0.0486]),\n",
      "indices=tensor([1550, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9846, 0.0021, 0.0020]),\n",
      "indices=tensor([1031, 1218, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0733, 0.0406, 0.0363]),\n",
      "indices=tensor([1440, 1382, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9265, 0.0088, 0.0048]),\n",
      "indices=tensor([1409, 1421, 1396]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9568e-01, 4.3603e-04, 4.1007e-04]),\n",
      "indices=tensor([1053, 1439, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0653, 0.0442, 0.0385]),\n",
      "indices=tensor([1310, 1262, 1322]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8858, 0.0686, 0.0033]),\n",
      "indices=tensor([1231, 1244, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0722, 0.0478, 0.0413]),\n",
      "indices=tensor([1380, 1178, 1039]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0441, 0.0432, 0.0393]),\n",
      "indices=tensor([1045, 1330, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9230e-01, 9.5633e-04, 7.2540e-04]),\n",
      "indices=tensor([1383, 1112, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1244, 0.0978, 0.0515]),\n",
      "indices=tensor([1394, 1355, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2602, 0.0769, 0.0521]),\n",
      "indices=tensor([1123, 1112, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9528e-01, 6.0725e-04, 3.5796e-04]),\n",
      "indices=tensor([1110, 1168, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6900, 0.0270, 0.0236]),\n",
      "indices=tensor([1379, 1380, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9513, 0.0044, 0.0038]),\n",
      "indices=tensor([1276, 1395, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9779e-01, 5.0281e-04, 2.8598e-04]),\n",
      "indices=tensor([1317, 1252, 1269]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3613, 0.0535, 0.0482]),\n",
      "indices=tensor([1489, 1415, 1419]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1541, 0.1146, 0.0770]),\n",
      "indices=tensor([1407, 1453, 1266]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9972e-01, 4.9543e-05, 3.5327e-05]),\n",
      "indices=tensor([1480, 1448, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7329, 0.0580, 0.0136]),\n",
      "indices=tensor([1406, 1403, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3160, 0.1038, 0.0340]),\n",
      "indices=tensor([1319, 1446, 1344]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9862e-01, 4.0125e-04, 1.1473e-04]),\n",
      "indices=tensor([1407, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7659, 0.0232, 0.0193]),\n",
      "indices=tensor([ 208, 1213, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9107, 0.0725, 0.0081]),\n",
      "indices=tensor([1440, 1498, 1436]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4827, 0.1950, 0.0336]),\n",
      "indices=tensor([1462, 1445, 1419]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2908, 0.0702, 0.0691]),\n",
      "indices=tensor([1397, 1022, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9519, 0.0079, 0.0033]),\n",
      "indices=tensor([ 996, 1039, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1006, 0.0717, 0.0538]),\n",
      "indices=tensor([1357, 1244, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9797, 0.0018, 0.0017]),\n",
      "indices=tensor([1380, 1308, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0880, 0.0752, 0.0557]),\n",
      "indices=tensor([1284, 1339, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9260e-01, 1.3012e-03, 4.0180e-04]),\n",
      "indices=tensor([1194, 1387, 1379]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1200, 0.0331, 0.0329]),\n",
      "indices=tensor([1164,  983, 1114]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9440, 0.0120, 0.0080]),\n",
      "indices=tensor([1408, 1308,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9067, 0.0114, 0.0092]),\n",
      "indices=tensor([1319, 1400, 1446]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9770, 0.0066, 0.0019]),\n",
      "indices=tensor([1291, 1310, 1186]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9176, 0.0455, 0.0038]),\n",
      "indices=tensor([1293, 1243, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1141, 0.0783, 0.0662]),\n",
      "indices=tensor([1460, 1448, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7964, 0.0091, 0.0086]),\n",
      "indices=tensor([1341, 1448, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0910, 0.0522, 0.0399]),\n",
      "indices=tensor([1112, 1096, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0917, 0.0607, 0.0438]),\n",
      "indices=tensor([1218, 1339, 1060]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9979e-01, 2.4789e-05, 1.1473e-05]),\n",
      "indices=tensor([1268, 1454, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9989e-01, 3.9014e-05, 1.4809e-05]),\n",
      "indices=tensor([1405, 1448, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000e+00, 5.3673e-08, 4.2736e-08]),\n",
      "indices=tensor([ 208, 1317, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0999, 0.0540, 0.0531]),\n",
      "indices=tensor([1394, 1429, 1417]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9424, 0.0053, 0.0028]),\n",
      "indices=tensor([1114, 1178, 1166]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9966e-01, 4.4519e-05, 3.1227e-05]),\n",
      "indices=tensor([1219, 1403, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4936, 0.0439, 0.0356]),\n",
      "indices=tensor([1081, 1223, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9648e-01, 1.0723e-03, 5.3772e-04]),\n",
      "indices=tensor([1143, 1244, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9757, 0.0019, 0.0018]),\n",
      "indices=tensor([1431, 1674, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1574, 0.0964, 0.0339]),\n",
      "indices=tensor([1403, 1395, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2558, 0.0666, 0.0630]),\n",
      "indices=tensor([1186, 1213, 1219]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9303e-01, 1.5507e-03, 5.5764e-04]),\n",
      "indices=tensor([1283, 1273, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3452, 0.0541, 0.0333]),\n",
      "indices=tensor([1030, 1178, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9774e-01, 9.9825e-04, 5.8030e-04]),\n",
      "indices=tensor([1297, 1447, 1356]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0506, 0.0489, 0.0415]),\n",
      "indices=tensor([1209, 1376, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9117e-01, 8.8159e-04, 5.1575e-04]),\n",
      "indices=tensor([1419, 1139, 1309]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0730, 0.0540, 0.0407]),\n",
      "indices=tensor([1310, 1308, 1152]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([9.9922e-01, 1.9848e-04, 8.9344e-05]),\n",
      "indices=tensor([1058, 1439, 1063]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9996e-01, 4.5682e-06, 4.2573e-06]),\n",
      "indices=tensor([1197, 1454, 1209]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0766, 0.0727, 0.0725]),\n",
      "indices=tensor([1255, 1500, 1393]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3804, 0.1087, 0.0453]),\n",
      "indices=tensor([1395, 1390, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9118, 0.0062, 0.0052]),\n",
      "indices=tensor([1380, 1214, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9302, 0.0059, 0.0048]),\n",
      "indices=tensor([1357, 1112, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9948e-01, 9.6539e-05, 7.2090e-05]),\n",
      "indices=tensor([1288, 1403, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9070e-01, 4.8490e-04, 4.5428e-04]),\n",
      "indices=tensor([1278, 1262, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9849, 0.0024, 0.0020]),\n",
      "indices=tensor([1252, 1460, 1296]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0893, 0.0540, 0.0498]),\n",
      "indices=tensor([1382, 1131,  986]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9864e-01, 2.0117e-04, 1.1305e-04]),\n",
      "indices=tensor([1081, 1277, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9786, 0.0017, 0.0010]),\n",
      "indices=tensor([1319, 1448, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1634, 0.0765, 0.0730]),\n",
      "indices=tensor([1343, 1403, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0404, 0.0320, 0.0313]),\n",
      "indices=tensor([1154, 1438, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9906e-01, 4.3673e-04, 9.8095e-05]),\n",
      "indices=tensor([1440, 1438, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9340, 0.0129, 0.0101]),\n",
      "indices=tensor([1493, 1522, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4053, 0.0981, 0.0322]),\n",
      "indices=tensor([1343, 1413, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0388, 0.0387, 0.0361]),\n",
      "indices=tensor([1357, 1445, 1371]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0763, 0.0534, 0.0478]),\n",
      "indices=tensor([1400, 1499,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0732, 0.0656, 0.0626]),\n",
      "indices=tensor([1321, 1375, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9820e-01, 1.0583e-03, 1.6092e-04]),\n",
      "indices=tensor([1273, 1413, 1310]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9105e-01, 7.5745e-04, 5.5368e-04]),\n",
      "indices=tensor([1280, 1321, 1297]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9737e-01, 2.4967e-04, 2.3637e-04]),\n",
      "indices=tensor([1408, 1485, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8413, 0.1107, 0.0060]),\n",
      "indices=tensor([1492, 1437, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9745e-01, 6.5358e-04, 1.2540e-04]),\n",
      "indices=tensor([1321, 1383, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9667e-01, 5.3218e-04, 2.7822e-04]),\n",
      "indices=tensor([1110,  941, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1098, 0.0401, 0.0392]),\n",
      "indices=tensor([1218, 1403, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8265, 0.0167, 0.0136]),\n",
      "indices=tensor([ 287, 1112, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9936e-01, 4.4651e-05, 3.3155e-05]),\n",
      "indices=tensor([1167,  941, 1514]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0777, 0.0600, 0.0536]),\n",
      "indices=tensor([1315, 1223, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0791, 0.0717, 0.0527]),\n",
      "indices=tensor([1031, 1112, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9084, 0.0417, 0.0052]),\n",
      "indices=tensor([1058, 1045, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1266, 0.0906, 0.0332]),\n",
      "indices=tensor([1380, 1448, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2882, 0.0371, 0.0365]),\n",
      "indices=tensor([1092, 1321, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9588, 0.0313, 0.0010]),\n",
      "indices=tensor([927, 988, 986]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9467, 0.0032, 0.0029]),\n",
      "indices=tensor([1039, 1178, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0694, 0.0548, 0.0486]),\n",
      "indices=tensor([1283, 1357, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0757, 0.0537, 0.0421]),\n",
      "indices=tensor([1112, 1213, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9692e-01, 5.5214e-04, 2.2688e-04]),\n",
      "indices=tensor([1383, 1403, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3493, 0.0659, 0.0610]),\n",
      "indices=tensor([1391, 1315, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9605e-01, 5.7056e-04, 4.0833e-04]),\n",
      "indices=tensor([1297, 1362, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9691, 0.0022, 0.0021]),\n",
      "indices=tensor([ 951, 1053, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0862, 0.0555, 0.0487]),\n",
      "indices=tensor([1218, 1283, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8044e-01, 1.2079e-03, 8.5328e-04]),\n",
      "indices=tensor([1060, 1112, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8388, 0.0065, 0.0063]),\n",
      "indices=tensor([1500, 1486, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8669, 0.0211, 0.0072]),\n",
      "indices=tensor([1386, 1403, 1408]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0722, 0.0474, 0.0422]),\n",
      "indices=tensor([1448, 1383, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9177e-01, 2.9312e-03, 3.4194e-04]),\n",
      "indices=tensor([1276, 1308, 1092]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1427, 0.1000, 0.0624]),\n",
      "indices=tensor([1265, 1403, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9549e-01, 2.2634e-03, 4.5954e-04]),\n",
      "indices=tensor([1355, 1297, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5539, 0.0532, 0.0276]),\n",
      "indices=tensor([1385, 1350, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4319, 0.3843, 0.0178]),\n",
      "indices=tensor([1168, 1203, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9750e-01, 1.8417e-04, 1.3470e-04]),\n",
      "indices=tensor([1446, 1248, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9973e-01, 5.4100e-05, 1.4523e-05]),\n",
      "indices=tensor([1479, 1413, 1288]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8101, 0.0667, 0.0086]),\n",
      "indices=tensor([1447, 1411, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0427, 0.0316, 0.0315]),\n",
      "indices=tensor([1496, 1154, 1048]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8842e-01, 2.2844e-03, 8.3771e-04]),\n",
      "indices=tensor([1455, 1485, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6026, 0.0614, 0.0414]),\n",
      "indices=tensor([1288, 1223, 1272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0586, 0.0547, 0.0491]),\n",
      "indices=tensor([1339, 1313, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9646e-01, 1.4813e-03, 1.0939e-04]),\n",
      "indices=tensor([1386, 1418, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9738e-01, 6.2146e-04, 3.7051e-04]),\n",
      "indices=tensor([1438, 1440, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9462e-01, 5.8013e-04, 4.3600e-04]),\n",
      "indices=tensor([1379,  996, 1202]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0457, 0.0406, 0.0310]),\n",
      "indices=tensor([1288, 1238, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9352, 0.0345, 0.0059]),\n",
      "indices=tensor([1194, 1132,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0884, 0.0592, 0.0462]),\n",
      "indices=tensor([1460, 1154, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6277, 0.0351, 0.0292]),\n",
      "indices=tensor([1308,  941, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9730, 0.0121, 0.0023]),\n",
      "indices=tensor([1391, 1445, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9934, 0.0015, 0.0013]),\n",
      "indices=tensor([1155, 1126, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9636e-01, 2.0604e-03, 1.1937e-04]),\n",
      "indices=tensor([1319, 1357, 1390]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9782, 0.0018, 0.0012]),\n",
      "indices=tensor([1344, 1489, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9450, 0.0245, 0.0031]),\n",
      "indices=tensor([1038,  987, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2056, 0.0624, 0.0405]),\n",
      "indices=tensor([1323, 1395, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7675, 0.0118, 0.0117]),\n",
      "indices=tensor([1462, 1499, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3857, 0.0259, 0.0231]),\n",
      "indices=tensor([1341, 1303, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9531, 0.0110, 0.0110]),\n",
      "indices=tensor([1339, 1421, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6455, 0.0231, 0.0230]),\n",
      "indices=tensor([1286, 1031, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9049e-01, 1.3197e-03, 7.6171e-04]),\n",
      "indices=tensor([1433, 1496, 1396]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9636, 0.0056, 0.0014]),\n",
      "indices=tensor([1315, 1277, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1049, 0.0419, 0.0378]),\n",
      "indices=tensor([1145, 1086, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9321, 0.0148, 0.0081]),\n",
      "indices=tensor([1252, 1413, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0872, 0.0748, 0.0583]),\n",
      "indices=tensor([1448, 1058, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4840, 0.0399, 0.0231]),\n",
      "indices=tensor([1433, 1357, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0901, 0.0631, 0.0528]),\n",
      "indices=tensor([1114, 1218, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9969e-01, 1.7070e-05, 1.5180e-05]),\n",
      "indices=tensor([1086, 1053, 1060]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9533, 0.0067, 0.0040]),\n",
      "indices=tensor([1326, 1496, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0606, 0.0560, 0.0487]),\n",
      "indices=tensor([1438, 1489, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0570, 0.0489, 0.0416]),\n",
      "indices=tensor([1284, 1321, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5302, 0.0257, 0.0200]),\n",
      "indices=tensor([1082, 1674, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0954, 0.0475, 0.0435]),\n",
      "indices=tensor([1230, 1112, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9022, 0.0496, 0.0090]),\n",
      "indices=tensor([1284, 1186, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0643, 0.0586, 0.0536]),\n",
      "indices=tensor([1293, 1243, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9618e-01, 1.4515e-03, 5.0406e-04]),\n",
      "indices=tensor([1440, 1380, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9988e-01, 5.3120e-05, 1.0042e-05]),\n",
      "indices=tensor([1232, 1326, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5642, 0.2711, 0.0218]),\n",
      "indices=tensor([1359, 1411, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9876e-01, 1.3537e-04, 1.1676e-04]),\n",
      "indices=tensor([1330, 1223, 1378]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0622, 0.0417, 0.0409]),\n",
      "indices=tensor([1117, 1196, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9960e-01, 6.8182e-05, 3.5981e-05]),\n",
      "indices=tensor([1641, 1550, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9150e-01, 7.0622e-04, 6.2829e-04]),\n",
      "indices=tensor([1011, 1377, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9875, 0.0022, 0.0011]),\n",
      "indices=tensor([1411, 1403, 1438]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.2144, 0.0665, 0.0659]),\n",
      "indices=tensor([1426, 1445, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8586, 0.0399, 0.0268]),\n",
      "indices=tensor([1435, 1421, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0988, 0.0628, 0.0588]),\n",
      "indices=tensor([1209, 1380, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8755, 0.0683, 0.0019]),\n",
      "indices=tensor([1398, 1347, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9994e-01, 5.0177e-06, 4.8211e-06]),\n",
      "indices=tensor([ 287, 1112, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9798, 0.0021, 0.0017]),\n",
      "indices=tensor([1406, 1350, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9412e-01, 3.3560e-04, 3.1809e-04]),\n",
      "indices=tensor([1243, 1134, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8728, 0.0116, 0.0049]),\n",
      "indices=tensor([1380, 1421, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1042, 0.0489, 0.0390]),\n",
      "indices=tensor([1407, 1465, 1288]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9779e-01, 2.0871e-04, 1.9790e-04]),\n",
      "indices=tensor([1433, 1496, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9144, 0.0391, 0.0221]),\n",
      "indices=tensor([1485, 1446, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9632, 0.0030, 0.0019]),\n",
      "indices=tensor([1397, 1437, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9430, 0.0167, 0.0035]),\n",
      "indices=tensor([1357, 1386, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9807e-01, 2.9642e-04, 2.3783e-04]),\n",
      "indices=tensor([1142, 1283, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9973e-01, 6.0689e-05, 2.1580e-05]),\n",
      "indices=tensor([1142, 1308, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9922e-01, 5.7999e-05, 4.1140e-05]),\n",
      "indices=tensor([1215, 1548, 1366]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9667, 0.0025, 0.0018]),\n",
      "indices=tensor([1196, 1437, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9724e-01, 1.6752e-04, 1.5002e-04]),\n",
      "indices=tensor([ 988, 1031, 1273]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0383, 0.0381, 0.0376]),\n",
      "indices=tensor([1395, 1376, 1371]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1512, 0.0641, 0.0489]),\n",
      "indices=tensor([1460, 1067, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7925, 0.0083, 0.0069]),\n",
      "indices=tensor([1415, 1308, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7519e-01, 1.2640e-03, 7.4385e-04]),\n",
      "indices=tensor([1341, 1053, 1120]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1243, 0.0950, 0.0926]),\n",
      "indices=tensor([1403, 1359, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9297, 0.0122, 0.0057]),\n",
      "indices=tensor([1278, 1197, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9915, 0.0017, 0.0010]),\n",
      "indices=tensor([1009, 1410, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5678, 0.0746, 0.0289]),\n",
      "indices=tensor([1448, 1641, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6833, 0.1195, 0.0310]),\n",
      "indices=tensor([1252, 1233, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1006, 0.0729, 0.0395]),\n",
      "indices=tensor([1346, 1126, 1301]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0604, 0.0397, 0.0394]),\n",
      "indices=tensor([1330,  996, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9981e-01, 3.0332e-05, 1.9165e-05]),\n",
      "indices=tensor([1255, 1292, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2891, 0.1455, 0.1163]),\n",
      "indices=tensor([1436, 1413, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8685, 0.0073, 0.0068]),\n",
      "indices=tensor([1215, 1227, 1325]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0774, 0.0531, 0.0428]),\n",
      "indices=tensor([1308, 1382, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0508, 0.0500, 0.0372]),\n",
      "indices=tensor([1382, 1357, 1498]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4191, 0.0864, 0.0250]),\n",
      "indices=tensor([1248, 1297, 1238]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9996e-01, 3.9686e-06, 2.8141e-06]),\n",
      "indices=tensor([1296, 1196, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0729, 0.0591, 0.0533]),\n",
      "indices=tensor([1230, 1269, 1389]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3157, 0.2602, 0.0168]),\n",
      "indices=tensor([1439, 1500, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0742, 0.0653, 0.0534]),\n",
      "indices=tensor([1448, 1308, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9787, 0.0024, 0.0011]),\n",
      "indices=tensor([ 930, 1047, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9249, 0.0053, 0.0038]),\n",
      "indices=tensor([1086, 1348, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9836e-01, 6.1708e-04, 7.8892e-05]),\n",
      "indices=tensor([ 985, 1248, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4063, 0.1156, 0.0202]),\n",
      "indices=tensor([1348, 1330,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0739, 0.0483, 0.0471]),\n",
      "indices=tensor([1437, 1440, 1429]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9708e-01, 2.0678e-04, 1.9663e-04]),\n",
      "indices=tensor([1276, 1178, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9867e-01, 1.7486e-04, 1.0080e-04]),\n",
      "indices=tensor([1257, 1310, 1332]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2536, 0.0261, 0.0242]),\n",
      "indices=tensor([1500, 1471, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9735, 0.0021, 0.0019]),\n",
      "indices=tensor([1431, 1496, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9967e-01, 4.3825e-05, 3.7274e-05]),\n",
      "indices=tensor([1435, 1438, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8883e-01, 1.2880e-03, 9.6207e-04]),\n",
      "indices=tensor([1326, 1496, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0726, 0.0545, 0.0477]),\n",
      "indices=tensor([1394, 1374, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4271, 0.1929, 0.0356]),\n",
      "indices=tensor([1436, 1211, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1093, 0.0454, 0.0388]),\n",
      "indices=tensor([1403, 1112, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0627, 0.0605, 0.0496]),\n",
      "indices=tensor([1283, 1248, 1303]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0820, 0.0426, 0.0377]),\n",
      "indices=tensor([1218, 1460, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9406e-01, 1.4833e-03, 3.4857e-04]),\n",
      "indices=tensor([1425, 1382, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6533, 0.0325, 0.0266]),\n",
      "indices=tensor([1338, 1448, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1112, 0.0878, 0.0744]),\n",
      "indices=tensor([1329, 1203, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0866, 0.0706, 0.0639]),\n",
      "indices=tensor([1413, 1406, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0603, 0.0504, 0.0478]),\n",
      "indices=tensor([1386, 1387, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0597, 0.0589, 0.0517]),\n",
      "indices=tensor([1313, 1496, 1230]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7821e-01, 9.3400e-03, 8.3750e-04]),\n",
      "indices=tensor([1383, 1447, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1565, 0.0883, 0.0440]),\n",
      "indices=tensor([1496, 1317, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0642, 0.0560, 0.0486]),\n",
      "indices=tensor([1448, 1022, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0533, 0.0499, 0.0437]),\n",
      "indices=tensor([1455, 1448, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9986e-01, 1.8593e-05, 1.1856e-05]),\n",
      "indices=tensor([1219, 1403, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8453, 0.0431, 0.0198]),\n",
      "indices=tensor([1269, 1305, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0682, 0.0605, 0.0406]),\n",
      "indices=tensor([1197, 1438, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9866e-01, 1.8652e-04, 1.6563e-04]),\n",
      "indices=tensor([1123, 1277, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8872, 0.0145, 0.0080]),\n",
      "indices=tensor([1389, 1380, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1178, 0.0687, 0.0618]),\n",
      "indices=tensor([1346, 1297, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1401, 0.0660, 0.0609]),\n",
      "indices=tensor([1550, 1343, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0669, 0.0575, 0.0479]),\n",
      "indices=tensor([1492,  996, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9270, 0.0438, 0.0013]),\n",
      "indices=tensor([1499, 1413, 1492]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9857e-01, 4.0685e-04, 3.7585e-04]),\n",
      "indices=tensor([1255, 1219, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9817, 0.0045, 0.0021]),\n",
      "indices=tensor([1345, 1319, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0612, 0.0567, 0.0498]),\n",
      "indices=tensor([1456, 1421, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8941e-01, 6.3459e-04, 3.7672e-04]),\n",
      "indices=tensor([1387, 1357, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0959, 0.0411, 0.0398]),\n",
      "indices=tensor([1394, 1374,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0827, 0.0751, 0.0320]),\n",
      "indices=tensor([1310, 1258, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9888, 0.0018, 0.0014]),\n",
      "indices=tensor([1329, 1383, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9936e-01, 1.2988e-04, 1.0675e-04]),\n",
      "indices=tensor([1405, 1383, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0723, 0.0678, 0.0466]),\n",
      "indices=tensor([1385, 1357, 1375]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0486, 0.0429, 0.0414]),\n",
      "indices=tensor([1332, 1276, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4340, 0.1257, 0.0611]),\n",
      "indices=tensor([1550, 1431, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0620, 0.0610, 0.0549]),\n",
      "indices=tensor([1139, 1448, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2525, 0.0674, 0.0484]),\n",
      "indices=tensor([1400, 1382,  985]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9554, 0.0044, 0.0029]),\n",
      "indices=tensor([1310, 1433, 1322]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6974, 0.1454, 0.0110]),\n",
      "indices=tensor([1262, 1186, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.1355e-01, 7.6302e-02, 8.4200e-04]),\n",
      "indices=tensor([1189, 1156, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1669, 0.1101, 0.0745]),\n",
      "indices=tensor([1403, 1447, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8925e-01, 9.5248e-04, 8.2234e-04]),\n",
      "indices=tensor([1313, 1338, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0484, 0.0421, 0.0408]),\n",
      "indices=tensor([1251, 1348, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2553, 0.0771, 0.0381]),\n",
      "indices=tensor([1143, 1641, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4792, 0.4636, 0.0133]),\n",
      "indices=tensor([1327, 1359, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0676, 0.0580, 0.0521]),\n",
      "indices=tensor([1413, 1479, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0566, 0.0558, 0.0512]),\n",
      "indices=tensor([1448, 1413, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9420e-01, 3.0369e-03, 7.1637e-04]),\n",
      "indices=tensor([1269, 1346, 1293]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9751e-01, 1.8401e-04, 1.7909e-04]),\n",
      "indices=tensor([1224, 1386, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9320e-01, 8.5145e-04, 6.7902e-04]),\n",
      "indices=tensor([1495, 1377, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0654, 0.0601, 0.0514]),\n",
      "indices=tensor([1460, 1397,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9900, 0.0045, 0.0017]),\n",
      "indices=tensor([1327, 1359, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0825, 0.0374, 0.0315]),\n",
      "indices=tensor([1413, 1347, 1197]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.1603, 0.0734, 0.0526]),\n",
      "indices=tensor([1313, 1213,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9746e-01, 3.0793e-04, 2.3008e-04]),\n",
      "indices=tensor([1407, 1403, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0726, 0.0664, 0.0598]),\n",
      "indices=tensor([1223, 1308, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9876, 0.0012, 0.0011]),\n",
      "indices=tensor([1407, 1496, 1475]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0708, 0.0371, 0.0368]),\n",
      "indices=tensor([1403, 1465, 1273]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9690e-01, 4.1072e-04, 1.6630e-04]),\n",
      "indices=tensor([1224, 1296, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1216, 0.0962, 0.0894]),\n",
      "indices=tensor([1395, 1403, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9359, 0.0097, 0.0081]),\n",
      "indices=tensor([1194, 1347, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0757, 0.0288, 0.0277]),\n",
      "indices=tensor([1403, 1293, 1436]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2010, 0.0573, 0.0426]),\n",
      "indices=tensor([ 956, 1110, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9997e-01, 4.2867e-06, 2.7569e-06]),\n",
      "indices=tensor([1197, 1454, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9461, 0.0042, 0.0028]),\n",
      "indices=tensor([1327, 1456, 1396]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9911e-01, 5.7375e-04, 3.7426e-05]),\n",
      "indices=tensor([1425, 1435, 1480]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9967e-01, 4.4820e-05, 2.1555e-05]),\n",
      "indices=tensor([1437, 1448, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0980, 0.0935, 0.0444]),\n",
      "indices=tensor([1496, 1329, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1447, 0.0596, 0.0553]),\n",
      "indices=tensor([1321, 1112, 1230]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9827, 0.0039, 0.0035]),\n",
      "indices=tensor([1192, 1047, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9882, 0.0019, 0.0016]),\n",
      "indices=tensor([1438, 1403, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6463, 0.3322, 0.0014]),\n",
      "indices=tensor([1186, 1123, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7100, 0.0741, 0.0160]),\n",
      "indices=tensor([1408, 1380, 1391]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9847, 0.0046, 0.0032]),\n",
      "indices=tensor([1145, 1192, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1076, 0.0627, 0.0382]),\n",
      "indices=tensor([1154,  970, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9018, 0.0056, 0.0051]),\n",
      "indices=tensor([ 946,  996, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0832, 0.0419, 0.0341]),\n",
      "indices=tensor([1439, 1455, 1192]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0470, 0.0430, 0.0420]),\n",
      "indices=tensor([1154, 1126, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9119, 0.0090, 0.0044]),\n",
      "indices=tensor([1132, 1067, 1280]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9709e-01, 3.1134e-04, 1.4575e-04]),\n",
      "indices=tensor([1139, 1189, 1148]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0787, 0.0371, 0.0365]),\n",
      "indices=tensor([1499, 1445, 1522]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0570, 0.0444, 0.0405]),\n",
      "indices=tensor([1514, 1132, 1120]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1149, 0.0681, 0.0601]),\n",
      "indices=tensor([1413, 1445, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9605e-01, 1.0347e-03, 3.3630e-04]),\n",
      "indices=tensor([1435, 1357, 1203]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9789e-01, 2.3565e-04, 1.7182e-04]),\n",
      "indices=tensor([1168, 1489, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3161, 0.0338, 0.0337]),\n",
      "indices=tensor([ 946, 1112,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2128, 0.0390, 0.0346]),\n",
      "indices=tensor([1202,  946, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0613, 0.0390, 0.0385]),\n",
      "indices=tensor([1112, 1039, 1296]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9827, 0.0018, 0.0015]),\n",
      "indices=tensor([1347, 1550, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1373, 0.0826, 0.0592]),\n",
      "indices=tensor([1313, 1317, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0648, 0.0597, 0.0582]),\n",
      "indices=tensor([1403, 1439, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0918, 0.0548, 0.0518]),\n",
      "indices=tensor([1415, 1338, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9633e-01, 7.7478e-04, 2.7496e-04]),\n",
      "indices=tensor([1343, 1380, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8197e-01, 1.6136e-03, 9.3526e-04]),\n",
      "indices=tensor([1359, 1380, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9224, 0.0033, 0.0031]),\n",
      "indices=tensor([1421, 1445, 1309]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6250, 0.2268, 0.0135]),\n",
      "indices=tensor([1233, 1202, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0443, 0.0437, 0.0362]),\n",
      "indices=tensor([1330, 1403, 1278]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9729, 0.0047, 0.0025]),\n",
      "indices=tensor([1031, 1218, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1103, 0.0759, 0.0454]),\n",
      "indices=tensor([1395, 1403, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9385e-01, 5.1484e-04, 3.5891e-04]),\n",
      "indices=tensor([1086, 1348, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0697, 0.0493, 0.0352]),\n",
      "indices=tensor([1053,  970, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9970e-01, 2.3640e-04, 4.0258e-06]),\n",
      "indices=tensor([1255, 1292, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0416, 0.0414, 0.0401]),\n",
      "indices=tensor([1394, 1288, 1238]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0888, 0.0498, 0.0472]),\n",
      "indices=tensor([1218, 1214, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9990e-01, 2.1085e-05, 1.1125e-05]),\n",
      "indices=tensor([1110, 1067, 1092]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0948, 0.0665, 0.0312]),\n",
      "indices=tensor([1413, 1362, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9805e-01, 4.1516e-04, 1.4550e-04]),\n",
      "indices=tensor([1310, 1674, 1291]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0683, 0.0468, 0.0461]),\n",
      "indices=tensor([1154, 1112,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9096e-01, 1.4685e-03, 7.9196e-04]),\n",
      "indices=tensor([1244, 1068, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9386e-01, 6.0430e-04, 4.1902e-04]),\n",
      "indices=tensor([1500, 1178, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8845, 0.0067, 0.0044]),\n",
      "indices=tensor([1272, 1303, 1227]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9590, 0.0062, 0.0047]),\n",
      "indices=tensor([1327, 1288, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9748, 0.0013, 0.0012]),\n",
      "indices=tensor([1284, 1460, 1156]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8604, 0.0190, 0.0065]),\n",
      "indices=tensor([1347, 1448, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0769, 0.0707, 0.0549]),\n",
      "indices=tensor([1489, 1421, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1426, 0.0733, 0.0557]),\n",
      "indices=tensor([1437, 1496, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1035, 0.0742, 0.0698]),\n",
      "indices=tensor([1321, 1112, 1230]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1015, 0.0812, 0.0479]),\n",
      "indices=tensor([1403, 1308, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9218e-01, 1.7539e-03, 5.2492e-04]),\n",
      "indices=tensor([1257, 1244, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9973e-01, 2.3764e-05, 2.1609e-05]),\n",
      "indices=tensor([1435, 1403, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4204, 0.0537, 0.0333]),\n",
      "indices=tensor([1258, 1550,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9031e-01, 3.8505e-03, 6.0171e-04]),\n",
      "indices=tensor([1186, 1123, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9365e-01, 1.5487e-03, 6.2632e-04]),\n",
      "indices=tensor([1486, 1437, 1423]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9960e-01, 3.1955e-05, 2.5269e-05]),\n",
      "indices=tensor([1310, 1674, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1814, 0.1371, 0.1079]),\n",
      "indices=tensor([1550, 1403, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9602e-01, 7.2431e-04, 2.2391e-04]),\n",
      "indices=tensor([1266, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2155, 0.0689, 0.0636]),\n",
      "indices=tensor([1407, 1380, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0628, 0.0432, 0.0374]),\n",
      "indices=tensor([1313, 1317, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9239, 0.0234, 0.0075]),\n",
      "indices=tensor([1495, 1414, 1391]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9417, 0.0312, 0.0030]),\n",
      "indices=tensor([1316, 1387, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1258, 0.0703, 0.0664]),\n",
      "indices=tensor([1382,  941, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9435e-01, 8.8048e-04, 8.5875e-04]),\n",
      "indices=tensor([1399, 1338, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0828, 0.0529, 0.0417]),\n",
      "indices=tensor([1403, 1258, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2200, 0.0415, 0.0392]),\n",
      "indices=tensor([1044, 1178, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0810, 0.0620, 0.0584]),\n",
      "indices=tensor([1110, 1214, 1339]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6764, 0.2908, 0.0068]),\n",
      "indices=tensor([1438, 1393, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1396, 0.0812, 0.0756]),\n",
      "indices=tensor([1011, 1112, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1106, 0.0535, 0.0375]),\n",
      "indices=tensor([1382, 1038, 1060]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8224e-01, 1.4605e-03, 9.4221e-04]),\n",
      "indices=tensor([1321, 1308, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9360e-01, 9.8820e-04, 5.9765e-04]),\n",
      "indices=tensor([1338, 1413, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9831, 0.0093, 0.0020]),\n",
      "indices=tensor([1327, 1359, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0726, 0.0507, 0.0422]),\n",
      "indices=tensor([1047, 1178, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4358, 0.0814, 0.0295]),\n",
      "indices=tensor([1455, 1433, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9704, 0.0066, 0.0035]),\n",
      "indices=tensor([1340, 1390, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1204, 0.0514, 0.0416]),\n",
      "indices=tensor([1460, 1308, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1394, 0.0416, 0.0409]),\n",
      "indices=tensor([1350, 1357, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8957e-01, 7.3061e-04, 6.4998e-04]),\n",
      "indices=tensor([1362, 1419, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6148, 0.0247, 0.0223]),\n",
      "indices=tensor([1231, 1393, 1126]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0694, 0.0574, 0.0572]),\n",
      "indices=tensor([1309, 1415, 1346]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9945e-01, 6.4284e-05, 6.0369e-05]),\n",
      "indices=tensor([1313, 1437, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9931e-01, 7.5852e-05, 4.1379e-05]),\n",
      "indices=tensor([1270, 1395,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9819e-01, 1.0356e-03, 6.0667e-05]),\n",
      "indices=tensor([1425, 1435, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3375, 0.1879, 0.1589]),\n",
      "indices=tensor([1269, 1292, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1519, 0.0607, 0.0401]),\n",
      "indices=tensor([ 983, 1045, 1192]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6524, 0.0316, 0.0273]),\n",
      "indices=tensor([1379,  996, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4078, 0.1319, 0.0449]),\n",
      "indices=tensor([1429, 1431, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1413, 0.0448, 0.0396]),\n",
      "indices=tensor([1317, 1395, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9984e-01, 1.4206e-05, 9.1788e-06]),\n",
      "indices=tensor([1197, 1396, 1454]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5967, 0.3656, 0.0033]),\n",
      "indices=tensor([1255, 1213, 1258]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9919, 0.0032, 0.0010]),\n",
      "indices=tensor([1282, 1380, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8879e-01, 6.8372e-04, 5.4234e-04]),\n",
      "indices=tensor([1366, 1045, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0594, 0.0402, 0.0377]),\n",
      "indices=tensor([1496, 1459, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9727, 0.0072, 0.0031]),\n",
      "indices=tensor([1252, 1413, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6902, 0.0233, 0.0190]),\n",
      "indices=tensor([1403, 1437, 1389]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0370, 0.0361, 0.0309]),\n",
      "indices=tensor([1489, 1459, 1385]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8939e-01, 7.6359e-04, 7.2611e-04]),\n",
      "indices=tensor([1273, 1252, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9830e-01, 1.5120e-04, 1.1794e-04]),\n",
      "indices=tensor([1367, 1460, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3786, 0.0559, 0.0297]),\n",
      "indices=tensor([1550, 1380, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4940, 0.0365, 0.0253]),\n",
      "indices=tensor([1269, 1413, 1418]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1792, 0.1129, 0.0929]),\n",
      "indices=tensor([1420, 1394, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0587, 0.0418, 0.0345]),\n",
      "indices=tensor([1345, 1192, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2307, 0.0624, 0.0518]),\n",
      "indices=tensor([1387, 1178, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9929, 0.0013, 0.0010]),\n",
      "indices=tensor([1211, 1308, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0682, 0.0511, 0.0482]),\n",
      "indices=tensor([1437, 1455, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5150, 0.0463, 0.0304]),\n",
      "indices=tensor([1338, 1403, 1498]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7608, 0.1321, 0.0079]),\n",
      "indices=tensor([1438, 1406, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0830, 0.0623, 0.0612]),\n",
      "indices=tensor([1178, 1395, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6092, 0.2659, 0.0174]),\n",
      "indices=tensor([1439, 1417, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9478e-01, 1.6749e-03, 5.1857e-04]),\n",
      "indices=tensor([1269, 1413, 1309]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9226e-01, 7.8678e-04, 6.8859e-04]),\n",
      "indices=tensor([1367, 1321, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0799, 0.0734, 0.0551]),\n",
      "indices=tensor([1465, 1403, 1453]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5012, 0.0863, 0.0496]),\n",
      "indices=tensor([1407, 1453, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2235, 0.0494, 0.0492]),\n",
      "indices=tensor([1152, 1196, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9588e-01, 5.4677e-04, 3.1713e-04]),\n",
      "indices=tensor([1376, 1413, 1266]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7610, 0.0421, 0.0285]),\n",
      "indices=tensor([1431, 1550, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9969e-01, 2.8511e-05, 1.7877e-05]),\n",
      "indices=tensor([1435, 1403, 1203]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7258, 0.0098, 0.0086]),\n",
      "indices=tensor([1500, 1478, 1522]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8512, 0.0201, 0.0126]),\n",
      "indices=tensor([1309, 1346, 1475]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9856e-01, 3.7710e-04, 1.1522e-04]),\n",
      "indices=tensor([1326, 1308, 1347]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9783e-01, 4.5290e-04, 1.3024e-04]),\n",
      "indices=tensor([ 956,  990, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1020, 0.0628, 0.0367]),\n",
      "indices=tensor([1445, 1403, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9964e-01, 3.5617e-05, 2.5481e-05]),\n",
      "indices=tensor([1530, 1448, 1347]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0584, 0.0472, 0.0454]),\n",
      "indices=tensor([1112, 1395, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9943, 0.0020, 0.0010]),\n",
      "indices=tensor([1310, 1219, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0850, 0.0781, 0.0445]),\n",
      "indices=tensor([1313, 1496, 1396]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9979e-01, 1.2019e-04, 1.4839e-05]),\n",
      "indices=tensor([1189, 1156, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1110, 0.0587, 0.0484]),\n",
      "indices=tensor([1110, 1120, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3010, 0.0350, 0.0290]),\n",
      "indices=tensor([1215, 1152, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9478, 0.0056, 0.0030]),\n",
      "indices=tensor([1409, 1421, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9505, 0.0138, 0.0046]),\n",
      "indices=tensor([1475, 1403, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0830, 0.0488, 0.0469]),\n",
      "indices=tensor([1308, 1359, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0631, 0.0421, 0.0373]),\n",
      "indices=tensor([1389, 1126, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8392, 0.0896, 0.0088]),\n",
      "indices=tensor([1435, 1480, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1249, 0.1064, 0.0730]),\n",
      "indices=tensor([1403, 1438, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0464, 0.0424, 0.0412]),\n",
      "indices=tensor([1178, 1492, 1478]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4690, 0.0478, 0.0313]),\n",
      "indices=tensor([1325, 1286, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8914e-01, 8.0331e-03, 3.9235e-04]),\n",
      "indices=tensor([1152, 1048, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9704e-01, 2.9516e-04, 1.2354e-04]),\n",
      "indices=tensor([1143, 1411, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3398, 0.1132, 0.0465]),\n",
      "indices=tensor([ 287, 1403, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1082, 0.0625, 0.0530]),\n",
      "indices=tensor([1415, 1445, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9960e-01, 6.9056e-05, 3.1550e-05]),\n",
      "indices=tensor([1346, 1550, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0706, 0.0448, 0.0439]),\n",
      "indices=tensor([946, 970, 986]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0925, 0.0493, 0.0321]),\n",
      "indices=tensor([1308, 1357, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0699, 0.0687, 0.0597]),\n",
      "indices=tensor([1413, 1496, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0548, 0.0537, 0.0521]),\n",
      "indices=tensor([1231, 1385, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1056, 0.0939, 0.0609]),\n",
      "indices=tensor([1395, 1313, 1233]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8135e-01, 1.4939e-02, 3.0390e-04]),\n",
      "indices=tensor([1296, 1329,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0594, 0.0485, 0.0394]),\n",
      "indices=tensor([1244, 1297, 1288]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1140, 0.0759, 0.0403]),\n",
      "indices=tensor([1486, 1154, 1389]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2677, 0.2652, 0.1466]),\n",
      "indices=tensor([1273, 1319, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9970e-01, 4.3080e-05, 3.7032e-05]),\n",
      "indices=tensor([1078, 1022, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3036, 0.1275, 0.0292]),\n",
      "indices=tensor([1377, 1429, 1493]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1942, 0.1835, 0.0428]),\n",
      "indices=tensor([1413, 1496, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1141, 0.0768, 0.0649]),\n",
      "indices=tensor([1067,  988, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0962, 0.0376, 0.0376]),\n",
      "indices=tensor([1145, 1196,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9889e-01, 2.1750e-04, 5.7064e-05]),\n",
      "indices=tensor([1117, 1674, 1082]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9589e-01, 1.4654e-03, 8.2599e-04]),\n",
      "indices=tensor([1211, 1395, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9603e-01, 6.4891e-04, 1.8380e-04]),\n",
      "indices=tensor([1266, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8791, 0.0156, 0.0069]),\n",
      "indices=tensor([1428, 1496, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6849, 0.0235, 0.0159]),\n",
      "indices=tensor([ 990, 1674, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9894e-01, 7.1509e-04, 2.5640e-05]),\n",
      "indices=tensor([1446, 1413, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9688, 0.0048, 0.0023]),\n",
      "indices=tensor([1348, 1448, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9965e-01, 6.4497e-05, 2.5425e-05]),\n",
      "indices=tensor([1078, 1022, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1066, 0.0751, 0.0458]),\n",
      "indices=tensor([1395, 1403, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4486, 0.1013, 0.0488]),\n",
      "indices=tensor([1380, 1338, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9207, 0.0057, 0.0043]),\n",
      "indices=tensor([1112, 1296, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9996e-01, 3.3646e-06, 2.8666e-06]),\n",
      "indices=tensor([ 287, 1395, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3317, 0.0559, 0.0345]),\n",
      "indices=tensor([1438, 1496, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6844, 0.2366, 0.0061]),\n",
      "indices=tensor([1300, 1244, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9990e-01, 3.1915e-05, 7.0088e-06]),\n",
      "indices=tensor([1152, 1048, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6069, 0.1369, 0.0277]),\n",
      "indices=tensor([1414, 1437, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0740, 0.0703, 0.0663]),\n",
      "indices=tensor([1112, 1460, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5897, 0.0310, 0.0200]),\n",
      "indices=tensor([1421, 1403, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1317, 0.0752, 0.0607]),\n",
      "indices=tensor([1214, 1308, 1243]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3602, 0.2721, 0.0719]),\n",
      "indices=tensor([1227, 1230, 1243]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9877e-01, 4.4938e-04, 5.8272e-05]),\n",
      "indices=tensor([1392, 1308, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7267, 0.1061, 0.0169]),\n",
      "indices=tensor([1455, 1421, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1046, 0.0664, 0.0587]),\n",
      "indices=tensor([1308, 1448, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9872e-01, 1.0284e-04, 8.4170e-05]),\n",
      "indices=tensor([1419, 1455, 1674]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([9.9404e-01, 8.6011e-04, 3.3187e-04]),\n",
      "indices=tensor([1309, 1419, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9823, 0.0025, 0.0012]),\n",
      "indices=tensor([1194, 1167, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9451e-01, 1.6198e-03, 3.4036e-04]),\n",
      "indices=tensor([1479, 1413, 1288]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8801, 0.0332, 0.0300]),\n",
      "indices=tensor([1418, 1347, 1385]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9686, 0.0023, 0.0015]),\n",
      "indices=tensor([ 970, 1009, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8806e-01, 9.4713e-04, 9.2558e-04]),\n",
      "indices=tensor([1213, 1326, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7208, 0.0185, 0.0170]),\n",
      "indices=tensor([1426, 1126, 1297]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9757e-01, 2.3932e-04, 1.7240e-04]),\n",
      "indices=tensor([1359, 1550, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4378, 0.1083, 0.0521]),\n",
      "indices=tensor([1453, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9913e-01, 8.6481e-05, 8.0672e-05]),\n",
      "indices=tensor([1382, 1308, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9115e-01, 8.0516e-04, 5.7723e-04]),\n",
      "indices=tensor([1244, 1270, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0700, 0.0481, 0.0467]),\n",
      "indices=tensor([1296, 1126, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4541, 0.0733, 0.0302]),\n",
      "indices=tensor([1214, 1273, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9969e-01, 1.3778e-04, 5.2333e-05]),\n",
      "indices=tensor([1305, 1202, 1446]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5055, 0.1507, 0.0438]),\n",
      "indices=tensor([1319, 1345,  985]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1202, 0.0520, 0.0459]),\n",
      "indices=tensor([1454, 1448, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9921, 0.0020, 0.0012]),\n",
      "indices=tensor([1305, 1332, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2660, 0.0713, 0.0308]),\n",
      "indices=tensor([1403, 1438, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9481, 0.0057, 0.0029]),\n",
      "indices=tensor([1347, 1398, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8053, 0.1120, 0.0052]),\n",
      "indices=tensor([1282, 1262, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2884, 0.0377, 0.0276]),\n",
      "indices=tensor([1380, 1421, 1209]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8702e-01, 1.4429e-03, 5.2164e-04]),\n",
      "indices=tensor([1485, 1309, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5401, 0.3098, 0.0070]),\n",
      "indices=tensor([1330, 1348, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9737, 0.0017, 0.0014]),\n",
      "indices=tensor([1433, 1445, 1393]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0618, 0.0549, 0.0427]),\n",
      "indices=tensor([1341, 1218, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9639e-01, 2.2879e-04, 1.8245e-04]),\n",
      "indices=tensor([1215, 1366, 1227]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9999e-01, 1.2205e-06, 8.7284e-07]),\n",
      "indices=tensor([ 930, 1357, 1340]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1249, 0.1189, 0.0882]),\n",
      "indices=tensor([ 946, 1343, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0979, 0.0445, 0.0431]),\n",
      "indices=tensor([1112, 1455, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9505, 0.0058, 0.0053]),\n",
      "indices=tensor([1180, 1268, 1243]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1123, 0.0468, 0.0459]),\n",
      "indices=tensor([1218, 1126, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9825e-01, 2.7423e-04, 1.0746e-04]),\n",
      "indices=tensor([1048, 1123, 1332]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0480, 0.0461, 0.0401]),\n",
      "indices=tensor([1058, 1189, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9287e-01, 2.9907e-03, 7.6389e-04]),\n",
      "indices=tensor([1280, 1297, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8658, 0.0088, 0.0085]),\n",
      "indices=tensor([1319, 1345,  985]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9808, 0.0134, 0.0015]),\n",
      "indices=tensor([1438, 1393, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1088, 0.0590, 0.0522]),\n",
      "indices=tensor([1123, 1053, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9448, 0.0062, 0.0042]),\n",
      "indices=tensor([1310, 1433, 1322]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5660, 0.1226, 0.0431]),\n",
      "indices=tensor([1203, 1168, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1053, 0.0344, 0.0313]),\n",
      "indices=tensor([1413, 1362, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9027, 0.0081, 0.0064]),\n",
      "indices=tensor([1387, 1112, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9694e-01, 8.0401e-04, 2.7906e-04]),\n",
      "indices=tensor([1282, 1380, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9865e-01, 1.3108e-04, 1.1887e-04]),\n",
      "indices=tensor([1211, 1375, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0794, 0.0593, 0.0529]),\n",
      "indices=tensor([1500, 1439, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8421, 0.0378, 0.0098]),\n",
      "indices=tensor([1305, 1155,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0544, 0.0523, 0.0444]),\n",
      "indices=tensor([1403, 1465, 1409]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5282, 0.0530, 0.0252]),\n",
      "indices=tensor([1423, 1403, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0710, 0.0675, 0.0286]),\n",
      "indices=tensor([ 946, 1283,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0746, 0.0625, 0.0553]),\n",
      "indices=tensor([1117, 1674, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9853, 0.0030, 0.0015]),\n",
      "indices=tensor([1343, 1380, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0648, 0.0615, 0.0495]),\n",
      "indices=tensor([1096, 1438, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9906e-01, 1.4884e-04, 6.2247e-05]),\n",
      "indices=tensor([1215, 1413, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9218, 0.0068, 0.0060]),\n",
      "indices=tensor([1262, 1282, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7580, 0.0710, 0.0092]),\n",
      "indices=tensor([1339, 1330, 1492]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9261, 0.0214, 0.0050]),\n",
      "indices=tensor([1433, 1403, 1409]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9899, 0.0039, 0.0010]),\n",
      "indices=tensor([1339, 1110, 1131]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9896e-01, 7.5713e-05, 7.4920e-05]),\n",
      "indices=tensor([1362, 1496, 1309]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3113, 0.2658, 0.0867]),\n",
      "indices=tensor([1327, 1180, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1703, 0.0691, 0.0635]),\n",
      "indices=tensor([1390, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0754, 0.0348, 0.0299]),\n",
      "indices=tensor([1394, 1465, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8824, 0.0998, 0.0014]),\n",
      "indices=tensor([1202, 1346, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0629, 0.0618, 0.0519]),\n",
      "indices=tensor([1433, 1395, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9127, 0.0099, 0.0055]),\n",
      "indices=tensor([1498, 1380, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9853, 0.0020, 0.0011]),\n",
      "indices=tensor([1179, 1152, 1310]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0577, 0.0550, 0.0446]),\n",
      "indices=tensor([1218, 1339, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9445, 0.0078, 0.0022]),\n",
      "indices=tensor([1514, 1498, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0710, 0.0513, 0.0394]),\n",
      "indices=tensor([1308, 1403, 1376]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9297, 0.0073, 0.0052]),\n",
      "indices=tensor([1317, 1325, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1184, 0.0920, 0.0632]),\n",
      "indices=tensor([1496, 1413, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1624, 0.0565, 0.0438]),\n",
      "indices=tensor([1112,  970, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5295, 0.0191, 0.0188]),\n",
      "indices=tensor([1496, 1390, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0870, 0.0406, 0.0361]),\n",
      "indices=tensor([1403, 1283, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9978e-01, 1.1689e-04, 1.2531e-05]),\n",
      "indices=tensor([1202, 1305, 1446]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9311, 0.0297, 0.0076]),\n",
      "indices=tensor([1371, 1403, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9399, 0.0404, 0.0035]),\n",
      "indices=tensor([1330, 1378, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1333, 0.0668, 0.0507]),\n",
      "indices=tensor([1438, 1496, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0617, 0.0505, 0.0459]),\n",
      "indices=tensor([1674, 1223, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1158, 0.0840, 0.0557]),\n",
      "indices=tensor([1308, 1448, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2500, 0.0834, 0.0609]),\n",
      "indices=tensor([1227, 1446, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8545, 0.1040, 0.0043]),\n",
      "indices=tensor([1325, 1386, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9564e-01, 6.9302e-04, 3.1264e-04]),\n",
      "indices=tensor([1252, 1317, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7972, 0.1841, 0.0025]),\n",
      "indices=tensor([1114, 1164, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9581e-01, 5.4409e-04, 2.5205e-04]),\n",
      "indices=tensor([1257, 1310, 1297]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0720, 0.0581, 0.0575]),\n",
      "indices=tensor([1284, 1493, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9147e-01, 2.0735e-03, 8.2414e-04]),\n",
      "indices=tensor([1486, 1437, 1423]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0785, 0.0470, 0.0459]),\n",
      "indices=tensor([1145, 1196, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9992e-01, 7.4928e-06, 3.7777e-06]),\n",
      "indices=tensor([1354, 1530, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1883, 0.0699, 0.0417]),\n",
      "indices=tensor([1400, 1382, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9718, 0.0025, 0.0020]),\n",
      "indices=tensor([1344, 1489, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9458, 0.0053, 0.0037]),\n",
      "indices=tensor([1418, 1386, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9986e-01, 4.6438e-05, 5.4421e-06]),\n",
      "indices=tensor([1078, 1117, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9922e-01, 4.5927e-05, 4.3802e-05]),\n",
      "indices=tensor([1326, 1142, 1347]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0647, 0.0612, 0.0611]),\n",
      "indices=tensor([1123, 1308, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0559, 0.0491, 0.0481]),\n",
      "indices=tensor([1347, 1283, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9795, 0.0025, 0.0012]),\n",
      "indices=tensor([1156, 1189, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0623, 0.0612, 0.0412]),\n",
      "indices=tensor([1112, 1178, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0997, 0.0747, 0.0644]),\n",
      "indices=tensor([1419, 1196, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9817e-01, 2.8520e-04, 1.7826e-04]),\n",
      "indices=tensor([ 956, 1403, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5356, 0.0236, 0.0225]),\n",
      "indices=tensor([1214, 1413,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0780, 0.0461, 0.0367]),\n",
      "indices=tensor([1321, 1223, 1278]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9993e-01, 2.5438e-05, 5.9798e-06]),\n",
      "indices=tensor([1232, 1326, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4735, 0.4412, 0.0063]),\n",
      "indices=tensor([1382, 1343, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3892, 0.1939, 0.0287]),\n",
      "indices=tensor([1114, 1139, 1514]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9918, 0.0031, 0.0011]),\n",
      "indices=tensor([1414, 1454, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0655, 0.0472, 0.0441]),\n",
      "indices=tensor([1218, 1438, 1332]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7802e-01, 1.3641e-03, 9.0035e-04]),\n",
      "indices=tensor([1341, 1053, 1120]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.9755, 0.0036, 0.0030]),\n",
      "indices=tensor([1383, 1355, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0642, 0.0538, 0.0527]),\n",
      "indices=tensor([1112, 1674, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8634, 0.0361, 0.0155]),\n",
      "indices=tensor([1391, 1548, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1293, 0.0336, 0.0309]),\n",
      "indices=tensor([1308, 1126, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8105, 0.1404, 0.0177]),\n",
      "indices=tensor([1295, 1248, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.4632e-01, 4.5843e-02, 6.7184e-04]),\n",
      "indices=tensor([1322, 1345,  985]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7962, 0.0352, 0.0154]),\n",
      "indices=tensor([1421, 1455, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9519, 0.0085, 0.0044]),\n",
      "indices=tensor([1435, 1403, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0602, 0.0550, 0.0541]),\n",
      "indices=tensor([1380, 1496, 1192]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0427, 0.0406, 0.0369]),\n",
      "indices=tensor([1465, 1031, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9684e-01, 2.3044e-04, 1.7222e-04]),\n",
      "indices=tensor([1232, 1262, 1278]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8653, 0.0101, 0.0087]),\n",
      "indices=tensor([ 990, 1674,  956]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5258, 0.0346, 0.0244]),\n",
      "indices=tensor([1158, 1255, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0918, 0.0595, 0.0585]),\n",
      "indices=tensor([1230, 1321, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4168, 0.1089, 0.0302]),\n",
      "indices=tensor([1499, 1413, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7768, 0.0168, 0.0113]),\n",
      "indices=tensor([1428, 1397, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0810, 0.0461, 0.0307]),\n",
      "indices=tensor([1218, 1460, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8109, 0.0161, 0.0151]),\n",
      "indices=tensor([1112, 1283, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0591, 0.0470, 0.0452]),\n",
      "indices=tensor([1339, 1112, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9419e-01, 6.3257e-04, 4.9935e-04]),\n",
      "indices=tensor([1355, 1278, 1480]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9652e-01, 5.4090e-04, 4.6041e-04]),\n",
      "indices=tensor([1419, 1285, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9611, 0.0023, 0.0018]),\n",
      "indices=tensor([1244, 1394, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9479e-01, 4.7009e-04, 3.2253e-04]),\n",
      "indices=tensor([1244, 1231, 1258]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1079, 0.0990, 0.0720]),\n",
      "indices=tensor([1394, 1496, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0882, 0.0757, 0.0478]),\n",
      "indices=tensor([1403, 1478, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9344, 0.0179, 0.0045]),\n",
      "indices=tensor([1142, 1301, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1027, 0.0434, 0.0343]),\n",
      "indices=tensor([1309, 1301, 1258]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0800, 0.0532, 0.0479]),\n",
      "indices=tensor([1347, 1343, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9990e-01, 2.5584e-05, 7.1038e-06]),\n",
      "indices=tensor([1354, 1359, 1530]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9734, 0.0141, 0.0014]),\n",
      "indices=tensor([ 930,  800, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9892e-01, 1.5941e-04, 1.0928e-04]),\n",
      "indices=tensor([1297, 1447, 1362]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9431, 0.0056, 0.0031]),\n",
      "indices=tensor([1496, 1445, 1390]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1394, 0.0859, 0.0836]),\n",
      "indices=tensor([1309, 1475, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8955, 0.0096, 0.0057]),\n",
      "indices=tensor([1227, 1400, 1297]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9970e-01, 3.7127e-05, 2.9360e-05]),\n",
      "indices=tensor([ 956,  988, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0872, 0.0476, 0.0382]),\n",
      "indices=tensor([1168, 1047, 1193]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1652, 0.0446, 0.0395]),\n",
      "indices=tensor([1489, 1359, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0739, 0.0448, 0.0366]),\n",
      "indices=tensor([1382, 1022, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0977, 0.0515, 0.0447]),\n",
      "indices=tensor([1489, 1496, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9657, 0.0029, 0.0022]),\n",
      "indices=tensor([1428, 1400, 1390]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1160, 0.0685, 0.0462]),\n",
      "indices=tensor([1233, 1310, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7353, 0.1075, 0.0099]),\n",
      "indices=tensor([1039,  996, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9712, 0.0179, 0.0015]),\n",
      "indices=tensor([1326, 1308, 1347]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9122e-01, 1.7229e-03, 6.5280e-04]),\n",
      "indices=tensor([1273, 1252, 1022]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4371, 0.0435, 0.0310]),\n",
      "indices=tensor([1438, 1214, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9863, 0.0013, 0.0012]),\n",
      "indices=tensor([1447, 1407, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1861, 0.1023, 0.0498]),\n",
      "indices=tensor([1522, 1394,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9964e-01, 8.0689e-05, 2.0838e-05]),\n",
      "indices=tensor([1437, 1448, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1476, 0.0590, 0.0590]),\n",
      "indices=tensor([1403, 1214, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0661, 0.0510, 0.0452]),\n",
      "indices=tensor([1394, 1374, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1095, 0.0734, 0.0537]),\n",
      "indices=tensor([1280, 1270, 1238]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0684, 0.0434, 0.0354]),\n",
      "indices=tensor([1394, 1465, 1641]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1509, 0.1209, 0.0885]),\n",
      "indices=tensor([1380, 1428, 1343]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8316e-01, 3.1967e-03, 5.7409e-04]),\n",
      "indices=tensor([1410, 1383, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0413, 0.0360, 0.0360]),\n",
      "indices=tensor([1496, 1456, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0902, 0.0715, 0.0638]),\n",
      "indices=tensor([1423, 1395, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8126e-01, 9.4475e-03, 6.7510e-04]),\n",
      "indices=tensor([1332, 1315, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0513, 0.0502, 0.0488]),\n",
      "indices=tensor([ 970, 1053, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1423, 0.0538, 0.0395]),\n",
      "indices=tensor([1355, 1154, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0966, 0.0803, 0.0683]),\n",
      "indices=tensor([1387, 1383, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2111, 0.0505, 0.0477]),\n",
      "indices=tensor([1495, 1494, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7962, 0.0672, 0.0171]),\n",
      "indices=tensor([1385, 1347, 1418]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7404e-01, 3.1826e-03, 7.7125e-04]),\n",
      "indices=tensor([1413, 1438, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9779, 0.0054, 0.0020]),\n",
      "indices=tensor([1243, 1293, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0511, 0.0415, 0.0415]),\n",
      "indices=tensor([ 970, 1131, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9910e-01, 1.6792e-04, 1.4141e-04]),\n",
      "indices=tensor([1419, 1448, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9171, 0.0259, 0.0068]),\n",
      "indices=tensor([1437, 1395, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9196e-01, 1.5419e-03, 4.7263e-04]),\n",
      "indices=tensor([1456, 1393, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0833, 0.0664, 0.0633]),\n",
      "indices=tensor([1286,  970, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1271, 0.0710, 0.0493]),\n",
      "indices=tensor([1309, 1498, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0415, 0.0407, 0.0376]),\n",
      "indices=tensor([1330, 1308, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9759e-01, 3.5556e-04, 2.0770e-04]),\n",
      "indices=tensor([1350, 1433, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9215e-01, 4.2166e-03, 5.5251e-04]),\n",
      "indices=tensor([1265, 1317, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1034, 0.0475, 0.0464]),\n",
      "indices=tensor([1223, 1315,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8003, 0.0471, 0.0317]),\n",
      "indices=tensor([1230, 1243, 1227]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0698, 0.0547, 0.0447]),\n",
      "indices=tensor([1112, 1455, 1419]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3449, 0.1029, 0.0496]),\n",
      "indices=tensor([1215, 1413, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9957e-01, 4.1167e-05, 3.4082e-05]),\n",
      "indices=tensor([1447, 1411, 1454]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6026, 0.2582, 0.0123]),\n",
      "indices=tensor([1421, 1386, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8643, 0.0070, 0.0066]),\n",
      "indices=tensor([1244, 1394, 1227]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6019, 0.0236, 0.0206]),\n",
      "indices=tensor([1327, 1380, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8765, 0.0121, 0.0108]),\n",
      "indices=tensor([1485, 1403, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9850, 0.0027, 0.0017]),\n",
      "indices=tensor([1252, 1218, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1264, 0.0456, 0.0325]),\n",
      "indices=tensor([1380, 1421,  986]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8290, 0.0223, 0.0202]),\n",
      "indices=tensor([1494, 1223, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9687, 0.0044, 0.0029]),\n",
      "indices=tensor([1456, 1445, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8324e-01, 5.2295e-03, 8.8034e-04]),\n",
      "indices=tensor([1426, 1344,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1810, 0.0602, 0.0592]),\n",
      "indices=tensor([1423, 1395, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9987e-01, 1.5973e-05, 1.4985e-05]),\n",
      "indices=tensor([1362, 1403, 1423]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3421, 0.0886, 0.0299]),\n",
      "indices=tensor([1092, 1152, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0455, 0.0426, 0.0417]),\n",
      "indices=tensor([1496, 1403, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3242, 0.1091, 0.0502]),\n",
      "indices=tensor([1343, 1413, 1396]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0998, 0.0953, 0.0573]),\n",
      "indices=tensor([1413, 1403, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1275, 0.0992, 0.0569]),\n",
      "indices=tensor([1380, 1550, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6553, 0.0988, 0.0746]),\n",
      "indices=tensor([1411, 1438, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0586, 0.0570, 0.0431]),\n",
      "indices=tensor([1045, 1308, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9846, 0.0010, 0.0010]),\n",
      "indices=tensor([1273, 1255, 1186]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5310, 0.0699, 0.0548]),\n",
      "indices=tensor([1359, 1448, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1250, 0.0354, 0.0330]),\n",
      "indices=tensor([1214, 1413,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0788, 0.0526, 0.0426]),\n",
      "indices=tensor([1437, 1308, 1455]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.9174, 0.0160, 0.0057]),\n",
      "indices=tensor([1180, 1387, 1398]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6853, 0.0816, 0.0293]),\n",
      "indices=tensor([1475, 1403, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5356, 0.0299, 0.0218]),\n",
      "indices=tensor([1387, 1413, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9702, 0.0085, 0.0017]),\n",
      "indices=tensor([1319, 1377, 1362]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7390, 0.0253, 0.0232]),\n",
      "indices=tensor([1485, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9733e-01, 3.4349e-04, 1.7502e-04]),\n",
      "indices=tensor([1308, 1196, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9546e-01, 4.0738e-04, 3.6390e-04]),\n",
      "indices=tensor([1038, 1382, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8530, 0.0245, 0.0112]),\n",
      "indices=tensor([1132, 1166, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1514, 0.0730, 0.0292]),\n",
      "indices=tensor([1283, 1273, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9286e-01, 4.7739e-04, 3.0171e-04]),\n",
      "indices=tensor([1156,  970, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9915, 0.0042, 0.0012]),\n",
      "indices=tensor([1218, 1158, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9245, 0.0075, 0.0058]),\n",
      "indices=tensor([1548, 1413, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9996e-01, 7.4000e-06, 6.0960e-06]),\n",
      "indices=tensor([1378, 1214, 1270]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8768, 0.0442, 0.0067]),\n",
      "indices=tensor([1522, 1493, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9859, 0.0021, 0.0014]),\n",
      "indices=tensor([1252, 1460, 1296]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8204, 0.0079, 0.0050]),\n",
      "indices=tensor([1500, 1478, 1522]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0764, 0.0652, 0.0522]),\n",
      "indices=tensor([1413,  996, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9600, 0.0081, 0.0048]),\n",
      "indices=tensor([1475, 1396, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8405, 0.0156, 0.0146]),\n",
      "indices=tensor([1499, 1421, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0894, 0.0630, 0.0371]),\n",
      "indices=tensor([1273, 1223, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9673e-01, 2.1168e-03, 1.5936e-04]),\n",
      "indices=tensor([1273, 1413, 1310]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0507, 0.0498, 0.0387]),\n",
      "indices=tensor([1355, 1277, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9631e-01, 1.0789e-03, 3.0264e-04]),\n",
      "indices=tensor([ 987, 1038, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0897, 0.0560, 0.0505]),\n",
      "indices=tensor([1382, 1310, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9796e-01, 1.2020e-04, 9.6791e-05]),\n",
      "indices=tensor([1123, 1277,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9817, 0.0044, 0.0020]),\n",
      "indices=tensor([1252, 1413, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0699, 0.0625, 0.0617]),\n",
      "indices=tensor([1445, 1265, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6729, 0.0515, 0.0246]),\n",
      "indices=tensor([1332, 1357, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0621, 0.0517, 0.0486]),\n",
      "indices=tensor([1110, 1272, 1251]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0588, 0.0503, 0.0416]),\n",
      "indices=tensor([1178,  946, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0623, 0.0607, 0.0571]),\n",
      "indices=tensor([1308, 1053,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1438, 0.0649, 0.0494]),\n",
      "indices=tensor([1435, 1060, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5423, 0.0706, 0.0223]),\n",
      "indices=tensor([1400, 1496, 1131]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8799e-01, 1.1398e-03, 7.9964e-04]),\n",
      "indices=tensor([1323, 1492, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8646e-01, 1.1847e-03, 7.2646e-04]),\n",
      "indices=tensor([1276, 1395, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6058, 0.3251, 0.0076]),\n",
      "indices=tensor([1186, 1284, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8721, 0.0145, 0.0129]),\n",
      "indices=tensor([1179, 1152, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0853, 0.0529, 0.0505]),\n",
      "indices=tensor([1309, 1283, 1393]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1920, 0.1699, 0.0922]),\n",
      "indices=tensor([1498, 1403, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9715, 0.0025, 0.0013]),\n",
      "indices=tensor([1319, 1448, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9237e-01, 7.7488e-04, 6.0505e-04]),\n",
      "indices=tensor([1044,  988, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8610e-01, 3.1561e-03, 5.9635e-04]),\n",
      "indices=tensor([1485, 1455, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1116, 0.0504, 0.0503]),\n",
      "indices=tensor([1244, 1152, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0920, 0.0608, 0.0578]),\n",
      "indices=tensor([1413, 1403, 1272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9144e-01, 2.0391e-03, 6.7004e-04]),\n",
      "indices=tensor([1139, 1178, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9839, 0.0057, 0.0023]),\n",
      "indices=tensor([1252, 1406, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9701, 0.0046, 0.0012]),\n",
      "indices=tensor([1265, 1114, 1142]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9738e-01, 3.1227e-04, 1.9600e-04]),\n",
      "indices=tensor([1265, 1219, 1408]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0596, 0.0533, 0.0306]),\n",
      "indices=tensor([1341, 1058, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9381, 0.0116, 0.0058]),\n",
      "indices=tensor([1494, 1223, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7837, 0.0081, 0.0073]),\n",
      "indices=tensor([1319,  985, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1538, 0.0818, 0.0731]),\n",
      "indices=tensor([1395, 1499, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9131e-01, 1.0703e-03, 4.8175e-04]),\n",
      "indices=tensor([1435, 1486, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9949e-01, 5.3485e-05, 3.3415e-05]),\n",
      "indices=tensor([ 956,  990, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1723, 0.0659, 0.0507]),\n",
      "indices=tensor([1438, 1214, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3909, 0.0458, 0.0420]),\n",
      "indices=tensor([1452, 1496, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0609, 0.0516, 0.0348]),\n",
      "indices=tensor([1154, 1045, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8016, 0.0336, 0.0131]),\n",
      "indices=tensor([1446, 1395, 1219]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0465, 0.0426, 0.0408]),\n",
      "indices=tensor([1164, 1395, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1564, 0.0885, 0.0513]),\n",
      "indices=tensor([1496, 1446, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2306, 0.0567, 0.0498]),\n",
      "indices=tensor([1338, 1445, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0442, 0.0409, 0.0409]),\n",
      "indices=tensor([1145, 1390,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1723, 0.0319, 0.0299]),\n",
      "indices=tensor([1268, 1053, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9964e-01, 8.4484e-05, 5.8053e-05]),\n",
      "indices=tensor([1207, 1268, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9966e-01, 2.7552e-05, 2.3158e-05]),\n",
      "indices=tensor([ 956,  990, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9986e-01, 6.0875e-05, 1.0252e-05]),\n",
      "indices=tensor([1378, 1395, 1039]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9956e-01, 8.0078e-05, 5.3796e-05]),\n",
      "indices=tensor([1255, 1321, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0629, 0.0573, 0.0458]),\n",
      "indices=tensor([1496, 1438, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9029, 0.0129, 0.0061]),\n",
      "indices=tensor([ 996, 1152, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9650e-01, 3.8344e-04, 2.6384e-04]),\n",
      "indices=tensor([1258, 1243, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1125, 0.0811, 0.0677]),\n",
      "indices=tensor([ 996, 1403, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0579, 0.0535, 0.0507]),\n",
      "indices=tensor([1123, 1382, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9608e-01, 9.1222e-04, 3.0249e-04]),\n",
      "indices=tensor([1270, 1048, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0593, 0.0543, 0.0542]),\n",
      "indices=tensor([1286, 1031, 1500]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9387, 0.0043, 0.0027]),\n",
      "indices=tensor([1480, 1317, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0625, 0.0597, 0.0527]),\n",
      "indices=tensor([1374, 1438, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1479, 0.0769, 0.0550]),\n",
      "indices=tensor([1496, 1096, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2418, 0.1160, 0.0568]),\n",
      "indices=tensor([1494, 1395, 1499]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2064, 0.0541, 0.0473]),\n",
      "indices=tensor([1286, 1394, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9832e-01, 3.6127e-04, 2.8285e-04]),\n",
      "indices=tensor([1155, 1395, 1295]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1116, 0.0486, 0.0383]),\n",
      "indices=tensor([1377, 1154, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9993e-01, 8.7722e-06, 6.8545e-06]),\n",
      "indices=tensor([ 800, 1053, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3195, 0.0443, 0.0427]),\n",
      "indices=tensor([1479, 1407, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8755e-01, 1.1720e-03, 8.8813e-04]),\n",
      "indices=tensor([1494, 1223, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8722e-01, 1.3426e-03, 8.1507e-04]),\n",
      "indices=tensor([1421, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0554, 0.0425, 0.0392]),\n",
      "indices=tensor([1420, 1447, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9817e-01, 2.4552e-04, 1.0693e-04]),\n",
      "indices=tensor([1387, 1403, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9651e-01, 7.0449e-04, 5.6090e-04]),\n",
      "indices=tensor([1419, 1462, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0970, 0.0737, 0.0641]),\n",
      "indices=tensor([1421, 1489, 1499]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8683e-01, 1.9917e-03, 8.6774e-04]),\n",
      "indices=tensor([1348, 1448, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5743, 0.0382, 0.0318]),\n",
      "indices=tensor([1500, 1139, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9560e-01, 7.6843e-04, 7.3665e-04]),\n",
      "indices=tensor([1395, 1248, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0607, 0.0588, 0.0558]),\n",
      "indices=tensor([1273, 1178, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1446, 0.0851, 0.0615]),\n",
      "indices=tensor([1380, 1394, 1423]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0667, 0.0594, 0.0413]),\n",
      "indices=tensor([1262, 1448, 1126]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0599, 0.0423, 0.0410]),\n",
      "indices=tensor([1437, 1227, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0467, 0.0425, 0.0402]),\n",
      "indices=tensor([1437, 1496, 1022]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9595, 0.0022, 0.0020]),\n",
      "indices=tensor([1285, 1186, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0693, 0.0449, 0.0408]),\n",
      "indices=tensor([1067, 1178, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1138, 0.1109, 0.0617]),\n",
      "indices=tensor([1403, 1438, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9379e-01, 2.1045e-03, 1.6633e-04]),\n",
      "indices=tensor([1343, 1413, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0755, 0.0696, 0.0419]),\n",
      "indices=tensor([1214, 1154, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9682e-01, 6.9083e-04, 5.5994e-04]),\n",
      "indices=tensor([1265, 1252, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4983, 0.0174, 0.0167]),\n",
      "indices=tensor([1500, 1448, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7087, 0.2325, 0.0045]),\n",
      "indices=tensor([1390, 1340, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2071, 0.0952, 0.0656]),\n",
      "indices=tensor([1178, 1438, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2789, 0.1984, 0.1348]),\n",
      "indices=tensor([1391, 1414, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0982, 0.0763, 0.0548]),\n",
      "indices=tensor([1395, 1114, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9854, 0.0045, 0.0014]),\n",
      "indices=tensor([1386, 1357, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9758e-01, 4.7781e-04, 1.8522e-04]),\n",
      "indices=tensor([1207, 1274, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7782, 0.0125, 0.0117]),\n",
      "indices=tensor([1348, 1395, 1500]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8751, 0.0139, 0.0108]),\n",
      "indices=tensor([1383, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9262, 0.0061, 0.0047]),\n",
      "indices=tensor([1244,  996, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9844, 0.0017, 0.0012]),\n",
      "indices=tensor([1266, 1413, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9689, 0.0022, 0.0016]),\n",
      "indices=tensor([ 970, 1164, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0770, 0.0499, 0.0464]),\n",
      "indices=tensor([1403, 1386, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0672, 0.0512, 0.0376]),\n",
      "indices=tensor([1053,  970, 1120]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0799, 0.0660, 0.0381]),\n",
      "indices=tensor([1395, 1154, 1114]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8724, 0.0079, 0.0065]),\n",
      "indices=tensor([1280, 1238, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9995e-01, 1.4766e-05, 4.4862e-06]),\n",
      "indices=tensor([1232, 1326, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9789, 0.0042, 0.0021]),\n",
      "indices=tensor([1321, 1383, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2209, 0.1243, 0.0427]),\n",
      "indices=tensor([1385, 1350, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8481, 0.0249, 0.0204]),\n",
      "indices=tensor([1459, 1413, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0825, 0.0631, 0.0372]),\n",
      "indices=tensor([1498, 1112, 1233]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6940, 0.0420, 0.0248]),\n",
      "indices=tensor([1386, 1550, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9196e-01, 1.1118e-03, 6.5738e-04]),\n",
      "indices=tensor([1495, 1377, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9949e-01, 1.2617e-04, 3.4063e-05]),\n",
      "indices=tensor([1155, 1214, 1348]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9973e-01, 4.6197e-05, 2.1301e-05]),\n",
      "indices=tensor([1152, 1500, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7902e-01, 1.5509e-02, 7.4532e-04]),\n",
      "indices=tensor([1269, 1346, 1293]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9789e-01, 1.3806e-04, 1.2300e-04]),\n",
      "indices=tensor([1276, 1248, 1186]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9364, 0.0311, 0.0202]),\n",
      "indices=tensor([1417, 1438, 1493]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9895e-01, 4.6852e-04, 9.5717e-05]),\n",
      "indices=tensor([1346, 1359, 1202]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9719, 0.0050, 0.0025]),\n",
      "indices=tensor([1180, 1387, 1398]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9947e-01, 7.8340e-05, 7.2650e-05]),\n",
      "indices=tensor([1212, 1338, 1266]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9990e-01, 3.5240e-05, 7.5474e-06]),\n",
      "indices=tensor([1232, 1359, 1325]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9983e-01, 2.4756e-05, 1.8072e-05]),\n",
      "indices=tensor([1224, 1438, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4253, 0.0284, 0.0257]),\n",
      "indices=tensor([ 970, 1218, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0907, 0.0650, 0.0446]),\n",
      "indices=tensor([1403, 1439, 1291]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9690e-01, 1.8061e-04, 1.5325e-04]),\n",
      "indices=tensor([ 990, 1251, 1156]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9985e-01, 1.5812e-05, 1.0860e-05]),\n",
      "indices=tensor([1081, 1168, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2127, 0.0698, 0.0443]),\n",
      "indices=tensor([1398, 1403, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0586, 0.0527, 0.0452]),\n",
      "indices=tensor([1223, 1345, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9164, 0.0150, 0.0097]),\n",
      "indices=tensor([1274, 1346, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9818e-01, 3.2037e-04, 1.4750e-04]),\n",
      "indices=tensor([1156, 1338, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9370, 0.0119, 0.0113]),\n",
      "indices=tensor([1438, 1386, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1024, 0.0650, 0.0595]),\n",
      "indices=tensor([1479, 1550, 1447]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9349, 0.0102, 0.0042]),\n",
      "indices=tensor([1132, 1067, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9952e-01, 1.5276e-04, 6.8709e-05]),\n",
      "indices=tensor([ 986, 1123, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0610, 0.0576, 0.0467]),\n",
      "indices=tensor([1154, 1218, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0941, 0.0625, 0.0552]),\n",
      "indices=tensor([1413, 1465, 1288]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9986e-01, 1.0193e-05, 9.5502e-06]),\n",
      "indices=tensor([1086,  946, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9316, 0.0162, 0.0060]),\n",
      "indices=tensor([1421, 1403, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0763, 0.0495, 0.0411]),\n",
      "indices=tensor([1257, 1244, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9814e-01, 1.6936e-04, 1.0709e-04]),\n",
      "indices=tensor([1447, 1403, 1343]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9258, 0.0083, 0.0069]),\n",
      "indices=tensor([1401, 1496, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0787, 0.0723, 0.0609]),\n",
      "indices=tensor([1478, 1403, 1283]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8080, 0.0177, 0.0065]),\n",
      "indices=tensor([1380, 1421, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7141e-01, 1.6226e-02, 7.7411e-04]),\n",
      "indices=tensor([1437, 1448, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1780, 0.1277, 0.0789]),\n",
      "indices=tensor([1389, 1403, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6823, 0.2665, 0.0087]),\n",
      "indices=tensor([1292, 1269, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9847, 0.0020, 0.0019]),\n",
      "indices=tensor([1257, 1156, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9984e-01, 2.4449e-05, 1.3724e-05]),\n",
      "indices=tensor([1189, 1156, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8622e-01, 9.6640e-03, 5.1954e-04]),\n",
      "indices=tensor([1329, 1296,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0415, 0.0385, 0.0379]),\n",
      "indices=tensor([1053, 1433, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0735, 0.0653, 0.0578]),\n",
      "indices=tensor([1313, 1345, 1339]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9986e-01, 2.3313e-05, 9.4191e-06]),\n",
      "indices=tensor([ 927, 1310, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0998, 0.0716, 0.0431]),\n",
      "indices=tensor([1346, 1455, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9584e-01, 9.3612e-04, 2.0541e-04]),\n",
      "indices=tensor([1045, 1058, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0553, 0.0449, 0.0424]),\n",
      "indices=tensor([1496, 1022, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7372, 0.0778, 0.0236]),\n",
      "indices=tensor([1327, 1387, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0575, 0.0468, 0.0336]),\n",
      "indices=tensor([1339, 1112, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5271, 0.1668, 0.0294]),\n",
      "indices=tensor([1478, 1496, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1263, 0.0697, 0.0649]),\n",
      "indices=tensor([1406, 1380, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9960e-01, 2.0643e-04, 3.4542e-05]),\n",
      "indices=tensor([1295, 1202, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1941, 0.0643, 0.0570]),\n",
      "indices=tensor([1423, 1403, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1133, 0.0551, 0.0436]),\n",
      "indices=tensor([1395, 1123, 1243]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9875, 0.0021, 0.0019]),\n",
      "indices=tensor([1063, 1295, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1186, 0.0520, 0.0507]),\n",
      "indices=tensor([1438, 1209, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0863, 0.0454, 0.0434]),\n",
      "indices=tensor([1319, 1223, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9748, 0.0037, 0.0018]),\n",
      "indices=tensor([1383, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0774, 0.0703, 0.0653]),\n",
      "indices=tensor([1243, 1038, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1226, 0.0670, 0.0538]),\n",
      "indices=tensor([1359, 1053, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8125e-01, 1.3802e-02, 6.5513e-04]),\n",
      "indices=tensor([1417, 1438, 1493]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7082, 0.0129, 0.0116]),\n",
      "indices=tensor([1362, 1047, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0996, 0.0510, 0.0495]),\n",
      "indices=tensor([1357, 1403, 1269]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5221, 0.0389, 0.0332]),\n",
      "indices=tensor([1045, 1196, 1514]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1644, 0.0475, 0.0309]),\n",
      "indices=tensor([1114, 1112, 1238]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0598, 0.0499, 0.0370]),\n",
      "indices=tensor([1308, 1022, 1340]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0754, 0.0530, 0.0521]),\n",
      "indices=tensor([1489, 1310, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0572, 0.0390, 0.0351]),\n",
      "indices=tensor([1478, 1419, 1495]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0495, 0.0491, 0.0488]),\n",
      "indices=tensor([1285, 1178, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9021, 0.0124, 0.0080]),\n",
      "indices=tensor([1313, 1265, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9311, 0.0047, 0.0027]),\n",
      "indices=tensor([1268, 1270, 1297]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9899e-01, 8.4468e-05, 5.7959e-05]),\n",
      "indices=tensor([1142, 1415, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9925e-01, 3.3113e-04, 7.5844e-05]),\n",
      "indices=tensor([1425, 1435, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7206, 0.0158, 0.0125]),\n",
      "indices=tensor([1418, 1403, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9361, 0.0040, 0.0028]),\n",
      "indices=tensor([ 946, 1403, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9280, 0.0160, 0.0069]),\n",
      "indices=tensor([1338, 1415, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0746, 0.0645, 0.0469]),\n",
      "indices=tensor([1053, 1308, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0666, 0.0627, 0.0525]),\n",
      "indices=tensor([1460, 1048, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9879e-01, 1.8457e-04, 9.2382e-05]),\n",
      "indices=tensor([1297, 1392, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9592e-01, 6.8910e-04, 2.7071e-04]),\n",
      "indices=tensor([1252, 1317, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9992e-01, 2.3389e-05, 1.8604e-05]),\n",
      "indices=tensor([1134, 1386, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9726, 0.0114, 0.0011]),\n",
      "indices=tensor([1319, 1356,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0670, 0.0552, 0.0455]),\n",
      "indices=tensor([1456, 1403, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9526e-01, 6.6093e-04, 4.8824e-04]),\n",
      "indices=tensor([1338, 1413, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0645, 0.0621, 0.0468]),\n",
      "indices=tensor([1178, 1492, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3128, 0.0918, 0.0493]),\n",
      "indices=tensor([1494, 1313, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3998, 0.3923, 0.0295]),\n",
      "indices=tensor([1132, 1081, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2453, 0.0500, 0.0458]),\n",
      "indices=tensor([1500, 1255, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0715, 0.0591, 0.0389]),\n",
      "indices=tensor([1131, 1168, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1359, 0.1174, 0.0328]),\n",
      "indices=tensor([1496, 1380, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9718e-01, 5.1451e-04, 2.0102e-04]),\n",
      "indices=tensor([1180, 1347, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0788, 0.0658, 0.0458]),\n",
      "indices=tensor([1403, 1053, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9037, 0.0406, 0.0051]),\n",
      "indices=tensor([1397, 1446, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9996e-01, 1.3685e-05, 2.1473e-06]),\n",
      "indices=tensor([1202, 1305, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0889, 0.0345, 0.0323]),\n",
      "indices=tensor([1499, 1445, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8022e-01, 2.6263e-03, 9.5832e-04]),\n",
      "indices=tensor([1355, 1278, 1480]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8431, 0.0619, 0.0096]),\n",
      "indices=tensor([1209, 1257, 1156]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0668, 0.0488, 0.0396]),\n",
      "indices=tensor([1154, 1045, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9936e-01, 5.9360e-05, 4.0849e-05]),\n",
      "indices=tensor([1038, 1112, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9881e-01, 2.8081e-04, 1.3160e-04]),\n",
      "indices=tensor([1145, 1455, 1414]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0528, 0.0494, 0.0481]),\n",
      "indices=tensor([1456, 1209, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1037, 0.0668, 0.0481]),\n",
      "indices=tensor([1392, 1278, 1142]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0610, 0.0577, 0.0476]),\n",
      "indices=tensor([1359, 1403, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0690, 0.0525, 0.0512]),\n",
      "indices=tensor([1489, 1403, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9764e-01, 4.8844e-04, 3.1149e-04]),\n",
      "indices=tensor([1310, 1674, 1291]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3679, 0.0393, 0.0372]),\n",
      "indices=tensor([1009, 1154, 1189]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4308, 0.0373, 0.0365]),\n",
      "indices=tensor([1514, 1419, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0684, 0.0612, 0.0562]),\n",
      "indices=tensor([1403, 1178, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5117, 0.3118, 0.0472]),\n",
      "indices=tensor([1548, 1391, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3635, 0.0402, 0.0390]),\n",
      "indices=tensor([1409, 1421, 1203]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0598, 0.0584, 0.0480]),\n",
      "indices=tensor([1126, 1385, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8735, 0.0893, 0.0043]),\n",
      "indices=tensor([1252, 1282, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8773e-01, 1.1896e-03, 6.9624e-04]),\n",
      "indices=tensor([1397, 1437, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0710, 0.0613, 0.0505]),\n",
      "indices=tensor([1382, 1460, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9327, 0.0172, 0.0033]),\n",
      "indices=tensor([1288, 1413, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9770e-01, 9.7810e-04, 1.6071e-04]),\n",
      "indices=tensor([1440, 1438, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8457, 0.0219, 0.0091]),\n",
      "indices=tensor([1223, 1288, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0853, 0.0403, 0.0372]),\n",
      "indices=tensor([1308, 1292, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9928e-01, 5.0790e-05, 3.0154e-05]),\n",
      "indices=tensor([1047, 1377, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7454, 0.1485, 0.0119]),\n",
      "indices=tensor([1485, 1408, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9767, 0.0017, 0.0016]),\n",
      "indices=tensor([1112, 1283, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9571, 0.0073, 0.0025]),\n",
      "indices=tensor([1392, 1308, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9633, 0.0149, 0.0023]),\n",
      "indices=tensor([1207, 1274, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2514, 0.0846, 0.0485]),\n",
      "indices=tensor([ 988, 1031, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9105, 0.0106, 0.0095]),\n",
      "indices=tensor([1338, 1387, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9733, 0.0057, 0.0017]),\n",
      "indices=tensor([1448, 1437, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9595e-01, 2.7826e-04, 2.6794e-04]),\n",
      "indices=tensor([1218, 1123, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2540, 0.0617, 0.0471]),\n",
      "indices=tensor([1438, 1406, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0506, 0.0463, 0.0458]),\n",
      "indices=tensor([1284, 1038,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1390, 0.0881, 0.0669]),\n",
      "indices=tensor([1403, 1383, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9756, 0.0026, 0.0015]),\n",
      "indices=tensor([1414, 1332, 1344]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9944e-01, 2.1555e-04, 2.8275e-05]),\n",
      "indices=tensor([1447, 1383, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0449, 0.0412, 0.0399]),\n",
      "indices=tensor([1110, 1009, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2383, 0.0828, 0.0404]),\n",
      "indices=tensor([1550, 1380, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0977, 0.0582, 0.0550]),\n",
      "indices=tensor([1313, 1233, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7723, 0.0235, 0.0148]),\n",
      "indices=tensor([1280,  941, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1457, 0.0364, 0.0348]),\n",
      "indices=tensor([1382, 1283, 1500]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0915, 0.0789, 0.0460]),\n",
      "indices=tensor([1496, 1550, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3653, 0.0999, 0.0574]),\n",
      "indices=tensor([1262, 1308, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3485, 0.0610, 0.0508]),\n",
      "indices=tensor([1440, 1438, 1492]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8001, 0.0813, 0.0042]),\n",
      "indices=tensor([1357, 1319, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8673, 0.0784, 0.0044]),\n",
      "indices=tensor([1406, 1429, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1716, 0.0641, 0.0521]),\n",
      "indices=tensor([ 941, 1514, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2293, 0.1886, 0.1269]),\n",
      "indices=tensor([1403, 1411, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0760, 0.0715, 0.0580]),\n",
      "indices=tensor([1362, 1126, 1203]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9998e-01, 6.1966e-06, 9.0430e-07]),\n",
      "indices=tensor([1202, 1305, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9958e-01, 1.6111e-04, 2.3071e-05]),\n",
      "indices=tensor([1437, 1448, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0796, 0.0455, 0.0421]),\n",
      "indices=tensor([1382, 1218, 1389]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3039, 0.0551, 0.0408]),\n",
      "indices=tensor([1110, 1489, 1219]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9998e-01, 2.5398e-06, 1.6147e-06]),\n",
      "indices=tensor([ 927, 1193, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7923, 0.1598, 0.0034]),\n",
      "indices=tensor([1387, 1348, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5322, 0.3434, 0.0184]),\n",
      "indices=tensor([1392, 1500, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0523, 0.0442, 0.0440]),\n",
      "indices=tensor([1398, 1380, 1120]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2217, 0.0972, 0.0426]),\n",
      "indices=tensor([1209, 1123, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4326, 0.0635, 0.0509]),\n",
      "indices=tensor([1443, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1172, 0.0897, 0.0418]),\n",
      "indices=tensor([1380, 1448, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2602, 0.0409, 0.0285]),\n",
      "indices=tensor([1414, 1377, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0695, 0.0548, 0.0466]),\n",
      "indices=tensor([1460, 1380, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9473, 0.0037, 0.0036]),\n",
      "indices=tensor([1341, 1437, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0578, 0.0571, 0.0525]),\n",
      "indices=tensor([1045, 1448, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0508, 0.0500, 0.0462]),\n",
      "indices=tensor([1196, 1406, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9816e-01, 8.3079e-04, 1.4868e-04]),\n",
      "indices=tensor([1479, 1459, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0762, 0.0598, 0.0487]),\n",
      "indices=tensor([1218, 1110, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0766, 0.0480, 0.0471]),\n",
      "indices=tensor([1493, 1096,  941]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9327e-01, 3.4738e-03, 6.7298e-04]),\n",
      "indices=tensor([1268, 1207, 1403]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([9.8618e-01, 1.4834e-03, 8.2663e-04]),\n",
      "indices=tensor([1410, 1131, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9727e-01, 8.5354e-04, 1.8365e-04]),\n",
      "indices=tensor([1455, 1421, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9931e-01, 1.1141e-04, 5.0118e-05]),\n",
      "indices=tensor([1117, 1674, 1164]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0808, 0.0672, 0.0552]),\n",
      "indices=tensor([1459, 1377, 1288]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6349, 0.0526, 0.0249]),\n",
      "indices=tensor([1315, 1218, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9355, 0.0068, 0.0066]),\n",
      "indices=tensor([1227, 1395, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9825, 0.0071, 0.0012]),\n",
      "indices=tensor([1283, 1273, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1611, 0.0786, 0.0548]),\n",
      "indices=tensor([1413, 1403, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8123, 0.0136, 0.0104]),\n",
      "indices=tensor([1494, 1390, 1493]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9210, 0.0054, 0.0051]),\n",
      "indices=tensor([1248, 1395,  956]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6019, 0.2600, 0.0205]),\n",
      "indices=tensor([1440, 1380, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4900, 0.0441, 0.0336]),\n",
      "indices=tensor([1238, 1329, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0407, 0.0394, 0.0363]),\n",
      "indices=tensor([1486, 1096, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0533, 0.0439, 0.0424]),\n",
      "indices=tensor([1489, 1039, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0627, 0.0522, 0.0499]),\n",
      "indices=tensor([1223, 1058, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6467, 0.2303, 0.0087]),\n",
      "indices=tensor([1347, 1418, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7649, 0.0165, 0.0104]),\n",
      "indices=tensor([1390, 1308, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9887e-01, 1.9937e-04, 8.2581e-05]),\n",
      "indices=tensor([1310, 1674,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0541, 0.0513, 0.0473]),\n",
      "indices=tensor([1047, 1178, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9741e-01, 5.1530e-04, 3.5140e-04]),\n",
      "indices=tensor([1282, 1380, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9818e-01, 1.8360e-04, 8.5776e-05]),\n",
      "indices=tensor([1431, 1196, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9922e-01, 1.4137e-04, 3.7040e-05]),\n",
      "indices=tensor([1117, 1674, 1082]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9811, 0.0076, 0.0012]),\n",
      "indices=tensor([1400, 1465, 1453]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4279, 0.2860, 0.0297]),\n",
      "indices=tensor([1393, 1421, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9476, 0.0100, 0.0053]),\n",
      "indices=tensor([1406, 1489, 1393]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1236, 0.0657, 0.0534]),\n",
      "indices=tensor([1403, 1406, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9992e-01, 1.6622e-05, 9.0991e-06]),\n",
      "indices=tensor([1378, 1214, 1270]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1273, 0.0750, 0.0731]),\n",
      "indices=tensor([1452, 1448,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1891, 0.0375, 0.0351]),\n",
      "indices=tensor([1330, 1438, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9997e-01, 3.1582e-06, 3.1398e-06]),\n",
      "indices=tensor([ 927,  988, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9820, 0.0061, 0.0033]),\n",
      "indices=tensor([1143, 1244, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0386, 0.0370, 0.0320]),\n",
      "indices=tensor([1448, 1096,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0871, 0.0451, 0.0439]),\n",
      "indices=tensor([1448,  970, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9807, 0.0137, 0.0013]),\n",
      "indices=tensor([1325, 1295, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0930, 0.0454, 0.0344]),\n",
      "indices=tensor([1437, 1403, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9282e-01, 5.3421e-04, 2.9409e-04]),\n",
      "indices=tensor([1285, 1403, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9984e-01, 3.5202e-05, 1.3162e-05]),\n",
      "indices=tensor([1189, 1156, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9649e-01, 2.6683e-04, 2.6118e-04]),\n",
      "indices=tensor([1359, 1550, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9835e-01, 1.3644e-04, 1.1037e-04]),\n",
      "indices=tensor([1530, 1674, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0911, 0.0594, 0.0558]),\n",
      "indices=tensor([1500, 1382, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.4716e-01, 4.3423e-02, 7.7275e-04]),\n",
      "indices=tensor([1186, 1123, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0639, 0.0537, 0.0535]),\n",
      "indices=tensor([1322, 1514, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0569, 0.0434, 0.0296]),\n",
      "indices=tensor([1403, 1341, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3211, 0.1856, 0.0324]),\n",
      "indices=tensor([1117, 1152, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9168, 0.0125, 0.0104]),\n",
      "indices=tensor([1231, 1355, 1203]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0690, 0.0675, 0.0476]),\n",
      "indices=tensor([1112, 1110, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1181, 0.1012, 0.0626]),\n",
      "indices=tensor([1403, 1383, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8751, 0.0261, 0.0058]),\n",
      "indices=tensor([1286, 1244,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9543e-01, 3.0380e-04, 2.4569e-04]),\n",
      "indices=tensor([1031, 1214, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1212, 0.0496, 0.0402]),\n",
      "indices=tensor([1438, 1386, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5073, 0.0474, 0.0370]),\n",
      "indices=tensor([1674, 1433, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9005e-01, 7.9760e-04, 6.7536e-04]),\n",
      "indices=tensor([1485, 1309, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9653e-01, 2.5876e-04, 2.2287e-04]),\n",
      "indices=tensor([1308, 1460, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0583, 0.0547, 0.0503]),\n",
      "indices=tensor([1374, 1178, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0687, 0.0583, 0.0494]),\n",
      "indices=tensor([1448, 1308, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2568, 0.1167, 0.0587]),\n",
      "indices=tensor([1428, 1496, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4299, 0.0472, 0.0399]),\n",
      "indices=tensor([1370, 1415, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5834, 0.0304, 0.0253]),\n",
      "indices=tensor([1359, 1292, 1269]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8130, 0.1198, 0.0077]),\n",
      "indices=tensor([1452, 1428, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9899, 0.0016, 0.0014]),\n",
      "indices=tensor([1186, 1291, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1008, 0.0845, 0.0733]),\n",
      "indices=tensor([1403, 1152, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0648, 0.0502, 0.0454]),\n",
      "indices=tensor([1219, 1233,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7934, 0.0182, 0.0146]),\n",
      "indices=tensor([1303, 1341, 1385]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9849, 0.0019, 0.0010]),\n",
      "indices=tensor([ 996, 1112, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9784, 0.0013, 0.0011]),\n",
      "indices=tensor([1392, 1425, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9574, 0.0069, 0.0026]),\n",
      "indices=tensor([1440, 1438, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0661, 0.0637, 0.0610]),\n",
      "indices=tensor([1415, 1053, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0424, 0.0391, 0.0382]),\n",
      "indices=tensor([1485, 1486, 1471]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9979e-01, 5.6503e-05, 3.0233e-05]),\n",
      "indices=tensor([1480, 1448, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2650, 0.1361, 0.0417]),\n",
      "indices=tensor([1346, 1550, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9851e-01, 1.9012e-04, 1.3634e-04]),\n",
      "indices=tensor([1455, 1433, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0808, 0.0759, 0.0743]),\n",
      "indices=tensor([1472, 1448, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9092e-01, 1.0619e-03, 8.2533e-04]),\n",
      "indices=tensor([1155, 1380,  996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1537, 0.0871, 0.0806]),\n",
      "indices=tensor([1092, 1186, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9976e-01, 4.5587e-05, 1.8889e-05]),\n",
      "indices=tensor([1447, 1383, 1454]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9555, 0.0138, 0.0021]),\n",
      "indices=tensor([1167, 1240, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0905, 0.0791, 0.0488]),\n",
      "indices=tensor([1445, 1284, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0508, 0.0346, 0.0308]),\n",
      "indices=tensor([1145, 1112, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8608, 0.0084, 0.0078]),\n",
      "indices=tensor([1277, 1308, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1054, 0.0741, 0.0728]),\n",
      "indices=tensor([1421, 1496, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1028, 0.0777, 0.0579]),\n",
      "indices=tensor([ 941, 1305, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0710, 0.0672, 0.0502]),\n",
      "indices=tensor([1315, 1321, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9839, 0.0023, 0.0011]),\n",
      "indices=tensor([1280, 1297, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5101, 0.0534, 0.0517]),\n",
      "indices=tensor([1396, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5328, 0.0602, 0.0500]),\n",
      "indices=tensor([1048, 1218, 1295]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9368, 0.0122, 0.0048]),\n",
      "indices=tensor([1277, 1339, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9823, 0.0059, 0.0028]),\n",
      "indices=tensor([1419, 1462, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0986, 0.0569, 0.0547]),\n",
      "indices=tensor([1345, 1213, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0677, 0.0540, 0.0477]),\n",
      "indices=tensor([1285,  983, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2622, 0.1027, 0.0941]),\n",
      "indices=tensor([1406, 1550, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0656, 0.0450, 0.0362]),\n",
      "indices=tensor([1313, 1496,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1110, 0.0554, 0.0408]),\n",
      "indices=tensor([1218, 1293, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9540e-01, 1.5267e-03, 2.1133e-04]),\n",
      "indices=tensor([1078, 1117, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9790e-01, 2.8661e-04, 1.5860e-04]),\n",
      "indices=tensor([1382, 1448, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9568e-01, 5.6748e-04, 4.2068e-04]),\n",
      "indices=tensor([1053, 1500, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9743, 0.0048, 0.0045]),\n",
      "indices=tensor([1329, 1321, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9969e-01, 1.1748e-04, 2.3701e-05]),\n",
      "indices=tensor([1413, 1406, 1396]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6766, 0.0171, 0.0165]),\n",
      "indices=tensor([1420, 1413, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8789, 0.0061, 0.0061]),\n",
      "indices=tensor([1323, 1492, 1120]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1035, 0.0829, 0.0519]),\n",
      "indices=tensor([1380, 1448, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9794, 0.0027, 0.0026]),\n",
      "indices=tensor([1227, 1395, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1296, 0.0469, 0.0423]),\n",
      "indices=tensor([1438, 1313, 1496]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([9.9884e-01, 1.7096e-04, 1.2181e-04]),\n",
      "indices=tensor([1048, 1332, 1123]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0536, 0.0477, 0.0404]),\n",
      "indices=tensor([1248, 1283, 1303]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8468, 0.0762, 0.0060]),\n",
      "indices=tensor([1244, 1293, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0576, 0.0502, 0.0460]),\n",
      "indices=tensor([1112, 1448, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9131, 0.0181, 0.0040]),\n",
      "indices=tensor([1114, 1139, 1514]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9003e-01, 2.4245e-03, 9.1738e-04]),\n",
      "indices=tensor([1367, 1409, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2721, 0.0667, 0.0643]),\n",
      "indices=tensor([1396, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9172, 0.0205, 0.0076]),\n",
      "indices=tensor([1500, 1392, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9938e-01, 8.1015e-05, 3.8130e-05]),\n",
      "indices=tensor([1168, 1280, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9923e-01, 6.9972e-05, 4.4669e-05]),\n",
      "indices=tensor([ 987, 1053, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2124, 0.1446, 0.0649]),\n",
      "indices=tensor([1293, 1277, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0378, 0.0336, 0.0280]),\n",
      "indices=tensor([1053, 1319, 1375]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9355e-01, 5.1981e-04, 4.1762e-04]),\n",
      "indices=tensor([1219, 1167, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1913, 0.0729, 0.0671]),\n",
      "indices=tensor([1313, 1394, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8992, 0.0804, 0.0074]),\n",
      "indices=tensor([1350, 1405, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0808, 0.0613, 0.0391]),\n",
      "indices=tensor([1313, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9288, 0.0046, 0.0042]),\n",
      "indices=tensor([1329, 1496, 1022]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0749, 0.0457, 0.0396]),\n",
      "indices=tensor([1438, 1496, 1203]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9732e-01, 2.8137e-04, 2.0240e-04]),\n",
      "indices=tensor([1265, 1219, 1408]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1050, 0.0690, 0.0498]),\n",
      "indices=tensor([1022, 1382, 1345]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0887, 0.0534, 0.0456]),\n",
      "indices=tensor([1223,  970, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9843e-01, 1.4986e-04, 1.3474e-04]),\n",
      "indices=tensor([1400, 1215, 1452]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1228, 0.1027, 0.0670]),\n",
      "indices=tensor([1308, 1218, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9156e-01, 6.9883e-04, 4.6505e-04]),\n",
      "indices=tensor([1397, 1437, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1766, 0.0990, 0.0397]),\n",
      "indices=tensor([1362, 1496, 1309]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2619, 0.0668, 0.0351]),\n",
      "indices=tensor([1323, 1395, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9982e-01, 2.6407e-05, 1.3469e-05]),\n",
      "indices=tensor([1078, 1117, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1757, 0.1152, 0.0409]),\n",
      "indices=tensor([1269, 1413,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9632e-01, 2.1417e-03, 1.4181e-04]),\n",
      "indices=tensor([1048, 1332, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0449, 0.0395, 0.0373]),\n",
      "indices=tensor([1496, 1456, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9184, 0.0050, 0.0043]),\n",
      "indices=tensor([1156, 1674, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0709, 0.0556, 0.0533]),\n",
      "indices=tensor([1178, 1078, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8339, 0.0618, 0.0337]),\n",
      "indices=tensor([1418, 1347, 1385]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9373, 0.0053, 0.0039]),\n",
      "indices=tensor([1417, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9467, 0.0050, 0.0031]),\n",
      "indices=tensor([1266, 1413, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9117, 0.0067, 0.0057]),\n",
      "indices=tensor([1347, 1317, 1459]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9924, 0.0019, 0.0014]),\n",
      "indices=tensor([1319, 1357, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2657, 0.0339, 0.0319]),\n",
      "indices=tensor([1357, 1403, 1366]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1936, 0.1573, 0.1376]),\n",
      "indices=tensor([1387, 1395, 1390]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5672, 0.1505, 0.0392]),\n",
      "indices=tensor([1408, 1391, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9421e-01, 1.0950e-03, 6.8406e-04]),\n",
      "indices=tensor([1110, 1308, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8196, 0.0104, 0.0094]),\n",
      "indices=tensor([1397, 1448, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1116, 0.0742, 0.0590]),\n",
      "indices=tensor([1438, 1230, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9581, 0.0042, 0.0039]),\n",
      "indices=tensor([1092, 1390, 1276]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0955, 0.0589, 0.0404]),\n",
      "indices=tensor([1403, 1550, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1012, 0.0891, 0.0518]),\n",
      "indices=tensor([1459, 1377, 1297]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9905e-01, 3.5499e-04, 1.0374e-04]),\n",
      "indices=tensor([1350, 1409, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9507e-01, 5.9231e-04, 2.9654e-04]),\n",
      "indices=tensor([1308, 1196, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9118e-01, 9.6454e-04, 3.0781e-04]),\n",
      "indices=tensor([1413, 1438, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1735, 0.0616, 0.0574]),\n",
      "indices=tensor([1347, 1317, 1459]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8471, 0.0125, 0.0080]),\n",
      "indices=tensor([1214, 1345, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6573, 0.0198, 0.0147]),\n",
      "indices=tensor([1348, 1439, 1082]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8753, 0.0155, 0.0072]),\n",
      "indices=tensor([1244, 1319, 1257]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9899e-01, 1.0360e-04, 7.6246e-05]),\n",
      "indices=tensor([1110, 1286, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9676, 0.0094, 0.0043]),\n",
      "indices=tensor([1399, 1338, 1212]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8903e-01, 7.1485e-04, 6.2849e-04]),\n",
      "indices=tensor([1110, 1223, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1385, 0.0688, 0.0529]),\n",
      "indices=tensor([1313, 1213,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1037, 0.0545, 0.0539]),\n",
      "indices=tensor([1292, 1053, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0730, 0.0728, 0.0294]),\n",
      "indices=tensor([1283,  946, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9883, 0.0046, 0.0032]),\n",
      "indices=tensor([1316, 1448, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1416, 0.0626, 0.0611]),\n",
      "indices=tensor([1321, 1112, 1230]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0959, 0.0545, 0.0429]),\n",
      "indices=tensor([1394, 1429, 1417]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9093, 0.0056, 0.0054]),\n",
      "indices=tensor([1238, 1044, 1378]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1574, 0.0645, 0.0599]),\n",
      "indices=tensor([1431, 1403, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9382, 0.0445, 0.0022]),\n",
      "indices=tensor([1292, 1255, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9853, 0.0019, 0.0010]),\n",
      "indices=tensor([1297, 1345,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9829e-01, 7.6225e-04, 1.2961e-04]),\n",
      "indices=tensor([1211, 1395, 1375]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0491, 0.0401, 0.0351]),\n",
      "indices=tensor([1448, 1413, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9265e-01, 2.0277e-03, 8.9481e-04]),\n",
      "indices=tensor([1377, 1348, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9643, 0.0041, 0.0038]),\n",
      "indices=tensor([1355, 1485, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9814e-01, 2.6462e-04, 1.6464e-04]),\n",
      "indices=tensor([1400, 1452, 1215]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0494, 0.0486, 0.0428]),\n",
      "indices=tensor([1674, 1308, 1164]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0650, 0.0645, 0.0605]),\n",
      "indices=tensor([1218, 1500, 1332]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9811, 0.0021, 0.0016]),\n",
      "indices=tensor([ 287, 1112, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1910, 0.1078, 0.0608]),\n",
      "indices=tensor([1403, 1227, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2128, 0.1065, 0.0262]),\n",
      "indices=tensor([1447, 1407, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0686, 0.0462, 0.0418]),\n",
      "indices=tensor([1154, 1218, 1323]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4304, 0.3571, 0.0156]),\n",
      "indices=tensor([1283, 1273, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0653, 0.0604, 0.0556]),\n",
      "indices=tensor([1460, 1285, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0571, 0.0489, 0.0425]),\n",
      "indices=tensor([1387, 1386, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9880, 0.0014, 0.0012]),\n",
      "indices=tensor([ 951, 1053, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0872, 0.0688, 0.0503]),\n",
      "indices=tensor([1437, 1486, 1374]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9114, 0.0137, 0.0101]),\n",
      "indices=tensor([1375, 1350, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1214, 0.0855, 0.0318]),\n",
      "indices=tensor([1152, 1308, 1179]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9394e-01, 2.7072e-03, 6.7013e-04]),\n",
      "indices=tensor([1266, 1359, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3919, 0.0247, 0.0216]),\n",
      "indices=tensor([1429, 1462, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2323, 0.1692, 0.0415]),\n",
      "indices=tensor([1386, 1429, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9683e-01, 2.1732e-04, 1.8209e-04]),\n",
      "indices=tensor([1276, 1460, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0753, 0.0644, 0.0626]),\n",
      "indices=tensor([1460, 1112, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0604, 0.0597, 0.0496]),\n",
      "indices=tensor([1460, 1395, 1131]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5367, 0.0470, 0.0377]),\n",
      "indices=tensor([1393, 1496, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9903e-01, 1.1803e-04, 8.9840e-05]),\n",
      "indices=tensor([1382, 1448, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2777, 0.0644, 0.0473]),\n",
      "indices=tensor([1387, 1112, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0845, 0.0625, 0.0615]),\n",
      "indices=tensor([1486, 1053, 1269]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5001, 0.0874, 0.0275]),\n",
      "indices=tensor([1252, 1218, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0825, 0.0615, 0.0529]),\n",
      "indices=tensor([1413, 1403,  996]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([9.9813e-01, 4.0740e-04, 3.2273e-04]),\n",
      "indices=tensor([1265, 1252, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3266, 0.1098, 0.0362]),\n",
      "indices=tensor([1550, 1496,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9877e-01, 1.2583e-04, 8.1865e-05]),\n",
      "indices=tensor([1341, 1252, 1446]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9001, 0.0736, 0.0020]),\n",
      "indices=tensor([1252, 1273, 1219]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9814e-01, 1.2171e-03, 7.0244e-05]),\n",
      "indices=tensor([1425, 1435, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1377, 0.0535, 0.0498]),\n",
      "indices=tensor([1309, 1252, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0558, 0.0518, 0.0506]),\n",
      "indices=tensor([1214, 1126, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6763, 0.0826, 0.0817]),\n",
      "indices=tensor([1462, 1445, 1419]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9875e-01, 1.7292e-04, 1.0132e-04]),\n",
      "indices=tensor([1081, 1433, 1274]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9677e-01, 9.5350e-04, 1.8868e-04]),\n",
      "indices=tensor([1219, 1255, 1167]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2731, 0.0584, 0.0565]),\n",
      "indices=tensor([1344, 1550, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1110, 0.0519, 0.0469]),\n",
      "indices=tensor([1395, 1403, 1480]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9574e-01, 5.5491e-04, 3.6649e-04]),\n",
      "indices=tensor([1395, 1380, 1453]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9358, 0.0097, 0.0069]),\n",
      "indices=tensor([1452, 1460, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9559, 0.0150, 0.0031]),\n",
      "indices=tensor([1178, 1258, 1123]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0570, 0.0530, 0.0523]),\n",
      "indices=tensor([1500, 1389, 1348]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9903e-01, 6.2453e-05, 4.2777e-05]),\n",
      "indices=tensor([1456, 1398,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8829e-01, 2.7791e-03, 7.1949e-04]),\n",
      "indices=tensor([1446, 1397, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8396, 0.1168, 0.0038]),\n",
      "indices=tensor([1428, 1452, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7236, 0.0720, 0.0326]),\n",
      "indices=tensor([1408, 1308, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9560e-01, 4.1837e-04, 3.8436e-04]),\n",
      "indices=tensor([1406, 1403, 1453]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8639e-01, 9.9678e-04, 9.7911e-04]),\n",
      "indices=tensor([1414, 1406, 1332]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0360, 0.0359, 0.0358]),\n",
      "indices=tensor([1291, 1641, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8352e-01, 5.8380e-03, 4.4381e-04]),\n",
      "indices=tensor([1215, 1152, 1086]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2322, 0.0488, 0.0439]),\n",
      "indices=tensor([1286, 1031, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6321, 0.0479, 0.0169]),\n",
      "indices=tensor([1447, 1407, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9330, 0.0114, 0.0042]),\n",
      "indices=tensor([1238, 1403, 1408]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7117, 0.2336, 0.0045]),\n",
      "indices=tensor([1291, 1186, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0854, 0.0528, 0.0482]),\n",
      "indices=tensor([1437, 1415, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9075e-01, 4.0842e-03, 4.5615e-04]),\n",
      "indices=tensor([985, 946, 996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4755, 0.2440, 0.0278]),\n",
      "indices=tensor([1421, 1455, 1485]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1358, 0.0892, 0.0447]),\n",
      "indices=tensor([1550, 1394, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3689, 0.0499, 0.0466]),\n",
      "indices=tensor([1341, 1674, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7878e-01, 1.0481e-03, 9.7338e-04]),\n",
      "indices=tensor([1339,  946, 1396]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9698e-01, 6.6827e-04, 2.7218e-04]),\n",
      "indices=tensor([1387, 1403, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9188e-01, 1.5297e-03, 4.8517e-04]),\n",
      "indices=tensor([1309, 1419, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7028, 0.2854, 0.0015]),\n",
      "indices=tensor([1465, 1413, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9628, 0.0046, 0.0021]),\n",
      "indices=tensor([1123, 1209, 1048]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0855, 0.0641, 0.0616]),\n",
      "indices=tensor([1435, 1455, 1471]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0893, 0.0639, 0.0484]),\n",
      "indices=tensor([1403, 1330, 1243]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1174, 0.0769, 0.0662]),\n",
      "indices=tensor([1413, 1496, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0444, 0.0442, 0.0376]),\n",
      "indices=tensor([1409, 1436, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9989e-01, 1.2490e-05, 9.8261e-06]),\n",
      "indices=tensor([ 800, 1031, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1947, 0.0664, 0.0522]),\n",
      "indices=tensor([1445, 1255, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0511, 0.0469, 0.0320]),\n",
      "indices=tensor([1387, 1436, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9615e-01, 3.5121e-04, 1.7926e-04]),\n",
      "indices=tensor([1270, 1395,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9989e-01, 1.5206e-05, 1.2661e-05]),\n",
      "indices=tensor([1152, 1308, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9190e-01, 5.0748e-04, 4.2663e-04]),\n",
      "indices=tensor([1278, 1262, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8838e-01, 1.7049e-03, 8.0830e-04]),\n",
      "indices=tensor([1419, 1489, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9899e-01, 1.5167e-04, 1.1000e-04]),\n",
      "indices=tensor([1455, 1421, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9816, 0.0063, 0.0042]),\n",
      "indices=tensor([1295, 1248, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6095, 0.0169, 0.0147]),\n",
      "indices=tensor([1341, 1548, 1303]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9594e-01, 2.7480e-03, 4.7838e-04]),\n",
      "indices=tensor([1305, 1219, 1202]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9987e-01, 1.9732e-05, 1.3654e-05]),\n",
      "indices=tensor([1067, 1152, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8843, 0.0689, 0.0046]),\n",
      "indices=tensor([1423, 1380, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1726, 0.0662, 0.0622]),\n",
      "indices=tensor([1413, 1313, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5810, 0.0790, 0.0270]),\n",
      "indices=tensor([1273, 1283, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0822, 0.0554, 0.0483]),\n",
      "indices=tensor([1117, 1283, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9072, 0.0398, 0.0110]),\n",
      "indices=tensor([1193, 1258, 1346]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7939, 0.0099, 0.0085]),\n",
      "indices=tensor([1445, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9812e-01, 4.7240e-04, 1.5580e-04]),\n",
      "indices=tensor([1338, 1415, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9680e-01, 5.5774e-04, 4.5606e-04]),\n",
      "indices=tensor([1362, 1304, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9364, 0.0029, 0.0027]),\n",
      "indices=tensor([1514, 1403, 1498]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7489, 0.0201, 0.0192]),\n",
      "indices=tensor([1293, 1277, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8892, 0.0319, 0.0105]),\n",
      "indices=tensor([1396, 1413, 1343]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9841, 0.0023, 0.0014]),\n",
      "indices=tensor([1082,  988, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9700, 0.0059, 0.0031]),\n",
      "indices=tensor([1391, 1408, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0410, 0.0343, 0.0309]),\n",
      "indices=tensor([1485, 1445, 1429]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1870, 0.0727, 0.0495]),\n",
      "indices=tensor([1313, 1213,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9305e-01, 1.3372e-03, 5.3623e-04]),\n",
      "indices=tensor([1179, 1152, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4160, 0.3656, 0.0375]),\n",
      "indices=tensor([1078, 1273, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2913, 0.0754, 0.0606]),\n",
      "indices=tensor([1155, 1154, 1192]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9977e-01, 3.4628e-05, 2.2870e-05]),\n",
      "indices=tensor([1288, 1403, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1543, 0.1417, 0.1080]),\n",
      "indices=tensor([1413, 1496, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6238, 0.0879, 0.0422]),\n",
      "indices=tensor([1495, 1494, 1480]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9484, 0.0196, 0.0023]),\n",
      "indices=tensor([1230, 1243, 1227]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1044, 0.0691, 0.0555]),\n",
      "indices=tensor([1496, 1283, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7893e-01, 2.1644e-03, 9.2532e-04]),\n",
      "indices=tensor([1392, 1244, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2695, 0.0750, 0.0613]),\n",
      "indices=tensor([1485, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7142, 0.0299, 0.0183]),\n",
      "indices=tensor([1397, 1145, 1492]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9640, 0.0116, 0.0017]),\n",
      "indices=tensor([1357, 1435, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9157e-01, 2.2500e-03, 4.4092e-04]),\n",
      "indices=tensor([1329, 1203, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9615, 0.0173, 0.0012]),\n",
      "indices=tensor([1485, 1455, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0870, 0.0530, 0.0304]),\n",
      "indices=tensor([1377, 1429, 1493]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0644, 0.0454, 0.0436]),\n",
      "indices=tensor([1022, 1233,  983]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1066, 0.0711, 0.0683]),\n",
      "indices=tensor([1406, 1403, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0566, 0.0564, 0.0539]),\n",
      "indices=tensor([1406, 1496, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8875, 0.0123, 0.0120]),\n",
      "indices=tensor([1130, 1313, 1238]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4919, 0.0359, 0.0310]),\n",
      "indices=tensor([1068,  983, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7117, 0.0148, 0.0103]),\n",
      "indices=tensor([1272, 1303, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9964e-01, 4.4594e-05, 2.3358e-05]),\n",
      "indices=tensor([1270, 1218, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0684, 0.0497, 0.0478]),\n",
      "indices=tensor([1053, 1438, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1996, 0.0481, 0.0411]),\n",
      "indices=tensor([1403, 1383, 1453]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9546e-01, 5.6705e-04, 4.9270e-04]),\n",
      "indices=tensor([1674, 1496, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2513, 0.0507, 0.0491]),\n",
      "indices=tensor([1500, 1550, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9657e-01, 2.8941e-04, 2.2748e-04]),\n",
      "indices=tensor([1410, 1386, 1131]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6758, 0.0155, 0.0154]),\n",
      "indices=tensor([1357, 1403, 1366]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0940, 0.0427, 0.0423]),\n",
      "indices=tensor([1448, 1395, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9872, 0.0037, 0.0018]),\n",
      "indices=tensor([1284, 1202, 1197]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0986, 0.0463, 0.0445]),\n",
      "indices=tensor([1112, 1330, 1492]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9306, 0.0086, 0.0065]),\n",
      "indices=tensor([1380, 1308, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0819, 0.0789, 0.0429]),\n",
      "indices=tensor([1472, 1445,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5097, 0.0462, 0.0263]),\n",
      "indices=tensor([1192,  990, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1170, 0.0774, 0.0528]),\n",
      "indices=tensor([1403, 1296, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7570, 0.1621, 0.0109]),\n",
      "indices=tensor([1494, 1550, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0611, 0.0599, 0.0536]),\n",
      "indices=tensor([1465, 1498, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0414, 0.0383, 0.0336]),\n",
      "indices=tensor([1403, 1278, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7085, 0.0244, 0.0173]),\n",
      "indices=tensor([1522, 1394,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1202, 0.0442, 0.0418]),\n",
      "indices=tensor([1460, 1382, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8780, 0.0087, 0.0063]),\n",
      "indices=tensor([1414, 1377, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9910, 0.0013, 0.0010]),\n",
      "indices=tensor([1339, 1110, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8208, 0.0289, 0.0082]),\n",
      "indices=tensor([1400, 1382,  985]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8513, 0.0226, 0.0098]),\n",
      "indices=tensor([1297, 1362, 1356]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9550, 0.0035, 0.0023]),\n",
      "indices=tensor([1192, 1154, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9037e-01, 4.1708e-03, 6.1986e-04]),\n",
      "indices=tensor([1401, 1406, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0937, 0.0485, 0.0472]),\n",
      "indices=tensor([1178, 1395, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9966e-01, 2.8819e-05, 2.4472e-05]),\n",
      "indices=tensor([1530, 1448, 1347]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5135, 0.0647, 0.0448]),\n",
      "indices=tensor([1386, 1415, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0813, 0.0759, 0.0649]),\n",
      "indices=tensor([1447, 1550, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9990e-01, 5.9636e-05, 2.5060e-06]),\n",
      "indices=tensor([1240, 1186, 1224]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9538, 0.0032, 0.0030]),\n",
      "indices=tensor([1413, 1310, 1498]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0738, 0.0561, 0.0501]),\n",
      "indices=tensor([1448, 1413, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4495, 0.0704, 0.0250]),\n",
      "indices=tensor([1283, 1273, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1030, 0.0698, 0.0382]),\n",
      "indices=tensor([1406, 1489, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5549, 0.0420, 0.0396]),\n",
      "indices=tensor([1419, 1403, 1285]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1042, 0.0940, 0.0902]),\n",
      "indices=tensor([1403, 1374, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0520, 0.0496, 0.0448]),\n",
      "indices=tensor([1277, 1433, 1164]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0595, 0.0523, 0.0487]),\n",
      "indices=tensor([1460,  941, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8737, 0.0677, 0.0147]),\n",
      "indices=tensor([1419, 1462, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9288e-01, 5.1892e-04, 4.0166e-04]),\n",
      "indices=tensor([1244, 1231, 1258]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0644, 0.0495, 0.0476]),\n",
      "indices=tensor([1460, 1448, 1067]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0870, 0.0826, 0.0753]),\n",
      "indices=tensor([1395, 1448, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9598e-01, 2.1770e-04, 1.5879e-04]),\n",
      "indices=tensor([1224, 1386, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1613, 0.0538, 0.0531]),\n",
      "indices=tensor([1415, 1496, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9560, 0.0051, 0.0029]),\n",
      "indices=tensor([1433, 1496, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9900e-01, 8.7456e-05, 6.1862e-05]),\n",
      "indices=tensor([1038, 1112,  990]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9562, 0.0050, 0.0039]),\n",
      "indices=tensor([1443, 1496, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0539, 0.0482, 0.0395]),\n",
      "indices=tensor([1321, 1357, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0653, 0.0603, 0.0441]),\n",
      "indices=tensor([1112, 1096, 1339]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0742, 0.0415, 0.0350]),\n",
      "indices=tensor([1345, 1277, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2639, 0.0404, 0.0404]),\n",
      "indices=tensor([1413,  946, 1454]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1568, 0.0430, 0.0352]),\n",
      "indices=tensor([1145, 1154,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9942e-01, 6.7905e-05, 4.1345e-05]),\n",
      "indices=tensor([985, 946, 996]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7089, 0.1198, 0.0191]),\n",
      "indices=tensor([1431, 1550, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9341e-01, 1.4256e-03, 5.6611e-04]),\n",
      "indices=tensor([1164, 1117, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0684, 0.0456, 0.0364]),\n",
      "indices=tensor([1288, 1269, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0522, 0.0505, 0.0423]),\n",
      "indices=tensor([1214, 1321, 1096]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7970, 0.1675, 0.0053]),\n",
      "indices=tensor([1428, 1400, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9516e-01, 2.7055e-03, 7.5658e-04]),\n",
      "indices=tensor([1255, 1219, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1149, 0.0865, 0.0496]),\n",
      "indices=tensor([1499, 1413, 1462]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0709, 0.0576, 0.0502]),\n",
      "indices=tensor([1248, 1330, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8341, 0.0436, 0.0082]),\n",
      "indices=tensor([1317, 1325, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9823, 0.0030, 0.0019]),\n",
      "indices=tensor([1435, 1403, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1092, 0.0723, 0.0673]),\n",
      "indices=tensor([1445, 1255, 1393]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0607, 0.0464, 0.0383]),\n",
      "indices=tensor([1308, 1045, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8791, 0.0058, 0.0052]),\n",
      "indices=tensor([1319,  985, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7449, 0.1851, 0.0063]),\n",
      "indices=tensor([1366, 1315, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9744, 0.0041, 0.0013]),\n",
      "indices=tensor([1332, 1323, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1280, 0.0555, 0.0417]),\n",
      "indices=tensor([1009, 1284,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5895, 0.2165, 0.0201]),\n",
      "indices=tensor([1462, 1429, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2552, 0.0561, 0.0369]),\n",
      "indices=tensor([1409, 1421, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9803e-01, 1.5984e-03, 3.9194e-05]),\n",
      "indices=tensor([1425, 1435, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0640, 0.0612, 0.0484]),\n",
      "indices=tensor([1380, 1403, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9484e-01, 5.0597e-04, 4.6687e-04]),\n",
      "indices=tensor([ 941,  986, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8931e-01, 9.5530e-04, 7.1451e-04]),\n",
      "indices=tensor([1428, 1452, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0781, 0.0472, 0.0445]),\n",
      "indices=tensor([1243, 1110, 1257]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9885e-01, 3.5984e-04, 1.3198e-04]),\n",
      "indices=tensor([1498, 1436, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0941, 0.0528, 0.0467]),\n",
      "indices=tensor([1350, 1329, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1127, 0.0641, 0.0630]),\n",
      "indices=tensor([1403, 1447, 1343]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9681, 0.0029, 0.0018]),\n",
      "indices=tensor([ 970, 1164, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0848, 0.0620, 0.0345]),\n",
      "indices=tensor([1438, 1386, 1498]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3188, 0.3014, 0.0667]),\n",
      "indices=tensor([1421, 1431, 1500]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1035, 0.0644, 0.0594]),\n",
      "indices=tensor([1500, 1394, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000e+00, 4.9909e-07, 3.5852e-07]),\n",
      "indices=tensor([1134, 1154, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3291, 0.0568, 0.0496]),\n",
      "indices=tensor([1223, 1284, 1339]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9170, 0.0275, 0.0034]),\n",
      "indices=tensor([1315, 1277, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0582, 0.0464, 0.0325]),\n",
      "indices=tensor([1448, 1218, 1376]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7670, 0.0131, 0.0108]),\n",
      "indices=tensor([1420, 1447, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0735, 0.0528, 0.0359]),\n",
      "indices=tensor([1403, 1096,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7327, 0.0689, 0.0077]),\n",
      "indices=tensor([1498, 1514, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1528, 0.0914, 0.0412]),\n",
      "indices=tensor([1448, 1269, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9909e-01, 5.3867e-04, 9.1827e-05]),\n",
      "indices=tensor([1295, 1202, 1248]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0879, 0.0496, 0.0458]),\n",
      "indices=tensor([1489, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0709, 0.0594, 0.0523]),\n",
      "indices=tensor([1168, 1218, 1514]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5917, 0.2249, 0.0195]),\n",
      "indices=tensor([1152, 1117, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1821, 0.1264, 0.0835]),\n",
      "indices=tensor([1403, 1447, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0739, 0.0652, 0.0570]),\n",
      "indices=tensor([1273, 1285, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0990, 0.0449, 0.0430]),\n",
      "indices=tensor([1496, 1214, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0744, 0.0618, 0.0493]),\n",
      "indices=tensor([1460, 1433, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5170, 0.0391, 0.0299]),\n",
      "indices=tensor([1428, 1413, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9709e-01, 8.3531e-04, 1.2930e-04]),\n",
      "indices=tensor([1479, 1448, 1045]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0963, 0.0506, 0.0396]),\n",
      "indices=tensor([1292, 1456, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9956e-01, 4.1412e-05, 2.5138e-05]),\n",
      "indices=tensor([1530, 1448, 1009]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9871e-01, 5.9961e-05, 5.9826e-05]),\n",
      "indices=tensor([1395, 1278, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1331, 0.0572, 0.0547]),\n",
      "indices=tensor([1123, 1053, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0702, 0.0540, 0.0418]),\n",
      "indices=tensor([1110, 1403, 1164]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3513, 0.1597, 0.0291]),\n",
      "indices=tensor([1438, 1406, 1317]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0881, 0.0878, 0.0431]),\n",
      "indices=tensor([1674, 1445, 1296]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0584, 0.0421, 0.0385]),\n",
      "indices=tensor([1428, 1022, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0504, 0.0436, 0.0331]),\n",
      "indices=tensor([1156, 1038, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4199, 0.1192, 0.0631]),\n",
      "indices=tensor([1300, 1357, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8217e-01, 5.4022e-03, 6.8816e-04]),\n",
      "indices=tensor([1269, 1297, 1058]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1600, 0.0839, 0.0626]),\n",
      "indices=tensor([1403, 1550, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000e+00, 5.7923e-07, 3.8025e-07]),\n",
      "indices=tensor([ 208, 1395, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9071e-01, 1.5869e-03, 8.3877e-04]),\n",
      "indices=tensor([1213, 1255, 1326]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8726, 0.1010, 0.0026]),\n",
      "indices=tensor([1273, 1252, 1219]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9506, 0.0289, 0.0024]),\n",
      "indices=tensor([1022, 1131, 1462]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8663e-01, 4.7453e-03, 4.5291e-04]),\n",
      "indices=tensor([1276, 1248, 1280]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9612, 0.0265, 0.0026]),\n",
      "indices=tensor([1269, 1293, 1346]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0730, 0.0400, 0.0377]),\n",
      "indices=tensor([1154, 1262, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1199, 0.0624, 0.0576]),\n",
      "indices=tensor([1313, 1394, 1096]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9746, 0.0016, 0.0010]),\n",
      "indices=tensor([1120, 1053, 1339]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6862, 0.2868, 0.0040]),\n",
      "indices=tensor([1269, 1346, 1309]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9797e-01, 1.8393e-04, 1.7310e-04]),\n",
      "indices=tensor([1367, 1460, 1321]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9873, 0.0014, 0.0013]),\n",
      "indices=tensor([1455, 1485, 1421]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1163, 0.0499, 0.0417]),\n",
      "indices=tensor([1403, 1406, 1498]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9772, 0.0027, 0.0015]),\n",
      "indices=tensor([1319, 1387, 1375]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9955, 0.0011, 0.0011]),\n",
      "indices=tensor([1327, 1359, 1292]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9395e-01, 1.7766e-03, 3.4806e-04]),\n",
      "indices=tensor([1315, 1359, 1366]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9602, 0.0041, 0.0028]),\n",
      "indices=tensor([1213, 1357, 1233]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9497, 0.0119, 0.0056]),\n",
      "indices=tensor([1494, 1492, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2693, 0.0872, 0.0651]),\n",
      "indices=tensor([1308, 1284, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8822e-01, 1.0531e-03, 8.9618e-04]),\n",
      "indices=tensor([1308, 1460, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1548, 0.0922, 0.0590]),\n",
      "indices=tensor([1498, 1479, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0547, 0.0512, 0.0497]),\n",
      "indices=tensor([1410, 1308, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1135, 0.0803, 0.0481]),\n",
      "indices=tensor([1438, 1456, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0999, 0.0967, 0.0579]),\n",
      "indices=tensor([1479, 1456, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9835e-01, 3.1706e-04, 1.6216e-04]),\n",
      "indices=tensor([1407, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8602e-01, 6.4506e-04, 6.2812e-04]),\n",
      "indices=tensor([1354, 1053, 1408]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3597, 0.0563, 0.0511]),\n",
      "indices=tensor([1496, 1394, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9965e-01, 8.7995e-05, 4.1669e-05]),\n",
      "indices=tensor([1480, 1448, 1386]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9800, 0.0016, 0.0015]),\n",
      "indices=tensor([1197, 1496, 1209]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5835, 0.1691, 0.1530]),\n",
      "indices=tensor([1120, 1139, 1145]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0845, 0.0812, 0.0776]),\n",
      "indices=tensor([1308, 1359, 1415]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6787, 0.0642, 0.0404]),\n",
      "indices=tensor([1327, 1387, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0953, 0.0639, 0.0376]),\n",
      "indices=tensor([1496, 1550, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7355, 0.0208, 0.0171]),\n",
      "indices=tensor([1325, 1286, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9227e-01, 9.8303e-04, 9.2317e-04]),\n",
      "indices=tensor([1158, 1126, 1389]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9815e-01, 1.0526e-04, 9.6975e-05]),\n",
      "indices=tensor([1224, 1386, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8457, 0.0147, 0.0073]),\n",
      "indices=tensor([1329, 1110, 1328]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0929, 0.0772, 0.0664]),\n",
      "indices=tensor([1448, 1403, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7267, 0.0242, 0.0201]),\n",
      "indices=tensor([1429, 1456, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0531, 0.0495, 0.0383]),\n",
      "indices=tensor([1112, 1403, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0601, 0.0487, 0.0320]),\n",
      "indices=tensor([ 986, 1493, 1330]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9570e-01, 3.2622e-04, 2.8864e-04]),\n",
      "indices=tensor([1408, 1485, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1198, 0.0849, 0.0475]),\n",
      "indices=tensor([1308, 1218, 1446]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0523, 0.0516, 0.0421]),\n",
      "indices=tensor([1284, 1189, 1310]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9267, 0.0166, 0.0055]),\n",
      "indices=tensor([ 927, 1310, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4781, 0.3741, 0.0127]),\n",
      "indices=tensor([1475, 1407, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9140, 0.0633, 0.0020]),\n",
      "indices=tensor([1213, 1255, 1326]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9769, 0.0014, 0.0012]),\n",
      "indices=tensor([1134, 1053, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4533, 0.3778, 0.0173]),\n",
      "indices=tensor([1343, 1453, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9923e-01, 9.1376e-05, 9.0832e-05]),\n",
      "indices=tensor([1166, 1154, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9363, 0.0108, 0.0066]),\n",
      "indices=tensor([1439, 1403, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1131, 0.0639, 0.0463]),\n",
      "indices=tensor([1295, 1433, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1062, 0.0767, 0.0701]),\n",
      "indices=tensor([1406, 1437, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8572, 0.0355, 0.0197]),\n",
      "indices=tensor([1309, 1413, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0395, 0.0309, 0.0300]),\n",
      "indices=tensor([1278, 1096, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7733, 0.0118, 0.0099]),\n",
      "indices=tensor([1445, 1433, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9789, 0.0090, 0.0011]),\n",
      "indices=tensor([1123, 1158, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1082, 0.0519, 0.0442]),\n",
      "indices=tensor([1489, 1126, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8699, 0.1098, 0.0038]),\n",
      "indices=tensor([1459, 1479, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9280, 0.0286, 0.0025]),\n",
      "indices=tensor([1243, 1179, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7395, 0.0295, 0.0273]),\n",
      "indices=tensor([1344, 1406, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1296, 0.0690, 0.0476]),\n",
      "indices=tensor([1403, 1496, 1408]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9777e-01, 2.3279e-04, 1.0523e-04]),\n",
      "indices=tensor([1143, 1411, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4811, 0.3623, 0.0574]),\n",
      "indices=tensor([1429, 1386, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9999e-01, 2.7810e-06, 8.7042e-07]),\n",
      "indices=tensor([1202, 1305, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0521, 0.0383, 0.0366]),\n",
      "indices=tensor([1332, 1285, 1276]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3097, 0.0838, 0.0632]),\n",
      "indices=tensor([1439, 1479, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0874, 0.0665, 0.0559]),\n",
      "indices=tensor([1438, 1496, 1214]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0710, 0.0592, 0.0556]),\n",
      "indices=tensor([1178,  941, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4148, 0.3970, 0.0444]),\n",
      "indices=tensor([1329, 1321, 1383]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8863, 0.0238, 0.0066]),\n",
      "indices=tensor([1120, 1155, 1233]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0435, 0.0390, 0.0375]),\n",
      "indices=tensor([ 988, 1112, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.7919e-01, 1.2221e-03, 7.1537e-04]),\n",
      "indices=tensor([1341, 1053, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8941e-01, 8.5698e-03, 6.4378e-04]),\n",
      "indices=tensor([1207, 1268, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1571, 0.1491, 0.0925]),\n",
      "indices=tensor([1406, 1433, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8964e-01, 7.7700e-03, 3.7255e-04]),\n",
      "indices=tensor([1096, 1045, 1390]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9824, 0.0064, 0.0011]),\n",
      "indices=tensor([1423, 1380, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8776e-01, 3.4617e-03, 6.6993e-04]),\n",
      "indices=tensor([1031, 1218, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9522e-01, 1.8012e-03, 9.7358e-04]),\n",
      "indices=tensor([1158, 1123, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5190, 0.3290, 0.0431]),\n",
      "indices=tensor([1310, 1273, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9021e-01, 1.5659e-03, 7.8508e-04]),\n",
      "indices=tensor([ 996, 1112, 1168]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9923e-01, 9.8420e-05, 4.3757e-05]),\n",
      "indices=tensor([ 996, 1196, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0414, 0.0383, 0.0330]),\n",
      "indices=tensor([1110, 1152, 1472]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9416, 0.0151, 0.0069]),\n",
      "indices=tensor([1409, 1359, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1179, 0.1173, 0.0806]),\n",
      "indices=tensor([1394, 1380, 1420]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.1295, 0.0679, 0.0433]),\n",
      "indices=tensor([1415, 1224, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1054, 0.0589, 0.0586]),\n",
      "indices=tensor([1218, 1438, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9310, 0.0056, 0.0052]),\n",
      "indices=tensor([1472, 1393, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2165, 0.0999, 0.0427]),\n",
      "indices=tensor([1376, 1382, 1273]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1477, 0.0520, 0.0473]),\n",
      "indices=tensor([1218, 1415, 1293]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0680, 0.0527, 0.0355]),\n",
      "indices=tensor([1053, 1126, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1368, 0.0408, 0.0278]),\n",
      "indices=tensor([1415, 1308, 1331]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2179, 0.0942, 0.0542]),\n",
      "indices=tensor([1414, 1455, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9232, 0.0533, 0.0014]),\n",
      "indices=tensor([1347, 1291, 1096]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2277, 0.0369, 0.0311]),\n",
      "indices=tensor([1309, 1067, 1258]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9638, 0.0155, 0.0026]),\n",
      "indices=tensor([ 941, 1110, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9981e-01, 7.7226e-05, 1.2265e-05]),\n",
      "indices=tensor([1189, 1156, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9484, 0.0064, 0.0044]),\n",
      "indices=tensor([ 996, 1152, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9946e-01, 9.1725e-05, 6.5704e-05]),\n",
      "indices=tensor([1413, 1406, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0384, 0.0377, 0.0349]),\n",
      "indices=tensor([1348, 1439, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0573, 0.0513, 0.0455]),\n",
      "indices=tensor([1203, 1345, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2057, 0.0441, 0.0404]),\n",
      "indices=tensor([1438, 1406, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9894e-01, 2.1924e-04, 1.4506e-04]),\n",
      "indices=tensor([1155, 1214, 1218]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1076, 0.0828, 0.0422]),\n",
      "indices=tensor([1460, 1433, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8045e-01, 1.3173e-03, 7.4600e-04]),\n",
      "indices=tensor([1387, 1357, 1674]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9894, 0.0025, 0.0014]),\n",
      "indices=tensor([1252, 1282, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0594, 0.0558, 0.0320]),\n",
      "indices=tensor([ 946, 1283,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6639, 0.0527, 0.0513]),\n",
      "indices=tensor([1443, 1350, 1329]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6958, 0.0228, 0.0172]),\n",
      "indices=tensor([1359, 1327, 1346]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1427, 0.0796, 0.0394]),\n",
      "indices=tensor([1448, 1269, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9988e-01, 3.9834e-05, 6.6606e-06]),\n",
      "indices=tensor([ 930, 1472, 1448]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9956e-01, 1.6581e-04, 2.2157e-05]),\n",
      "indices=tensor([1437, 1448, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1484, 0.1424, 0.1213]),\n",
      "indices=tensor([1438, 1403, 1354]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9933e-01, 9.1107e-05, 6.3865e-05]),\n",
      "indices=tensor([1456, 1415, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9528e-01, 5.4056e-04, 2.1119e-04]),\n",
      "indices=tensor([1456, 1398, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9819, 0.0035, 0.0016]),\n",
      "indices=tensor([1209, 1251, 1193]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9628e-01, 4.6120e-04, 2.4281e-04]),\n",
      "indices=tensor([1244, 1340, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9989e-01, 1.3342e-05, 1.1867e-05]),\n",
      "indices=tensor([1067, 1152, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4011, 0.1069, 0.0796]),\n",
      "indices=tensor([1218, 1067, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9244, 0.0343, 0.0159]),\n",
      "indices=tensor([1486, 1413, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9932e-01, 1.0228e-04, 1.0007e-04]),\n",
      "indices=tensor([1255, 1219, 1213]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9157, 0.0048, 0.0043]),\n",
      "indices=tensor([1044, 1178, 1186]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0554, 0.0406, 0.0403]),\n",
      "indices=tensor([1045, 1178, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9041e-01, 1.1649e-03, 4.3359e-04]),\n",
      "indices=tensor([1485, 1455, 1309]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8126, 0.0118, 0.0095]),\n",
      "indices=tensor([1426, 1145, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0959, 0.0793, 0.0402]),\n",
      "indices=tensor([1310, 1189, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3736, 0.0414, 0.0344]),\n",
      "indices=tensor([1390, 1403, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8649, 0.1060, 0.0040]),\n",
      "indices=tensor([ 930, 1067, 1293]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0908, 0.0761, 0.0674]),\n",
      "indices=tensor([1344, 1413, 1394]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9752e-01, 2.4734e-04, 1.9725e-04]),\n",
      "indices=tensor([1367, 1415, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8994e-01, 2.6398e-03, 5.4143e-04]),\n",
      "indices=tensor([1331, 1415, 1268]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1108, 0.0937, 0.0749]),\n",
      "indices=tensor([1403, 1374, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1339, 0.0610, 0.0497]),\n",
      "indices=tensor([1406, 1496, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4962, 0.3873, 0.0151]),\n",
      "indices=tensor([1130, 1152, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7695, 0.1451, 0.0074]),\n",
      "indices=tensor([1243, 1179, 1230]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9995e-01, 6.4390e-06, 4.5033e-06]),\n",
      "indices=tensor([1436, 1438, 1455]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9377, 0.0480, 0.0012]),\n",
      "indices=tensor([1110, 1112,  988]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9181, 0.0083, 0.0050]),\n",
      "indices=tensor([1400, 1382, 1038]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9607, 0.0014, 0.0013]),\n",
      "indices=tensor([1380, 1214, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9836e-01, 8.5326e-04, 6.8461e-05]),\n",
      "indices=tensor([1317, 1252, 1486]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0951, 0.0596, 0.0471]),\n",
      "indices=tensor([1213, 1112, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9827, 0.0021, 0.0011]),\n",
      "indices=tensor([1068, 1152, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0852, 0.0763, 0.0639]),\n",
      "indices=tensor([1297, 1346, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5180, 0.0484, 0.0469]),\n",
      "indices=tensor([1227, 1380, 1446]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9727, 0.0180, 0.0010]),\n",
      "indices=tensor([1550, 1403, 1438]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9820, 0.0014, 0.0013]),\n",
      "indices=tensor([1499, 1421, 1445]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1114, 0.0459, 0.0428]),\n",
      "indices=tensor([1244,  988, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9206e-01, 6.1530e-03, 2.1097e-04]),\n",
      "indices=tensor([1317, 1252, 1293]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9963e-01, 7.0537e-05, 3.1219e-05]),\n",
      "indices=tensor([1078, 1022, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9364, 0.0352, 0.0104]),\n",
      "indices=tensor([1273, 1310, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9104e-01, 9.0358e-04, 8.7193e-04]),\n",
      "indices=tensor([1266, 1403, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9928e-01, 8.5961e-05, 6.3748e-05]),\n",
      "indices=tensor([1145, 1413, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1549, 0.0539, 0.0476]),\n",
      "indices=tensor([1438, 1403,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8396, 0.0219, 0.0163]),\n",
      "indices=tensor([1292, 1265, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1312, 0.0920, 0.0769]),\n",
      "indices=tensor([1403, 1359, 1148]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9992e-01, 1.3026e-05, 8.6330e-06]),\n",
      "indices=tensor([1296, 1224, 1196]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0587, 0.0478, 0.0448]),\n",
      "indices=tensor([1038, 1284, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8883e-01, 1.0320e-03, 6.9998e-04]),\n",
      "indices=tensor([ 956, 1403, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1241, 0.0525, 0.0501]),\n",
      "indices=tensor([1674, 1296, 1514]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0708, 0.0520, 0.0497]),\n",
      "indices=tensor([1283, 1248, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5645, 0.0549, 0.0374]),\n",
      "indices=tensor([1435, 1403, 1456]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3319, 0.1127, 0.0458]),\n",
      "indices=tensor([1500, 1478, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9833e-01, 4.5373e-04, 1.1099e-04]),\n",
      "indices=tensor([ 956, 1067, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8122, 0.1102, 0.0085]),\n",
      "indices=tensor([ 986, 1096, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0813, 0.0757, 0.0551]),\n",
      "indices=tensor([1496, 1403, 1393]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2786, 0.1468, 0.0632]),\n",
      "indices=tensor([1273, 1308, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8209, 0.0326, 0.0087]),\n",
      "indices=tensor([1440, 1438, 1436]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9796, 0.0014, 0.0012]),\n",
      "indices=tensor([1392, 1244, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7881, 0.0900, 0.0492]),\n",
      "indices=tensor([1212, 1338, 1399]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9805e-01, 3.9550e-04, 9.2947e-05]),\n",
      "indices=tensor([1355, 1383, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4304, 0.1410, 0.0308]),\n",
      "indices=tensor([1338, 1413, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7889, 0.1454, 0.0064]),\n",
      "indices=tensor([1376, 1269, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0717, 0.0614, 0.0598]),\n",
      "indices=tensor([1382, 1395, 1117]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7942, 0.0408, 0.0081]),\n",
      "indices=tensor([1496, 1445, 1390]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0660, 0.0465, 0.0433]),\n",
      "indices=tensor([1178, 1053, 1492]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9621, 0.0080, 0.0034]),\n",
      "indices=tensor([1252, 1218, 1317]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9977e-01, 2.2726e-05, 1.6364e-05]),\n",
      "indices=tensor([1134, 1203, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9994e-01, 9.9446e-06, 4.1950e-06]),\n",
      "indices=tensor([1197, 1454, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2238, 0.0509, 0.0399]),\n",
      "indices=tensor([1493, 1478, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0697, 0.0694, 0.0609]),\n",
      "indices=tensor([1445, 1168, 1380]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0894, 0.0690, 0.0574]),\n",
      "indices=tensor([1380, 1223, 1315]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1733, 0.0490, 0.0485]),\n",
      "indices=tensor([1223, 1385, 1231]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2346, 0.1040, 0.0984]),\n",
      "indices=tensor([1274, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0540, 0.0447, 0.0439]),\n",
      "indices=tensor([1038, 1522, 1086]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.8810, 0.0364, 0.0074]),\n",
      "indices=tensor([1428, 1406, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8340, 0.0188, 0.0074]),\n",
      "indices=tensor([1421, 1496, 1437]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0609, 0.0406, 0.0363]),\n",
      "indices=tensor([1357, 1196, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2475, 0.0600, 0.0528]),\n",
      "indices=tensor([1403, 1496, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0443, 0.0435, 0.0339]),\n",
      "indices=tensor([1397, 1045, 1192]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0939, 0.0719, 0.0478]),\n",
      "indices=tensor([1347, 1343, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9916e-01, 3.1717e-04, 8.9709e-05]),\n",
      "indices=tensor([1486, 1419, 1060]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9288, 0.0079, 0.0043]),\n",
      "indices=tensor([1391, 1448, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2953, 0.1686, 0.0454]),\n",
      "indices=tensor([1428, 1406, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8378e-01, 2.6270e-03, 9.0843e-04]),\n",
      "indices=tensor([1227, 1265, 1039]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1835, 0.1254, 0.0600]),\n",
      "indices=tensor([1438, 1354, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8325, 0.0430, 0.0066]),\n",
      "indices=tensor([1123, 1209, 1048]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3772, 0.3157, 0.0144]),\n",
      "indices=tensor([1514, 1498, 1377]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.8506e-01, 9.0385e-04, 6.9746e-04]),\n",
      "indices=tensor([ 988, 1382, 1273]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7753, 0.0253, 0.0177]),\n",
      "indices=tensor([1548, 1413, 1286]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1048, 0.0959, 0.0609]),\n",
      "indices=tensor([1423, 1403, 1433]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9212e-01, 1.2449e-03, 8.6567e-04]),\n",
      "indices=tensor([1321, 1308, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9985e-01, 1.4876e-05, 1.0056e-05]),\n",
      "indices=tensor([1086,  946, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9620, 0.0150, 0.0032]),\n",
      "indices=tensor([1186, 1291, 1152]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0759, 0.0725, 0.0467]),\n",
      "indices=tensor([1156, 1110, 1154]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9465e-01, 7.9472e-04, 3.7347e-04]),\n",
      "indices=tensor([1266, 1403, 1338]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9764, 0.0035, 0.0024]),\n",
      "indices=tensor([1435, 1486, 1480]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0748, 0.0421, 0.0418]),\n",
      "indices=tensor([1499, 1397, 1393]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9431, 0.0076, 0.0037]),\n",
      "indices=tensor([1355, 1278, 1397]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1533, 0.0767, 0.0755]),\n",
      "indices=tensor([1313, 1233, 1395]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5141, 0.0409, 0.0316]),\n",
      "indices=tensor([1332, 1421, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0584, 0.0508, 0.0457]),\n",
      "indices=tensor([1345, 1214, 1223]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0969, 0.0536, 0.0483]),\n",
      "indices=tensor([1456, 1396, 1401]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9757, 0.0038, 0.0021]),\n",
      "indices=tensor([1277, 1110, 1498]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0524, 0.0511, 0.0427]),\n",
      "indices=tensor([1297, 1067, 1390]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1631, 0.1238, 0.0537]),\n",
      "indices=tensor([1499, 1500, 1120]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9609e-01, 9.2225e-04, 1.5588e-04]),\n",
      "indices=tensor([1329, 1328, 1475]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0517, 0.0516, 0.0433]),\n",
      "indices=tensor([1265, 1158, 1325]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9621, 0.0104, 0.0024]),\n",
      "indices=tensor([1423, 1380, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7154, 0.1481, 0.0691]),\n",
      "indices=tensor([1436, 1398, 1413]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.3849, 0.1305, 0.0604]),\n",
      "indices=tensor([ 983, 1022, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4707, 0.4542, 0.0031]),\n",
      "indices=tensor([1383, 1410, 1178]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8163, 0.0395, 0.0105]),\n",
      "indices=tensor([1423, 1380, 1362]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9739, 0.0033, 0.0029]),\n",
      "indices=tensor([1011, 1285,  946]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0911, 0.0562, 0.0511]),\n",
      "indices=tensor([1313,  946, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9999e-01, 1.3346e-06, 8.6337e-07]),\n",
      "indices=tensor([ 927, 1284, 1215]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8835, 0.0085, 0.0066]),\n",
      "indices=tensor([1152, 1112,  970]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2502, 0.0423, 0.0411]),\n",
      "indices=tensor([1357, 1486, 1269]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9029e-01, 8.5265e-04, 7.2075e-04]),\n",
      "indices=tensor([1332, 1421, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9837e-01, 2.1175e-04, 1.7156e-04]),\n",
      "indices=tensor([1407, 1380, 1548]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9744e-01, 5.6900e-04, 1.9944e-04]),\n",
      "indices=tensor([1437, 1479, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0767, 0.0484, 0.0456]),\n",
      "indices=tensor([1380,  941, 1131]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9858, 0.0014, 0.0010]),\n",
      "indices=tensor([1009, 1284, 1357]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9760, 0.0078, 0.0029]),\n",
      "indices=tensor([1202, 1346, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0635, 0.0407, 0.0382]),\n",
      "indices=tensor([1265, 1397, 1158]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9151e-01, 1.9097e-03, 4.6558e-04]),\n",
      "indices=tensor([1202, 1413, 1284]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8161, 0.0116, 0.0091]),\n",
      "indices=tensor([1396, 1380, 1439]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9726e-01, 2.4257e-04, 2.3348e-04]),\n",
      "indices=tensor([1258, 1243, 1550]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0733, 0.0399, 0.0358]),\n",
      "indices=tensor([1265, 1397, 1398]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8842, 0.0251, 0.0063]),\n",
      "indices=tensor([1338, 1413, 1440]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1081, 0.0823, 0.0528]),\n",
      "indices=tensor([1438, 1496, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1202, 0.0467, 0.0336]),\n",
      "indices=tensor([1248, 1022, 1192]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9961e-01, 3.9050e-05, 3.0558e-05]),\n",
      "indices=tensor([1022,  983, 1308]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5670, 0.0969, 0.0395]),\n",
      "indices=tensor([1399, 1415, 1460]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6919, 0.0225, 0.0158]),\n",
      "indices=tensor([1327, 1380, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9253e-01, 5.2108e-04, 4.6469e-04]),\n",
      "indices=tensor([1112,  988, 1382]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9849, 0.0044, 0.0011]),\n",
      "indices=tensor([1326, 1232, 1301]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0876, 0.0613, 0.0462]),\n",
      "indices=tensor([1413, 1414, 1465]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9636, 0.0029, 0.0028]),\n",
      "indices=tensor([1117, 1382, 1047]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9592, 0.0106, 0.0023]),\n",
      "indices=tensor([1366, 1407, 1341]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9782, 0.0016, 0.0015]),\n",
      "indices=tensor([1297, 1134, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9722e-01, 7.7462e-04, 3.3082e-04]),\n",
      "indices=tensor([1305, 1269, 1202]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9650, 0.0015, 0.0013]),\n",
      "indices=tensor([1478, 1355, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9768, 0.0013, 0.0013]),\n",
      "indices=tensor([1224, 1496, 1255]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8997, 0.0067, 0.0054]),\n",
      "indices=tensor([1110, 1223, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9469e-01, 3.7936e-04, 3.3610e-04]),\n",
      "indices=tensor([1355, 1448, 1480]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0783, 0.0575, 0.0406]),\n",
      "indices=tensor([1489, 1403, 1496]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6204, 0.0688, 0.0319]),\n",
      "indices=tensor([1380, 1338, 1313]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9984e-01, 1.7132e-05, 1.5682e-05]),\n",
      "indices=tensor([1081, 1433, 1277]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.2513, 0.0533, 0.0517]),\n",
      "indices=tensor([1496, 1437, 1489]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5551, 0.1132, 0.0214]),\n",
      "indices=tensor([1496, 1413, 1454]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0473, 0.0409, 0.0321]),\n",
      "indices=tensor([1053, 1465, 1126]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0870, 0.0777, 0.0671]),\n",
      "indices=tensor([1437, 1266, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1990, 0.0800, 0.0791]),\n",
      "indices=tensor([1433, 1403, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9592e-01, 4.0418e-04, 3.1253e-04]),\n",
      "indices=tensor([1110, 1168, 1112]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9628e-01, 8.3587e-04, 5.7494e-04]),\n",
      "indices=tensor([1168, 1203, 1194]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5565, 0.3506, 0.0099]),\n",
      "indices=tensor([1408, 1485, 1403]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9742, 0.0020, 0.0015]),\n",
      "indices=tensor([1357, 1112, 1053]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9660, 0.0100, 0.0062]),\n",
      "indices=tensor([1445, 1406, 1401]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([9.9940e-01, 6.7241e-05, 6.3915e-05]),\n",
      "indices=tensor([1313, 1437, 1338]))\n",
      "--------------------------------------------------\n",
      "tensor([1.0026])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "validate(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5e056",
   "metadata": {},
   "source": [
    "### FX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "344728a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:True\n"
     ]
    }
   ],
   "source": [
    "rates = AddBoaderValue(pd.read_csv(f'/mnt/landisk/data/fx/NextBoaderPossibility/fx_USDJPY_5_2020-08-03T23-05-00_to_2021-12-04T07-50-00.csv'), 10)\n",
    "train_ds = FXBoaderDataset(rates, True, 1017, \"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "973bbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54753611",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,o = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bde5f5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99754864, 0.99754864, 0.9970978 , ..., 0.99343485, 0.9932846 ,\n",
       "        0.99307793],\n",
       "       [0.9963652 , 0.9969945 , 0.99671274, ..., 0.9930685 , 0.99277735,\n",
       "        0.9927492 ],\n",
       "       [0.9964873 , 0.9975392 , 0.99703205, ..., 0.9933879 , 0.9932    ,\n",
       "        0.9927962 ],\n",
       "       [0.99754864, 0.99703205, 0.9967691 , ..., 0.99319065, 0.9927962 ,\n",
       "        0.9930404 ]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_numpy(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b34f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = round((1.15 - 0.85)*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a8d4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(4,16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16,32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(32,16, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(16,8, kernel_size=3, padding=1)\n",
    "        self.convSame = nn.Conv1d(4,4, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(16*size, length)\n",
    "        self.fc1_2 = nn.Linear(16*size, 8*size)\n",
    "        self.fc2 = nn.Linear(8*size, length)\n",
    "        \n",
    "        self.fc4 = nn.Linear(4*size, 6*size)\n",
    "        self.fc5 = nn.Linear(6*size, 3*size)\n",
    "        self.fc6 = nn.Linear(3*size, size)\n",
    "        self.fc7 = nn.Linear(size, length)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.convSame(x))\n",
    "        out = out.view(-1, 4*size)\n",
    "        out = F.relu(self.fc4(out))\n",
    "        out = F.relu(self.fc5(out))\n",
    "        #out = torch.tanh(self.conv4(out))\n",
    "        #out = out.view(-1, 16*size)\n",
    "        out = F.relu(self.fc6(out))\n",
    "        out = F.relu(self.fc7(out))\n",
    "        #out = out.view(-1, 8*size)\n",
    "        #out = F.relu(self.fc2(out))\n",
    "        out = self.softmax(out)\n",
    "        #out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb0f234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size,  drop_last = True, shuffle=True)\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00b461ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7b7d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData, outputData = train_ds[0:10]\n",
    "out = model(inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbdce5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3000])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e7aa12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3000])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11841325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"576\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-89-910ead4f7c9d>\", line 1, in <module>\n",
      "    training_loop(n_epochs =300, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_dl)\n",
      "  File \"<ipython-input-50-71abd46b7531>\", line 23, in training_loop\n",
      "    for inputValues, ansValue in train_loader:\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 561, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"<ipython-input-10-0468ea73bb43>\", line 109, in __getitem__\n",
      "    return torch.tensor(inputs, device=device).to(dtype=dtype), torch.tensor(outputs, device=device).to(dtype=dtype)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/cow/.pyenv/versions/3.6.8/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-910ead4f7c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-71abd46b7531>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_loader, mode)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mansValue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0468ea73bb43>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, ndx)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;31m#return inputs, outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs =300, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ed73021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"576\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loop(n_epochs =300, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56d4aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fx_boaderRatePossibility_5_2days_adam_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "690fc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input, dummy_output = train_ds[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aaab4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, dummy_input, 'fx_boaderRatePossibility_5_2days_adam_v1.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15debe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ad225",
   "metadata": {},
   "source": [
    "## Simple Model for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9df0123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(4*size, size*8)\n",
    "        self.fc1 = nn.Linear(size*8, size*6)\n",
    "        self.fc2 = nn.Linear(6*size, length)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, 4*size)\n",
    "        out = F.relu(self.fc0(out))\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "69579ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a3383024",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5d90cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-22 19:24:22.754888 Epoch 1, Training loss 0.0003317914673200639\n",
      "2021-10-22 19:45:20.868056 Epoch 10, Training loss 0.0003316675594106335\n",
      "2021-10-22 20:13:55.819655 Epoch 20, Training loss 0.0003316532728707262\n",
      "2021-10-22 20:52:18.209663 Epoch 30, Training loss 0.00033226650735257847\n",
      "2021-10-22 21:35:40.736326 Epoch 40, Training loss 0.00033145428826147005\n",
      "2021-10-22 22:20:51.515944 Epoch 50, Training loss 0.0003314124641933116\n",
      "2021-10-22 23:08:09.836940 Epoch 60, Training loss 0.00033142726628678697\n",
      "2021-10-22 23:55:12.196995 Epoch 70, Training loss 0.00033140838420903996\n",
      "2021-10-23 00:42:54.144048 Epoch 80, Training loss 0.0003312024520996848\n",
      "2021-10-23 01:22:54.230907 Epoch 90, Training loss 0.00033126060958158025\n",
      "2021-10-23 02:08:31.017359 Epoch 100, Training loss 0.0003311242985658421\n",
      "2021-10-23 02:59:10.271253 Epoch 110, Training loss 0.00033117779370011956\n",
      "2021-10-23 03:52:33.360748 Epoch 120, Training loss 0.0003311771145629527\n",
      "2021-10-23 04:45:48.780238 Epoch 130, Training loss 0.0003313423956462223\n",
      "2021-10-23 05:39:06.720062 Epoch 140, Training loss 0.0003311329647689929\n",
      "2021-10-23 06:31:46.117721 Epoch 150, Training loss 0.0003309720964285687\n",
      "2021-10-23 07:24:24.132700 Epoch 160, Training loss 0.0003314372100477368\n",
      "2021-10-23 08:13:56.082895 Epoch 170, Training loss 0.00033104783434448353\n",
      "2021-10-23 09:06:09.381762 Epoch 180, Training loss 0.00033137843894813523\n",
      "2021-10-23 09:54:02.902592 Epoch 190, Training loss 0.000331202819696834\n",
      "2021-10-23 10:37:59.786614 Epoch 200, Training loss 0.0003308077316141683\n",
      "2021-10-23 11:35:12.445929 Epoch 210, Training loss 0.00033116299404391074\n",
      "2021-10-23 12:29:48.076192 Epoch 220, Training loss 0.0003313861528968925\n",
      "2021-10-23 13:22:36.284078 Epoch 230, Training loss 0.0003309736631608802\n",
      "2021-10-23 14:16:04.804179 Epoch 240, Training loss 0.0003313122594183118\n",
      "2021-10-23 15:11:14.084939 Epoch 250, Training loss 0.0003311223507597308\n",
      "2021-10-23 16:07:09.343926 Epoch 260, Training loss 0.0003313146125275201\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-22439920d7fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-5177ad87b28f>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_loader)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloss_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/torch/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/torch/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/torch/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/torch/lib/python3.6/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs =1000, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f3c55390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0489, 0.0465, 0.0285]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0500, 0.0432, 0.0380]),\n",
      "indices=tensor([1350, 1359, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0394, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0494, 0.0439, 0.0272]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0583, 0.0447, 0.0280]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0175, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0367, 0.0258, 0.0213]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0296, 0.0184, 0.0172]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0604, 0.0419, 0.0289]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0122, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0329, 0.0176, 0.0166]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0187, 0.0179]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0256, 0.0201, 0.0161]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0229, 0.0194, 0.0142]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0156, 0.0151]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1136, 0.0853, 0.0656]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0607, 0.0412, 0.0290]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0326, 0.0225, 0.0192]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0263, 0.0203, 0.0169]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0641, 0.0404, 0.0378]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0182, 0.0157]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0222, 0.0134, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0145, 0.0136]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0331, 0.0174, 0.0169]),\n",
      "indices=tensor([1346, 1134, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0328, 0.0226, 0.0193]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0531, 0.0433, 0.0290]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0212, 0.0187, 0.0131]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0540, 0.0352, 0.0244]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0199, 0.0133, 0.0126]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0351, 0.0187, 0.0171]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0503, 0.0455, 0.0287]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0225, 0.0135, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0156, 0.0152]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0481, 0.0382, 0.0325]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0404, 0.0289, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0172, 0.0170]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0582, 0.0449, 0.0278]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0345, 0.0200, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0182, 0.0176]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0133, 0.0122]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0346, 0.0184, 0.0170]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0812, 0.0513, 0.0466]),\n",
      "indices=tensor([1359, 1387, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0535, 0.0411, 0.0232]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0410, 0.0241, 0.0225]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0484, 0.0377, 0.0326]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0152, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0130, 0.0129]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0192, 0.0181]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0221, 0.0211, 0.0152]),\n",
      "indices=tensor([1110, 1081, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0360, 0.0204, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0326, 0.0174, 0.0165]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0158, 0.0151]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0138, 0.0135]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0239, 0.0163, 0.0163]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0199, 0.0190, 0.0174]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0170, 0.0138]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0147, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0197, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0478, 0.0352, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0121]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0130, 0.0121, 0.0120]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0121, 0.0118]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0552, 0.0330, 0.0235]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0275, 0.0203, 0.0186]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0372, 0.0195, 0.0180]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0360, 0.0191, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0253, 0.0168, 0.0166]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0151, 0.0148]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0187, 0.0179]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0119]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0529, 0.0404, 0.0225]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0190, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0128, 0.0121]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0151, 0.0142]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0251, 0.0200, 0.0157]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0201, 0.0196, 0.0188]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0356, 0.0189, 0.0172]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0141, 0.0138, 0.0126]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0250, 0.0182, 0.0180]),\n",
      "indices=tensor([1081, 1031, 1078]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0142, 0.0136]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0133, 0.0121]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0137, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0432, 0.0368, 0.0284]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0183, 0.0159]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0250, 0.0186, 0.0166]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0158, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0124]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0377, 0.0266, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0476, 0.0473, 0.0282]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0349, 0.0201, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0494, 0.0360, 0.0348]),\n",
      "indices=tensor([1350, 1346, 1359]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0481, 0.0355, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0222, 0.0191, 0.0138]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0224, 0.0161, 0.0157]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0129, 0.0124]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0433, 0.0313, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0415, 0.0252, 0.0230]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0256, 0.0145, 0.0140]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0681, 0.0483, 0.0447]),\n",
      "indices=tensor([1359, 1350, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0128, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0196, 0.0147]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0298, 0.0203, 0.0177]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0645, 0.0427, 0.0389]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0430, 0.0377, 0.0288]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0756, 0.0471, 0.0463]),\n",
      "indices=tensor([1359, 1350, 1387]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0291, 0.0182, 0.0171]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0431, 0.0313, 0.0260]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0415, 0.0298, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0503, 0.0375, 0.0209]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0157, 0.0149]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0197, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0295, 0.0251]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0470, 0.0391, 0.0321]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0189, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0192, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0492, 0.0365, 0.0340]),\n",
      "indices=tensor([1350, 1346, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0476, 0.0349, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0155, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0151, 0.0148]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0156, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0178, 0.0121]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0148, 0.0138]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0472, 0.0390, 0.0321]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0424, 0.0306, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0153, 0.0150]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0650, 0.0469, 0.0407]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0273, 0.0176, 0.0169]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0221, 0.0191, 0.0138]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0370, 0.0261, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0512, 0.0384, 0.0210]),\n",
      "indices=tensor([1110, 1180, 1101]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0402, 0.0226, 0.0218]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0121, 0.0113]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0127, 0.0126, 0.0119]),\n",
      "indices=tensor([1463, 1425, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0172, 0.0170]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0153, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0146, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0133, 0.0129]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0459, 0.0399, 0.0318]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0584, 0.0281, 0.0258]),\n",
      "indices=tensor([1110, 1180,  956]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0276, 0.0198, 0.0196]),\n",
      "indices=tensor([1081, 1031, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0227, 0.0203, 0.0163]),\n",
      "indices=tensor([1081, 1110, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0194, 0.0188]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0330, 0.0227, 0.0194]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0133]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0196, 0.0147]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0421, 0.0265, 0.0237]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0147, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0266, 0.0178, 0.0173]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0521, 0.0395, 0.0218]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0180, 0.0175]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0144, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0137, 0.0135]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0460, 0.0335, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0247, 0.0182, 0.0179]),\n",
      "indices=tensor([1081, 1110, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0377, 0.0199, 0.0188]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0539, 0.0415, 0.0235]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0384, 0.0291]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0264, 0.0203, 0.0170]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0173, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0260, 0.0178, 0.0173]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0174, 0.0143]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0145, 0.0141]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0432, 0.0312, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0127, 0.0126, 0.0119]),\n",
      "indices=tensor([1463, 1425, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0123]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0498, 0.0388, 0.0364]),\n",
      "indices=tensor([1350, 1359, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0426, 0.0286, 0.0247]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0519, 0.0442, 0.0289]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0199, 0.0154]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0537, 0.0359, 0.0246]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0598, 0.0318, 0.0260]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0137, 0.0136]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0419, 0.0416, 0.0304]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0488, 0.0360, 0.0213]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0276, 0.0165, 0.0164]),\n",
      "indices=tensor([1346, 1134, 1290]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0228, 0.0204, 0.0150]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0605, 0.0417, 0.0289]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0354, 0.0202, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0245, 0.0199, 0.0153]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0259, 0.0179, 0.0173]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0384, 0.0272, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0147, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0176, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0156, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0338, 0.0197, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0321, 0.0220, 0.0189]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0178, 0.0149]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0194, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0357, 0.0190, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0220, 0.0159, 0.0154]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0129, 0.0128]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0472, 0.0390, 0.0321]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0253, 0.0201, 0.0158]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0427, 0.0292, 0.0250]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0352, 0.0202, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0179, 0.0120]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0481, 0.0354, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0179, 0.0120]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0163, 0.0162]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0360, 0.0252, 0.0209]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0256, 0.0201, 0.0161]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0173, 0.0125]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0312, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0121, 0.0114]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0153, 0.0134]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0393, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0442, 0.0320, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0961, 0.0658, 0.0526]),\n",
      "indices=tensor([1359, 1387, 1349]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0354, 0.0202, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0159, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0168, 0.0168]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1139, 0.0857, 0.0658]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0196, 0.0191]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0248, 0.0200, 0.0155]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0530, 0.0372, 0.0251]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0340, 0.0235, 0.0199]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0186, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0314, 0.0190, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0125, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0487, 0.0360, 0.0214]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0145, 0.0141]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0165, 0.0133]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0268, 0.0203, 0.0176]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0624, 0.0350, 0.0348]),\n",
      "indices=tensor([ 956, 1155, 1086]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0302, 0.0163, 0.0158]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0140, 0.0139, 0.0124]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0120, 0.0119]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0469, 0.0343, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0143, 0.0138, 0.0129]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0151, 0.0141]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0144, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0318, 0.0191, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0148, 0.0121, 0.0116]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0524, 0.0398, 0.0221]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0156, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0203, 0.0196, 0.0189]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0177, 0.0122]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0166, 0.0164]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0146, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0380, 0.0201, 0.0192]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0167, 0.0166]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0407, 0.0235, 0.0222]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0146, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0421, 0.0265, 0.0237]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0270, 0.0203, 0.0178]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1017, 0.0560, 0.0516]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0650, 0.0482, 0.0412]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0253, 0.0201, 0.0158]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0229, 0.0203, 0.0150]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0152, 0.0142]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0143, 0.0138, 0.0129]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0467, 0.0394, 0.0320]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0354, 0.0188, 0.0172]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1049, 0.0752, 0.0588]),\n",
      "indices=tensor([1359, 1387, 1369]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0387, 0.0275, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0393, 0.0208, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0169, 0.0169]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0222, 0.0160, 0.0157]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0154, 0.0143, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0192, 0.0190]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0214, 0.0188, 0.0133]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1026, 0.0727, 0.0571]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0338, 0.0180, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0244, 0.0141, 0.0133]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0197, 0.0156]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0405, 0.0289, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0191, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0179, 0.0151]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0134, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0579, 0.0450, 0.0277]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0361, 0.0204, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0260, 0.0202, 0.0166]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0337, 0.0197, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0203, 0.0192, 0.0179]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0316, 0.0191, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0216, 0.0189, 0.0134]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0325, 0.0193, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0248, 0.0188, 0.0164]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0467, 0.0393, 0.0320]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0152, 0.0143]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0178, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0554, 0.0326, 0.0233]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0195, 0.0194]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0145, 0.0144]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0170, 0.0138]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0429, 0.0382, 0.0290]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0415, 0.0298, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0296, 0.0252]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0327, 0.0194, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0128, 0.0120]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0194, 0.0188]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0159, 0.0155, 0.0133]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0152, 0.0149]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0274, 0.0198, 0.0194]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0152, 0.0151]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0252, 0.0144, 0.0138]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0195, 0.0193]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0122]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0478, 0.0351, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0203, 0.0192, 0.0180]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0187, 0.0167]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0539, 0.0415, 0.0236]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0131, 0.0119]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0152, 0.0148]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0370, 0.0193, 0.0178]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1123, 0.0839, 0.0646]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0124]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0130, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0273, 0.0203, 0.0183]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0397, 0.0283, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0234, 0.0200, 0.0154]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0393, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0193, 0.0183]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0148, 0.0138]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0137, 0.0137]),\n",
      "indices=tensor([1327, 1290, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0151, 0.0141]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0170, 0.0138]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0178, 0.0121]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0366, 0.0194, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0196, 0.0190]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1096, 0.0806, 0.0624]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0156, 0.0148]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0421, 0.0410, 0.0302]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0138, 0.0134]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0350, 0.0201, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0357, 0.0184, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0213, 0.0158, 0.0154]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0186, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0197, 0.0156]),\n",
      "indices=tensor([1110, 1081, 1180]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0378, 0.0267, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0143, 0.0132]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0139, 0.0123]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0169, 0.0137]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0392, 0.0211, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0254, 0.0183, 0.0169]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0363, 0.0188, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0239, 0.0197, 0.0149]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0147, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0138, 0.0131]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0379, 0.0200, 0.0190]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0278, 0.0203, 0.0192]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0136, 0.0124]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0387, 0.0211, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0231, 0.0137, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0546, 0.0342, 0.0240]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0605, 0.0358, 0.0323]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0483, 0.0379, 0.0326]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0514, 0.0387, 0.0212]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0201, 0.0191, 0.0176]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0358, 0.0250, 0.0209]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0177, 0.0169]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0196, 0.0184]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0182, 0.0176]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0413, 0.0296, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0333, 0.0230, 0.0196]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0138, 0.0137]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0474, 0.0347, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0228, 0.0160, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0327, 0.0225, 0.0192]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0394, 0.0209, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0256, 0.0186, 0.0184]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0260, 0.0189, 0.0187]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0122]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0550, 0.0428, 0.0247]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0165, 0.0132]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0198, 0.0155]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0315, 0.0216, 0.0186]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0433, 0.0362, 0.0281]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0303, 0.0170, 0.0166]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0124, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0381, 0.0202, 0.0194]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0185, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0364, 0.0193, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0338, 0.0198, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0364, 0.0255, 0.0212]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0492, 0.0365, 0.0212]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0163, 0.0162]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0323, 0.0193, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0196, 0.0193]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0122, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0322, 0.0173, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0211, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0499, 0.0399, 0.0368]),\n",
      "indices=tensor([1350, 1359, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0331, 0.0195, 0.0177]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0202, 0.0156, 0.0150]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0141, 0.0139]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0278, 0.0203, 0.0191]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0272, 0.0165, 0.0163]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0125, 0.0125]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0127, 0.0125]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0148, 0.0148, 0.0145]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0294, 0.0183, 0.0172]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0606, 0.0416, 0.0289]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0135, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0224, 0.0207, 0.0161]),\n",
      "indices=tensor([1081, 1110, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0178, 0.0148]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0132, 0.0122]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0163, 0.0162]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0275, 0.0203, 0.0186]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0534, 0.0431, 0.0290]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0121, 0.0114]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0247, 0.0166, 0.0165]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0154, 0.0147, 0.0135]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0156, 0.0148]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0136]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0192, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0266, 0.0203, 0.0173]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0262, 0.0202, 0.0167]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0195, 0.0194]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0427, 0.0391, 0.0294]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0650, 0.0475, 0.0409]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0240, 0.0140, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0647, 0.0442, 0.0396]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0207, 0.0196, 0.0192]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0184, 0.0175, 0.0124]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0189, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0295, 0.0251]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0338, 0.0197, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0203, 0.0192, 0.0179]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0591, 0.0296, 0.0250]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0278, 0.0203, 0.0191]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0142, 0.0121, 0.0111]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0224, 0.0208, 0.0150]),\n",
      "indices=tensor([1110, 1081, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0590, 0.0294, 0.0249]),\n",
      "indices=tensor([1110, 1180, 1049]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0286, 0.0155, 0.0154]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0437, 0.0317, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0480, 0.0353, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0120, 0.0119]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0125, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0182, 0.0161, 0.0155]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0333, 0.0178, 0.0167]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0295, 0.0184, 0.0172]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0126, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0137]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0604, 0.0420, 0.0289]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0135, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0145, 0.0144]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0299, 0.0203, 0.0177]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0131, 0.0119]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0145, 0.0140]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0130, 0.0119]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0166, 0.0138, 0.0126]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0141, 0.0133, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0124, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0358, 0.0250, 0.0209]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0149, 0.0146]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0139, 0.0137]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0130, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0174, 0.0124]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0251, 0.0200, 0.0157]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0383, 0.0210, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0261, 0.0177, 0.0174]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0152, 0.0134]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0139, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0206, 0.0196, 0.0191]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0558, 0.0437, 0.0256]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0202, 0.0196]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0128, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0191, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0601, 0.0426, 0.0287]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0138, 0.0122]),\n",
      "indices=tensor([1355, 1252, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0198, 0.0189, 0.0172]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0397, 0.0283, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0487, 0.0359, 0.0214]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0141, 0.0129]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0127, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0183, 0.0177]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0304, 0.0170, 0.0166]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0294, 0.0169, 0.0166]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0182, 0.0173, 0.0125]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0559, 0.0314, 0.0236]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0423, 0.0273, 0.0241]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0185, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0320, 0.0192, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0467, 0.0341, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0152, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0351, 0.0245, 0.0205]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0137, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0192, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0184, 0.0127]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0138, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0133, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0210, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0120]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0360, 0.0204, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0561, 0.0309, 0.0239]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0330, 0.0227, 0.0194]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0121, 0.0120]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0167, 0.0166]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0464, 0.0396, 0.0319]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0167, 0.0166]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0132, 0.0122]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0193, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0128, 0.0121]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0249, 0.0187, 0.0165]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0239, 0.0161, 0.0156]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0200, 0.0182, 0.0124]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0140, 0.0121, 0.0113]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0203, 0.0189]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0240, 0.0194, 0.0158]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0339, 0.0198, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0936, 0.0632, 0.0515]),\n",
      "indices=tensor([1359, 1387, 1349]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0239, 0.0195, 0.0158]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0256, 0.0201, 0.0161]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0206, 0.0196, 0.0192]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0173, 0.0142]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0171, 0.0139]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0232, 0.0162, 0.0160]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0475, 0.0349, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0515, 0.0389, 0.0213]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0294, 0.0251]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0272, 0.0197, 0.0194]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0260, 0.0202, 0.0166]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0489, 0.0362, 0.0213]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0247, 0.0166, 0.0165]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0300, 0.0170, 0.0166]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0130, 0.0119]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0386, 0.0210, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0230, 0.0203, 0.0151]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0364, 0.0255, 0.0212]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0287, 0.0194, 0.0171]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0139, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0153, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0644, 0.0488, 0.0440]),\n",
      "indices=tensor([1359, 1350, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0126, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0196, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0200, 0.0196, 0.0187]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0482, 0.0381, 0.0325]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0422, 0.0417, 0.0306]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0437, 0.0410, 0.0311]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0387, 0.0204, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0148, 0.0146]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0124, 0.0124, 0.0120]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0121, 0.0114]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0197, 0.0155, 0.0149]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0494, 0.0366, 0.0212]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0272, 0.0150, 0.0148]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0267, 0.0163, 0.0163]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0348, 0.0242, 0.0203]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0538, 0.0414, 0.0235]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0134, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0147, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0390, 0.0211, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0248, 0.0200, 0.0155]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0190, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0137]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0597, 0.0369, 0.0314]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0147, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0145, 0.0143]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0222, 0.0160, 0.0156]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0370, 0.0207, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0166, 0.0133]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0182, 0.0159, 0.0153]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0131, 0.0119]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0261, 0.0177, 0.0174]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0201, 0.0196, 0.0188]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1073, 0.0780, 0.0607]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0135, 0.0123]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0585, 0.0382, 0.0303]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0129, 0.0126]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0137, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0161, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0314, 0.0190, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0275, 0.0198, 0.0194]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0269, 0.0203, 0.0178]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0154, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0241, 0.0161, 0.0156]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0167, 0.0166]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0566, 0.0402, 0.0290]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0152, 0.0142]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0148, 0.0135]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0285, 0.0154, 0.0154]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0313, 0.0172, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0418, 0.0418, 0.0305]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0149, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0129, 0.0128]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0153, 0.0149]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0295, 0.0184, 0.0172]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0151, 0.0148]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0160, 0.0151, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0219, 0.0160, 0.0155]),\n",
      "indices=tensor([1425, 1435, 1420]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0273, 0.0203, 0.0183]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0423, 0.0304, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0542, 0.0419, 0.0239]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0154, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0132, 0.0119]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0196, 0.0194]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0585, 0.0445, 0.0281]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0136, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0180, 0.0175]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0513, 0.0404, 0.0262]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0127, 0.0127, 0.0119]),\n",
      "indices=tensor([1463, 1425, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0132, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0199, 0.0196]),\n",
      "indices=tensor([1081, 1031, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0268, 0.0195, 0.0192]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0213, 0.0158, 0.0153]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0546, 0.0341, 0.0240]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0329, 0.0195, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0142, 0.0121, 0.0111]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0134, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0220, 0.0134, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0178, 0.0155, 0.0146]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0304, 0.0163, 0.0159]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0244, 0.0198, 0.0152]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0342, 0.0199, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0398, 0.0284, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0166, 0.0146, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0163, 0.0163]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0125, 0.0125]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0144, 0.0143]),\n",
      "indices=tensor([1290, 1406, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0203, 0.0196, 0.0189]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0257, 0.0202, 0.0161]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0200, 0.0196, 0.0187]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0228, 0.0205, 0.0149]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0387, 0.0292]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0373, 0.0196, 0.0182]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0129, 0.0125]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0216, 0.0159, 0.0154]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0335, 0.0231, 0.0196]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0320, 0.0172, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0296, 0.0252]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0241, 0.0164, 0.0164]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0384, 0.0204, 0.0197]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0134, 0.0128, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0146, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0324, 0.0193, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0398, 0.0283, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1052, 0.0756, 0.0590]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0594, 0.0373, 0.0311]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0143, 0.0141]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0565, 0.0445, 0.0264]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0591, 0.0297, 0.0250]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0434, 0.0353, 0.0277]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0140, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0390, 0.0206, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0129, 0.0128]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0134, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0131, 0.0129]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0271, 0.0203, 0.0180]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0212, 0.0158, 0.0153]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0166, 0.0160, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0170, 0.0138]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0283, 0.0153, 0.0153]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0165, 0.0132]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0165, 0.0163]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0122, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0863, 0.0561, 0.0483]),\n",
      "indices=tensor([1359, 1387, 1349]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0186, 0.0165]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0369, 0.0259, 0.0214]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0386, 0.0210, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0127, 0.0125, 0.0119]),\n",
      "indices=tensor([1463, 1425, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0202, 0.0196]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0252, 0.0184, 0.0168]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0133, 0.0130]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0252, 0.0162, 0.0159]),\n",
      "indices=tensor([1346, 1290, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0199, 0.0196, 0.0186]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0165, 0.0162]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0300, 0.0204, 0.0178]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0122, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0345, 0.0200, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0341, 0.0199, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0379, 0.0268, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0609, 0.0369, 0.0279]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0642, 0.0640, 0.0463]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0493, 0.0365, 0.0340]),\n",
      "indices=tensor([1350, 1346, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0138, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1081]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0264, 0.0176, 0.0175]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0302, 0.0186, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0154, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0410, 0.0241, 0.0225]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0156, 0.0152]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0206, 0.0193, 0.0185]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0511, 0.0409, 0.0264]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0324, 0.0223, 0.0191]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0291, 0.0168, 0.0165]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0131, 0.0121, 0.0120]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0522, 0.0396, 0.0219]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0271, 0.0175, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0258, 0.0187, 0.0185]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0196, 0.0190]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0152, 0.0143]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0232, 0.0137, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0144, 0.0143]),\n",
      "indices=tensor([1290, 1327, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0501, 0.0373, 0.0210]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0221, 0.0159, 0.0154]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0166, 0.0159, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0214, 0.0188, 0.0133]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0159, 0.0132]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0412, 0.0245, 0.0227]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0155, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0140, 0.0129]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0219, 0.0211, 0.0158]),\n",
      "indices=tensor([1081, 1110, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0132, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0202, 0.0183, 0.0125]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0432, 0.0318, 0.0262]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0367, 0.0206, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0173, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0421, 0.0410, 0.0302]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0196, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0512, 0.0385, 0.0211]),\n",
      "indices=tensor([1110, 1180, 1101]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0183, 0.0158]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0343, 0.0183, 0.0169]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0269, 0.0174, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0302, 0.0186, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0196, 0.0147]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0365, 0.0205, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0581, 0.0449, 0.0278]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0138, 0.0130]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0291, 0.0168, 0.0165]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0508, 0.0414, 0.0265]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0377, 0.0266, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0160, 0.0157, 0.0133]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0139, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0168, 0.0128]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0644, 0.0418, 0.0385]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0175, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0168, 0.0136]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0512, 0.0408, 0.0263]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0338, 0.0198, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0377, 0.0198, 0.0187]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0124, 0.0123, 0.0120]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0228, 0.0193, 0.0142]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0480, 0.0353, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0319, 0.0191, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0228, 0.0193, 0.0142]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0325, 0.0223, 0.0191]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0164, 0.0132]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0128, 0.0124]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0301, 0.0162, 0.0158]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0195, 0.0190]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0261, 0.0202, 0.0167]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0512, 0.0385, 0.0211]),\n",
      "indices=tensor([1110, 1180, 1101]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0170, 0.0169]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0280, 0.0202, 0.0196]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0159, 0.0153]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0488, 0.0361, 0.0213]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0131, 0.0119]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0199, 0.0196, 0.0186]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0154, 0.0142, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0298, 0.0161, 0.0157]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0121, 0.0114]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0322, 0.0193, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0192, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0430, 0.0379, 0.0289]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0539, 0.0416, 0.0236]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0349, 0.0201, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0142, 0.0140]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0191, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0268, 0.0203, 0.0175]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0131, 0.0119]),\n",
      "indices=tensor([1400, 1319, 1416]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0546, 0.0342, 0.0240]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0124, 0.0123, 0.0120]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0141, 0.0133, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0297, 0.0160, 0.0157]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0481, 0.0381, 0.0325]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0202, 0.0196, 0.0188]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0139, 0.0137]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0358, 0.0250, 0.0209]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0129, 0.0127]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0165, 0.0163]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0142, 0.0121, 0.0112]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0217, 0.0159, 0.0154]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0173, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0196, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0139, 0.0122]),\n",
      "indices=tensor([1355, 1252, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0159, 0.0153]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0227, 0.0205, 0.0149]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0196, 0.0193]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0201, 0.0156, 0.0150]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0187, 0.0166]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0275, 0.0203, 0.0186]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0127, 0.0124]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0243, 0.0192, 0.0160]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0336, 0.0197, 0.0177]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0121, 0.0115]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0253, 0.0144, 0.0138]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0365, 0.0194, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0195, 0.0184]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0125, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0121, 0.0117]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0537, 0.0413, 0.0234]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0179, 0.0121]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0518, 0.0395, 0.0259]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0282, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0268, 0.0174, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0541, 0.0351, 0.0243]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0450, 0.0327, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0320, 0.0220, 0.0189]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0271, 0.0165, 0.0163]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0942, 0.0578, 0.0510]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0190, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0177, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0184, 0.0159]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0251, 0.0200, 0.0157]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0164, 0.0130]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0356, 0.0248, 0.0207]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0129, 0.0121, 0.0121]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0383, 0.0202, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0164, 0.0132]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0199, 0.0197]),\n",
      "indices=tensor([1081, 1031, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0425, 0.0397, 0.0296]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0355, 0.0203, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0591, 0.0494, 0.0428]),\n",
      "indices=tensor([1359, 1350, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0129, 0.0123]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0167, 0.0167]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0410, 0.0241, 0.0225]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0385, 0.0210, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0381, 0.0269, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0270, 0.0203, 0.0179]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0378, 0.0200, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0245, 0.0190, 0.0162]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0127, 0.0127, 0.0119]),\n",
      "indices=tensor([1463, 1425, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0349, 0.0243, 0.0204]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0168, 0.0167]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0275, 0.0203, 0.0186]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0164, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0258, 0.0179, 0.0172]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0413, 0.0296, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0168, 0.0168]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0325, 0.0193, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0394, 0.0280, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0276, 0.0203, 0.0188]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0175, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0148, 0.0137]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0196, 0.0191]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0448, 0.0326, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0179, 0.0174]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0601, 0.0328, 0.0264]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0179, 0.0174]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0362, 0.0192, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0240, 0.0161, 0.0156]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0138, 0.0131]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0133, 0.0121, 0.0118]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0148, 0.0135]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0287, 0.0181, 0.0171]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0391, 0.0211, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0121, 0.0116]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0184, 0.0164, 0.0160]),\n",
      "indices=tensor([1400, 1319, 1232]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0137, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0427, 0.0389, 0.0293]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0271, 0.0203, 0.0180]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0121, 0.0112]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0262, 0.0176, 0.0175]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0518, 0.0443, 0.0289]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0154, 0.0150]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0154, 0.0148]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0211, 0.0158, 0.0152]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0195, 0.0190]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0173, 0.0141]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0129, 0.0129]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0260, 0.0202, 0.0165]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0381, 0.0269, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0258, 0.0202, 0.0163]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0485, 0.0377, 0.0327]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0390, 0.0207, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0527, 0.0401, 0.0224]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0263, 0.0203, 0.0169]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0385, 0.0203, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0121]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0201, 0.0157, 0.0153]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0249, 0.0180, 0.0180]),\n",
      "indices=tensor([1081, 1031, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0185, 0.0162]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0148, 0.0145]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0598, 0.0318, 0.0260]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0155, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0132, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0216, 0.0159, 0.0154]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0252, 0.0201, 0.0158]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0132, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0178, 0.0174]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0529, 0.0404, 0.0226]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0567, 0.0298, 0.0248]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0274, 0.0150, 0.0149]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0203, 0.0190]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0156, 0.0148]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0197, 0.0196, 0.0185]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0313, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0345, 0.0200, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0151, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0164, 0.0161]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0311, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0133, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0123]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0142, 0.0121, 0.0112]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0533, 0.0409, 0.0230]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0150, 0.0141]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0197, 0.0155]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0189, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0546, 0.0342, 0.0240]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0153, 0.0149]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0165, 0.0162]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0426, 0.0307, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0122]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0134, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0173, 0.0125]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0715, 0.0628, 0.0478]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0316, 0.0172, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0456, 0.0401, 0.0317]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0121, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0520, 0.0394, 0.0218]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0408, 0.0292, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0180, 0.0121]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0200, 0.0198]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0148, 0.0145]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0251, 0.0200, 0.0157]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0244, 0.0198, 0.0152]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0167, 0.0134]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0343, 0.0238, 0.0201]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0128, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0135, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0263, 0.0203, 0.0169]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0409, 0.0293, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0650, 0.0479, 0.0411]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0217, 0.0214]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0143, 0.0138, 0.0128]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0172, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0153, 0.0146]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0195, 0.0194]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0145, 0.0142]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0195, 0.0189]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0121, 0.0118]),\n",
      "indices=tensor([1400, 1416, 1319]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0222, 0.0191, 0.0138]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0180, 0.0121]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0177, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0131, 0.0119]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0155, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0377, 0.0199, 0.0177]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0378, 0.0200, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0479, 0.0352, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0145, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0327, 0.0194, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0306, 0.0187, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0363, 0.0192, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0152, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0153, 0.0134]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0263, 0.0203, 0.0169]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0576, 0.0451, 0.0275]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0808, 0.0608, 0.0493]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0321, 0.0192, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0197, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0196, 0.0147]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0201, 0.0133, 0.0127]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0504, 0.0454, 0.0287]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0340, 0.0236, 0.0199]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0550, 0.0417, 0.0291]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0182, 0.0155]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0178, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0177, 0.0174]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0148, 0.0121, 0.0117]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0340, 0.0236, 0.0199]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0516, 0.0400, 0.0261]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0615, 0.0341, 0.0336]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0145, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0145, 0.0140]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0344, 0.0199, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0196, 0.0146]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0174, 0.0142]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0165, 0.0162]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0273, 0.0176, 0.0169]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0197, 0.0156]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0175, 0.0124]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0284, 0.0154, 0.0153]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0134, 0.0128, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0173, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0228, 0.0202, 0.0164]),\n",
      "indices=tensor([1081, 1110, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0382, 0.0209, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0338, 0.0180, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0137, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0249, 0.0187, 0.0165]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0143, 0.0129, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0243, 0.0141, 0.0133]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0293, 0.0183, 0.0171]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0645, 0.0427, 0.0389]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0166, 0.0164]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0233, 0.0160, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0246, 0.0189, 0.0163]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0160, 0.0152, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0168, 0.0167]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0132, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0247, 0.0199, 0.0154]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0196, 0.0190]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0474, 0.0389, 0.0322]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0141, 0.0138, 0.0125]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0382, 0.0270, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0128, 0.0124]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0128, 0.0121]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0145, 0.0135]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0524, 0.0398, 0.0221]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1062, 0.0550, 0.0519]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0293, 0.0251]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0136, 0.0124]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0390, 0.0277, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0502, 0.0374, 0.0210]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0563, 0.0443, 0.0262]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0449, 0.0404, 0.0315]),\n",
      "indices=tensor([1350, 1346, 1311]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0129, 0.0127]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0246, 0.0166, 0.0165]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0195, 0.0183]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0576, 0.0495, 0.0424]),\n",
      "indices=tensor([1359, 1350, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0497, 0.0434, 0.0271]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0522, 0.0396, 0.0219]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0156, 0.0150]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0405, 0.0290, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0657, 0.0487, 0.0442]),\n",
      "indices=tensor([1359, 1350, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0269, 0.0149, 0.0146]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0422, 0.0268, 0.0238]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0484, 0.0377, 0.0326]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0317, 0.0191, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0496, 0.0361, 0.0356]),\n",
      "indices=tensor([1350, 1359, 1346]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0430, 0.0306, 0.0257]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0163, 0.0163]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0249, 0.0143, 0.0136]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0481, 0.0382, 0.0325]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0171, 0.0170]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0166, 0.0129]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0403, 0.0228, 0.0219]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0312, 0.0167, 0.0161]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0371, 0.0196, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0172, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0185, 0.0162]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0203, 0.0171]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0497, 0.0369, 0.0211]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0153, 0.0146]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0175, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0140, 0.0128]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1109, 0.0822, 0.0635]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0199, 0.0190, 0.0174]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0196, 0.0147]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0268, 0.0179, 0.0172]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0129, 0.0123]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0131]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0263, 0.0191, 0.0189]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0120]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0178, 0.0155, 0.0146]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0178, 0.0174]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0193, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0193, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0348, 0.0242, 0.0203]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0145, 0.0141]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0184, 0.0127]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0314, 0.0168, 0.0161]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0202, 0.0195]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0405, 0.0289, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0918, 0.0584, 0.0507]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0255, 0.0182, 0.0170]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0168, 0.0168]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0245, 0.0165, 0.0164]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0178, 0.0155, 0.0146]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0142, 0.0138, 0.0128]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0149, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0385, 0.0203, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0415, 0.0253, 0.0230]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0294, 0.0251]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0164, 0.0162]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0120, 0.0119]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0196, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0173, 0.0125]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0180, 0.0153]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0322, 0.0173, 0.0164]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0241, 0.0164, 0.0164]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0298, 0.0169, 0.0166]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0337, 0.0197, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0417, 0.0300, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0228, 0.0160, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0257, 0.0202, 0.0162]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0242, 0.0198, 0.0151]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0398, 0.0283, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0182, 0.0176]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0539, 0.0415, 0.0235]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0132, 0.0121, 0.0119]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0138, 0.0135]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0500, 0.0438, 0.0383]),\n",
      "indices=tensor([1350, 1359, 1373]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0186, 0.0129]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0161, 0.0156]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0129, 0.0128]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0139, 0.0127]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0293, 0.0158, 0.0156]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0186, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0139, 0.0122]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0191, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0269, 0.0203, 0.0177]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0438, 0.0410, 0.0312]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0425, 0.0397, 0.0296]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0609, 0.0401, 0.0288]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0366, 0.0194, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0203, 0.0189]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0151, 0.0142]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0157, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0243, 0.0141, 0.0133]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0511, 0.0410, 0.0264]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0250, 0.0167, 0.0165]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0161, 0.0156]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0191, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0203, 0.0190]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0202, 0.0196, 0.0189]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0368, 0.0206, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0165, 0.0132]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0147, 0.0137]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0166, 0.0164]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0196, 0.0193]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0133, 0.0122]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0190, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0185, 0.0163]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0312, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0264, 0.0192, 0.0189]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0309, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0339, 0.0234, 0.0198]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0141, 0.0139]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0184, 0.0162, 0.0158]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0125, 0.0125]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0332, 0.0229, 0.0195]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0497, 0.0435, 0.0271]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0399, 0.0222, 0.0216]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0125, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0385, 0.0203, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0125, 0.0122, 0.0120]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0163, 0.0162]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0607, 0.0353, 0.0274]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0510, 0.0382, 0.0209]),\n",
      "indices=tensor([1110, 1180, 1101]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0464, 0.0338, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0146, 0.0135]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0499, 0.0371, 0.0210]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0132, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0371, 0.0261, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0587, 0.0444, 0.0281]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0182, 0.0160, 0.0154]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0462, 0.0337, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0324, 0.0223, 0.0191]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0148, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0253, 0.0184, 0.0168]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0408, 0.0238, 0.0224]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0220, 0.0190, 0.0137]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0385, 0.0273, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0467, 0.0393, 0.0320]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0427, 0.0309, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0501, 0.0476, 0.0396]),\n",
      "indices=tensor([1350, 1359, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0121, 0.0111]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0314, 0.0169, 0.0162]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0483, 0.0379, 0.0326]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0211, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0161, 0.0156]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0435, 0.0411, 0.0311]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0254, 0.0201, 0.0159]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0272, 0.0197, 0.0193]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0197, 0.0196, 0.0185]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0941, 0.0579, 0.0510]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0137, 0.0135]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0128, 0.0124]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0137, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0294, 0.0199, 0.0175]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0524, 0.0399, 0.0221]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0141, 0.0121, 0.0113]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0536, 0.0412, 0.0233]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0250, 0.0186, 0.0166]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0550, 0.0427, 0.0247]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0368, 0.0259, 0.0214]),\n",
      "indices=tensor([1110, 1180,  927]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0128, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0145, 0.0143]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0174, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0121, 0.0115]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0142, 0.0131]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0252, 0.0168, 0.0166]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0603, 0.0423, 0.0288]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0119]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0141, 0.0138, 0.0126]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0414, 0.0250, 0.0229]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0156, 0.0152]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0463, 0.0338, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0202, 0.0191, 0.0179]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0514, 0.0387, 0.0211]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0456, 0.0400, 0.0317]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0307, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0127, 0.0122, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0349, 0.0242, 0.0204]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0203, 0.0196, 0.0189]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0198, 0.0155, 0.0149]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0156, 0.0149]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0161, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0202, 0.0183, 0.0125]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0533, 0.0409, 0.0230]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0596, 0.0310, 0.0256]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0169, 0.0168]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0649, 0.0461, 0.0404]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0300, 0.0204, 0.0178]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0132, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0388, 0.0205, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0194, 0.0183]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0251, 0.0200, 0.0157]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0136, 0.0124]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0143, 0.0129, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0133, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0289, 0.0181, 0.0171]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0121, 0.0117]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0522, 0.0395, 0.0219]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0122]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0178, 0.0154, 0.0146]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0652, 0.0551, 0.0438]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0342, 0.0182, 0.0169]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0175, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0608, 0.0410, 0.0290]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0379, 0.0200, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0144, 0.0144]),\n",
      "indices=tensor([1290, 1406, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0180, 0.0175]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0404, 0.0231, 0.0220]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0131, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0480, 0.0382, 0.0324]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0324, 0.0193, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0159, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0126, 0.0125]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0195, 0.0194]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0154, 0.0143, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0226, 0.0193, 0.0141]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0128, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0131, 0.0128, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0196, 0.0184]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0215, 0.0159, 0.0153]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0326, 0.0225, 0.0192]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0139, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0125, 0.0121, 0.0119]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0125, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0375, 0.0198, 0.0177]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0315, 0.0172, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0162, 0.0158]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0395, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0356, 0.0203, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0136, 0.0124]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0134, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0312, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0566, 0.0298, 0.0248]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0324, 0.0193, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0366, 0.0194, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0413, 0.0247, 0.0228]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0154, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0178, 0.0154, 0.0145]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0194, 0.0183]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0603, 0.0360, 0.0321]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0264, 0.0148, 0.0144]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0141, 0.0139]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0230, 0.0194, 0.0143]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0464, 0.0338, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0225, 0.0160, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0510, 0.0411, 0.0264]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0373, 0.0263, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0324, 0.0223, 0.0191]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0146, 0.0145]),\n",
      "indices=tensor([1290, 1346, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0258, 0.0170, 0.0167]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0160, 0.0130, 0.0119]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0221, 0.0210, 0.0159]),\n",
      "indices=tensor([1081, 1110, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0365, 0.0206, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0257, 0.0145, 0.0140]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0154, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0185, 0.0177]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0607, 0.0354, 0.0274]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0278, 0.0203, 0.0193]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0129, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0350, 0.0179, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0402, 0.0287, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0386, 0.0204, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0427, 0.0290, 0.0249]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0148, 0.0134, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0166, 0.0147, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0195, 0.0190]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0143, 0.0121, 0.0111]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0295, 0.0183, 0.0172]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0278, 0.0203, 0.0191]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0123]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0390, 0.0211, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0378, 0.0267, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0382, 0.0270, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0633, 0.0374, 0.0364]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0124, 0.0123, 0.0120]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0301, 0.0170, 0.0166]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0154, 0.0148]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0625, 0.0350, 0.0349]),\n",
      "indices=tensor([ 956, 1155, 1086]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0181, 0.0176]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0178, 0.0174]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0274, 0.0203, 0.0185]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0198, 0.0196, 0.0185]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0481, 0.0381, 0.0325]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0239, 0.0195, 0.0157]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0259, 0.0162, 0.0161]),\n",
      "indices=tensor([1346, 1290, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0135, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0602, 0.0330, 0.0265]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0163, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0140, 0.0139, 0.0124]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0275, 0.0151, 0.0149]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0216, 0.0189, 0.0134]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0170, 0.0138]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0439, 0.0318, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0166, 0.0164]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0149, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0261, 0.0190, 0.0188]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0223, 0.0191, 0.0138]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0186, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0270, 0.0149, 0.0147]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0142, 0.0121, 0.0111]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0211, 0.0187, 0.0131]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0134, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0244, 0.0165, 0.0164]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1008, 0.0707, 0.0557]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0255, 0.0162, 0.0159]),\n",
      "indices=tensor([1346, 1290, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0298, 0.0161, 0.0157]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0533, 0.0409, 0.0230]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0594, 0.0436, 0.0285]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0226, 0.0193, 0.0141]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0178, 0.0177, 0.0147]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0143, 0.0133]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0347, 0.0200, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0201, 0.0196, 0.0187]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0156, 0.0152]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0315, 0.0190, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0274, 0.0203, 0.0185]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0267, 0.0174, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0195, 0.0183]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0169, 0.0169]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0148, 0.0137]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0193, 0.0182]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0176, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0217, 0.0214, 0.0156]),\n",
      "indices=tensor([1081, 1110, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1136, 0.0854, 0.0656]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0249, 0.0200, 0.0155]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0434, 0.0338, 0.0271]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0775, 0.0615, 0.0488]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0507, 0.0379, 0.0208]),\n",
      "indices=tensor([1110, 1180, 1101]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0609, 0.0390, 0.0285]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0294, 0.0159, 0.0156]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0145, 0.0135]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0174, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0488, 0.0361, 0.0213]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0158, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0198, 0.0155]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0121, 0.0114]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0154, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0479, 0.0383, 0.0324]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0132, 0.0121, 0.0119]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0336, 0.0179, 0.0167]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0175, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0322, 0.0193, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0173, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0149, 0.0139]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0636, 0.0383, 0.0368]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0482, 0.0380, 0.0325]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0679, 0.0635, 0.0471]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0170, 0.0169]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0275, 0.0203, 0.0186]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0130, 0.0129]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0484, 0.0377, 0.0326]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0196, 0.0147]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0133, 0.0121, 0.0119]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0125, 0.0122, 0.0120]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0121, 0.0118]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0425, 0.0416, 0.0307]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0181, 0.0176]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0211, 0.0133, 0.0131]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0288, 0.0195, 0.0171]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0645, 0.0641, 0.0464]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0188, 0.0179]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0247, 0.0142, 0.0135]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0182, 0.0176]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0425, 0.0279, 0.0244]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0527, 0.0402, 0.0224]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0128, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0197, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0145, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0146, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0481, 0.0462, 0.0278]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0242, 0.0187, 0.0175]),\n",
      "indices=tensor([1081, 1110, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0157, 0.0150]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0470, 0.0391, 0.0321]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0330, 0.0177, 0.0166]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0267, 0.0203, 0.0175]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0644, 0.0420, 0.0386]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0143, 0.0138, 0.0129]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0525, 0.0399, 0.0222]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0206, 0.0193, 0.0185]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0376, 0.0265, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0839, 0.0538, 0.0471]),\n",
      "indices=tensor([1359, 1387, 1349]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0158, 0.0151]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0232, 0.0160, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0339, 0.0198, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0200, 0.0198]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0199, 0.0196, 0.0186]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0491, 0.0363, 0.0213]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0177, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0509, 0.0413, 0.0265]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0483, 0.0356, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0280, 0.0202, 0.0197]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0485, 0.0454, 0.0277]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0166, 0.0133]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0165, 0.0130]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0194, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0226, 0.0135, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0647, 0.0438, 0.0394]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0395, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0558, 0.0437, 0.0256]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0137, 0.0125]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0609, 0.0351, 0.0328]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0176, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0382, 0.0202, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0142, 0.0136]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0124, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0184, 0.0164, 0.0160]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0319, 0.0192, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0418, 0.0258, 0.0233]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0321, 0.0192, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0196, 0.0193]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0619, 0.0342, 0.0334]),\n",
      "indices=tensor([ 956, 1155, 1110]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0174, 0.0142]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0579, 0.0450, 0.0277]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0184, 0.0163, 0.0159]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0202, 0.0196, 0.0189]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0176, 0.0145]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0177, 0.0174]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0220, 0.0212, 0.0152]),\n",
      "indices=tensor([1110, 1081, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0136, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0234, 0.0195, 0.0169]),\n",
      "indices=tensor([1081, 1110, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0166, 0.0133]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0137, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0286, 0.0167, 0.0165]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0163, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0211, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0240, 0.0194, 0.0158]),\n",
      "indices=tensor([1110, 1081, 1180]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0175, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0902, 0.0598, 0.0500]),\n",
      "indices=tensor([1359, 1387, 1349]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0272, 0.0197, 0.0193]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0121, 0.0118]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0143, 0.0129, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0156, 0.0148]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0170, 0.0138]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0543, 0.0423, 0.0291]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0186, 0.0129]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0154, 0.0151]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0195, 0.0191]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0139, 0.0138]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0184, 0.0164, 0.0160]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0535, 0.0411, 0.0232]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0194, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0230, 0.0194, 0.0143]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0267, 0.0164, 0.0163]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0230, 0.0137, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0367, 0.0194, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0120, 0.0119]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0387, 0.0206, 0.0202]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0165, 0.0163]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0504, 0.0422, 0.0268]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0121, 0.0117]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0229, 0.0136, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0140, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0184, 0.0177]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0195, 0.0192]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0835, 0.0602, 0.0497]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0129, 0.0126]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0121, 0.0114]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0387, 0.0211, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0119]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0140, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0160, 0.0156, 0.0133]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0144, 0.0133]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0215, 0.0188, 0.0133]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0128, 0.0122]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0397, 0.0283, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0491, 0.0368, 0.0335]),\n",
      "indices=tensor([1350, 1346, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0192, 0.0181]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0170, 0.0138]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0121, 0.0118]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0171, 0.0170]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0139, 0.0123]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0166, 0.0134]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0258, 0.0162, 0.0160]),\n",
      "indices=tensor([1346, 1290, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0229, 0.0161, 0.0159]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0203, 0.0172]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0281, 0.0179, 0.0170]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0153, 0.0150]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0159, 0.0129, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0132, 0.0121, 0.0119]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0187, 0.0179]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0785, 0.0488, 0.0465]),\n",
      "indices=tensor([1359, 1387, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0177, 0.0174]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0129, 0.0128, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0145, 0.0142]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0221, 0.0159, 0.0154]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0127, 0.0126, 0.0119]),\n",
      "indices=tensor([1463, 1425, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0700, 0.0480, 0.0450]),\n",
      "indices=tensor([1359, 1350, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0278, 0.0203, 0.0191]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0225, 0.0192, 0.0140]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0327, 0.0194, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0166, 0.0133]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0126, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0184, 0.0151, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0256, 0.0170, 0.0166]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0171, 0.0170]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0159, 0.0153]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0145, 0.0145]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0215, 0.0133, 0.0132]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0253, 0.0183, 0.0168]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0478, 0.0352, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0179, 0.0151]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0129, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0178, 0.0148]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0173, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0634, 0.0378, 0.0365]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0370, 0.0196, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0148, 0.0121, 0.0116]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0156, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0395, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0275, 0.0177, 0.0169]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0145, 0.0134]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0228, 0.0193, 0.0142]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0307, 0.0188, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0196, 0.0184]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0234, 0.0199, 0.0154]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0606, 0.0350, 0.0273]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0533, 0.0409, 0.0230]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0125, 0.0125]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0206, 0.0196, 0.0192]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0271, 0.0203, 0.0180]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0304, 0.0207, 0.0180]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0414, 0.0297, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0197, 0.0181, 0.0122]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0305, 0.0164, 0.0159]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0164, 0.0161]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0182, 0.0180, 0.0151]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0203, 0.0189]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0448, 0.0405, 0.0315]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0292, 0.0197, 0.0173]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0200, 0.0198]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0179, 0.0175]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0179, 0.0174]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0564, 0.0444, 0.0263]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0186, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0278, 0.0187, 0.0166]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0159, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0327, 0.0225, 0.0192]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0121]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0151, 0.0142]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0207, 0.0194, 0.0187]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0126, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0153, 0.0149]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0147, 0.0137]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0134, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0368, 0.0206, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0595, 0.0371, 0.0313]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0145, 0.0143]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0240, 0.0161, 0.0156]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0140, 0.0121, 0.0113]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0168, 0.0128]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0203, 0.0194]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0472, 0.0390, 0.0322]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0245, 0.0165, 0.0164]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0296, 0.0201, 0.0176]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0500, 0.0372, 0.0210]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0336, 0.0174, 0.0171]),\n",
      "indices=tensor([1346, 1134, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0585, 0.0381, 0.0304]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0553, 0.0414, 0.0291]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0119]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0344, 0.0176, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0331, 0.0228, 0.0194]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0123]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0342, 0.0237, 0.0200]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0580, 0.0272, 0.0269]),\n",
      "indices=tensor([1110, 1180,  956]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0652, 0.0512, 0.0424]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0196, 0.0193]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0159, 0.0150, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1103, 0.0814, 0.0630]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0139, 0.0122]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0643, 0.0413, 0.0383]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0162, 0.0158]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0280, 0.0202, 0.0196]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0257, 0.0145, 0.0140]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0159, 0.0150, 0.0147]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0417, 0.0257, 0.0233]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0307, 0.0188, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0139, 0.0127]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0131, 0.0129]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0144, 0.0133]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0178, 0.0174]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0132, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0149, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0137, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0221, 0.0160, 0.0156]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0196, 0.0190]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0183, 0.0159]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0415, 0.0251, 0.0230]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0449, 0.0326, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0440, 0.0319, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1105, 0.0816, 0.0631]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0133, 0.0122]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0921, 0.0583, 0.0508]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0188, 0.0170]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0147, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0129, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0146, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0353, 0.0202, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0568, 0.0400, 0.0290]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0399, 0.0222, 0.0216]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0349, 0.0179, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0535, 0.0411, 0.0232]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0222, 0.0159, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0313, 0.0172, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0214, 0.0188, 0.0133]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0148, 0.0137, 0.0137]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0389, 0.0276, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0479, 0.0465, 0.0279]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0193, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0203, 0.0171]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0177, 0.0169]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0350, 0.0186, 0.0171]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0600, 0.0365, 0.0318]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0391, 0.0209, 0.0208]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0206, 0.0196, 0.0191]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0639, 0.0395, 0.0374]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0495, 0.0461, 0.0286]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0147, 0.0137]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0221, 0.0191, 0.0137]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0391, 0.0207, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0426, 0.0392, 0.0294]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0152, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0269, 0.0164, 0.0163]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0192, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0247, 0.0162, 0.0157]),\n",
      "indices=tensor([1346, 1290, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0202, 0.0183, 0.0125]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0382, 0.0270, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0315, 0.0215, 0.0186]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0179, 0.0120]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0429, 0.0299, 0.0253]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0196, 0.0147]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0358, 0.0184, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0128, 0.0121, 0.0121]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0131, 0.0121, 0.0120]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0470, 0.0344, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0500, 0.0428, 0.0269]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0380, 0.0268, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0365, 0.0193, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1057, 0.0551, 0.0518]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0128, 0.0124]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0132, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0223, 0.0135, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0162, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0243, 0.0165, 0.0164]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0159, 0.0131, 0.0119]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0134, 0.0121, 0.0117]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0133]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0177, 0.0174]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0518, 0.0396, 0.0259]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0163, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0193, 0.0171]),\n",
      "indices=tensor([1081, 1110, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0398, 0.0284, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0125, 0.0125]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0196, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0415, 0.0253, 0.0230]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0146, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0220, 0.0211, 0.0158]),\n",
      "indices=tensor([1081, 1110, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0140, 0.0129]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0306, 0.0164, 0.0159]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0134, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0190, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0153, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0462, 0.0337, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0250, 0.0162, 0.0158]),\n",
      "indices=tensor([1346, 1290, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0166, 0.0160, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0212, 0.0158, 0.0154]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0319, 0.0219, 0.0188]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0143, 0.0139]),\n",
      "indices=tensor([1327, 1425, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0394, 0.0209, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0193, 0.0183]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0200, 0.0190, 0.0176]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0543, 0.0346, 0.0241]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0554, 0.0325, 0.0233]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0187, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0356, 0.0248, 0.0207]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0183, 0.0158]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0135, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0207, 0.0196, 0.0192]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0511, 0.0383, 0.0210]),\n",
      "indices=tensor([1110, 1180, 1101]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0268, 0.0149, 0.0146]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0392, 0.0208, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0338, 0.0197, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0263, 0.0203, 0.0169]),\n",
      "indices=tensor([1081, 1252, 1031]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0299, 0.0161, 0.0157]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0374, 0.0208, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0188, 0.0179]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0267, 0.0203, 0.0174]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0298, 0.0169, 0.0166]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0182, 0.0160, 0.0155]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0255, 0.0169, 0.0166]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0388, 0.0205, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0421, 0.0303, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0155, 0.0151]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0198, 0.0181, 0.0123]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0138, 0.0137]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0219, 0.0190, 0.0136]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0224, 0.0161, 0.0157]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0369, 0.0259, 0.0214]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0170, 0.0127]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0133, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0159, 0.0150, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0275, 0.0185, 0.0166]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0141, 0.0121, 0.0112]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0273, 0.0183, 0.0168]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0483, 0.0356, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0301, 0.0162, 0.0158]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0195, 0.0194]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0175, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0145, 0.0140]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0556, 0.0434, 0.0253]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0402, 0.0287, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0193, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0128, 0.0123]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0176, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0316, 0.0190, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0246, 0.0199, 0.0153]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0271, 0.0203, 0.0180]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0167, 0.0129]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0185, 0.0162]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0145, 0.0140]),\n",
      "indices=tensor([1327, 1425, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0391, 0.0207, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0142, 0.0133, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0368, 0.0195, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0366, 0.0257, 0.0213]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0257, 0.0180, 0.0171]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0484, 0.0357, 0.0214]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0352, 0.0180, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0258, 0.0202, 0.0163]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0163, 0.0163]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0147, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0229, 0.0203, 0.0150]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0346, 0.0177, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0526, 0.0400, 0.0222]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0259, 0.0146, 0.0141]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0197, 0.0196, 0.0185]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0578, 0.0389, 0.0298]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0129, 0.0128, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0259, 0.0146, 0.0141]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0141, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0157, 0.0153]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0256, 0.0201, 0.0161]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0329, 0.0176, 0.0166]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0168, 0.0168]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0197, 0.0155, 0.0149]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0606, 0.0349, 0.0272]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0207, 0.0158, 0.0153]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0475, 0.0388, 0.0322]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0129, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0167, 0.0135]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0592, 0.0438, 0.0284]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0381, 0.0269, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0167, 0.0166]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0406, 0.0290, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0261, 0.0171, 0.0167]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0476, 0.0349, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0217, 0.0214]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0198, 0.0133, 0.0126]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0125, 0.0121, 0.0119]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0135, 0.0122]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0143, 0.0133, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0413, 0.0247, 0.0228]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0309, 0.0166, 0.0160]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0551, 0.0332, 0.0236]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0272, 0.0183, 0.0168]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0321, 0.0173, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0168, 0.0128]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0128, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0641, 0.0402, 0.0377]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0199, 0.0189, 0.0173]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0121, 0.0113]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0157, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0166, 0.0165, 0.0130]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0198, 0.0155]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0240, 0.0163, 0.0163]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0128, 0.0124]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0163, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0200, 0.0157, 0.0153]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0196, 0.0147]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0121, 0.0114]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0186, 0.0166]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0529, 0.0404, 0.0226]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0251, 0.0200, 0.0157]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0479, 0.0384, 0.0324]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0377, 0.0199, 0.0177]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0637, 0.0388, 0.0370]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0126, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0361, 0.0191, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0467, 0.0393, 0.0320]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0486, 0.0375, 0.0327]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0626, 0.0353, 0.0352]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0207, 0.0196, 0.0192]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0136, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0343, 0.0238, 0.0201]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0199, 0.0196]),\n",
      "indices=tensor([1081, 1031, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0163, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0346, 0.0241, 0.0202]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0191, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0363, 0.0205, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0461, 0.0336, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0516, 0.0399, 0.0260]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1019, 0.0719, 0.0565]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0143, 0.0141]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0141, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0464, 0.0338, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0161, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0125, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0568, 0.0294, 0.0251]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0309, 0.0211, 0.0182]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0608, 0.0367, 0.0278]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0262, 0.0147, 0.0143]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0139, 0.0123]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0244, 0.0199, 0.0153]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0252, 0.0144, 0.0138]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0392, 0.0208, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0192, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0133, 0.0128]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0322, 0.0173, 0.0164]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0202, 0.0195]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0198, 0.0155, 0.0149]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0338, 0.0180, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0188, 0.0169]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0196, 0.0190]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0455, 0.0331, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0599, 0.0321, 0.0261]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0406, 0.0290, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0159, 0.0130, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0532, 0.0407, 0.0229]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0194, 0.0189]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0341, 0.0182, 0.0169]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0133, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0317, 0.0191, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0355, 0.0202, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0382, 0.0202, 0.0194]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0161, 0.0131, 0.0119]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0129, 0.0125]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0143, 0.0132]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0270, 0.0181, 0.0170]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0368, 0.0206, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0213, 0.0188, 0.0132]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0525, 0.0400, 0.0222]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0136, 0.0124]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0398, 0.0220, 0.0215]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0166, 0.0164]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0276, 0.0151, 0.0150]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0480, 0.0383, 0.0324]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0513, 0.0386, 0.0211]),\n",
      "indices=tensor([1110, 1180, 1101]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0200, 0.0198]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0129, 0.0127]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0527, 0.0402, 0.0224]),\n",
      "indices=tensor([1110, 1180, 1049]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0471, 0.0391, 0.0321]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0370, 0.0260, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0141, 0.0137]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0250, 0.0181, 0.0180]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0291, 0.0157, 0.0155]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0600, 0.0323, 0.0262]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0268, 0.0203, 0.0176]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0330, 0.0195, 0.0177]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0370, 0.0207, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0184, 0.0161]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0133, 0.0125]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0148, 0.0121, 0.0116]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0357, 0.0184, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0505, 0.0377, 0.0209]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0171, 0.0126]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0278, 0.0203, 0.0192]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0646, 0.0435, 0.0392]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0122, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0481, 0.0381, 0.0325]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0398, 0.0283, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0218, 0.0190, 0.0135]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0217, 0.0215, 0.0154]),\n",
      "indices=tensor([1110, 1081, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0131, 0.0123]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0164, 0.0161]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0128, 0.0123]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0499, 0.0403, 0.0369]),\n",
      "indices=tensor([1350, 1359, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0477, 0.0386, 0.0323]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0234, 0.0160, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0218, 0.0159, 0.0155]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0391, 0.0211, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0194, 0.0188]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0280, 0.0201, 0.0198]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0177, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0153, 0.0145, 0.0136]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0168, 0.0128]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0129, 0.0121, 0.0121]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0165, 0.0159, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0203, 0.0193]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0196, 0.0195, 0.0183]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0501, 0.0373, 0.0210]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0154, 0.0131, 0.0119]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0506, 0.0418, 0.0266]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0167, 0.0135]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0142, 0.0121, 0.0112]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0433, 0.0359, 0.0280]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0313, 0.0172, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0166, 0.0165, 0.0130]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0165, 0.0163]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0173, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0177, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0145, 0.0134]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0533, 0.0408, 0.0230]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0140, 0.0121, 0.0113]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0366, 0.0190, 0.0174]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0138, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0178, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0497, 0.0374, 0.0358]),\n",
      "indices=tensor([1350, 1359, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0222, 0.0134, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0386, 0.0210, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0168, 0.0128]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0222, 0.0191, 0.0138]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0576, 0.0452, 0.0275]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0168, 0.0162, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0439, 0.0318, 0.0221]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0240, 0.0161, 0.0156]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0608, 0.0408, 0.0289]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0318, 0.0170, 0.0163]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0175, 0.0149, 0.0140]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0151, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0609, 0.0395, 0.0286]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0121, 0.0120]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0131, 0.0123]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0152, 0.0148]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0139, 0.0122]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0141, 0.0133, 0.0131]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0165, 0.0132]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0177, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0137, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0175, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0234, 0.0196, 0.0169]),\n",
      "indices=tensor([1081, 1110, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0568, 0.0448, 0.0268]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0471, 0.0391, 0.0321]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0241, 0.0140, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0383, 0.0271, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0160, 0.0151, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0124]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0352, 0.0245, 0.0205]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0291, 0.0157, 0.0155]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0207, 0.0157, 0.0151]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0297, 0.0202, 0.0176]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0298, 0.0184, 0.0172]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0128, 0.0123]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0145, 0.0142]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0156, 0.0149]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0133]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0136, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0375, 0.0198, 0.0177]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0295, 0.0159, 0.0156]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0121, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0203, 0.0172]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0395, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0187, 0.0167]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0440, 0.0409, 0.0312]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0266, 0.0173, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0239, 0.0197, 0.0149]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0345, 0.0184, 0.0170]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0128, 0.0120]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0153, 0.0150]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0127, 0.0121]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0178, 0.0121]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0128, 0.0124]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0121, 0.0115]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0193, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0162, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0196, 0.0190]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0157, 0.0151]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0644, 0.0418, 0.0385]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0294, 0.0183, 0.0172]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0173, 0.0125]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0196, 0.0190]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0152, 0.0149]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0383, 0.0202, 0.0179]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0199, 0.0196, 0.0186]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0389, 0.0276, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0317, 0.0217, 0.0187]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0206, 0.0196, 0.0192]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0139, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0340, 0.0174, 0.0174]),\n",
      "indices=tensor([1346, 1134, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0450, 0.0327, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0370, 0.0207, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0330, 0.0227, 0.0194]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0165, 0.0162]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0500, 0.0427, 0.0378]),\n",
      "indices=tensor([1350, 1359, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0227, 0.0161, 0.0158]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0133, 0.0122]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0147, 0.0137]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0225, 0.0192, 0.0140]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0219, 0.0160, 0.0155]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0467, 0.0341, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0262, 0.0147, 0.0143]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0217, 0.0189, 0.0135]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0472, 0.0390, 0.0322]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0198, 0.0189, 0.0172]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0256, 0.0201, 0.0161]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0131, 0.0123]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0167, 0.0166]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0652, 0.0539, 0.0433]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0595, 0.0307, 0.0255]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0207, 0.0194, 0.0187]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0273, 0.0203, 0.0182]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0159, 0.0130, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0138, 0.0137]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0133, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0187, 0.0167]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0515, 0.0388, 0.0212]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0230, 0.0162, 0.0160]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0149, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0518, 0.0392, 0.0215]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0126, 0.0125]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0283, 0.0153, 0.0153]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0287, 0.0155, 0.0154]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0729, 0.0476, 0.0455]),\n",
      "indices=tensor([1359, 1350, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0191, 0.0181]),\n",
      "indices=tensor([1400, 1232, 1319]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0129, 0.0123]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0145, 0.0141]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0494, 0.0366, 0.0212]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0169, 0.0142, 0.0131]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0196, 0.0193]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0283, 0.0191, 0.0169]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0203, 0.0172]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0192, 0.0172]),\n",
      "indices=tensor([1081, 1110, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0145, 0.0140]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0173, 0.0168]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0180, 0.0120]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0169, 0.0137]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0384, 0.0291]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0195, 0.0189]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0196, 0.0193]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0405, 0.0232, 0.0221]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0287, 0.0167, 0.0165]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0184, 0.0177]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0127, 0.0124]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0572, 0.0451, 0.0271]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0487, 0.0374, 0.0328]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0154, 0.0151]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0242, 0.0192, 0.0160]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0534, 0.0410, 0.0231]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0158, 0.0128, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0652, 0.0555, 0.0439]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0381, 0.0209, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0359, 0.0204, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0211, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0149, 0.0135]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0164, 0.0164, 0.0130]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0170, 0.0170]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0200, 0.0196, 0.0187]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0457, 0.0400, 0.0317]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0652, 0.0549, 0.0437]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0153, 0.0144]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0488, 0.0361, 0.0213]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0520, 0.0393, 0.0217]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0582, 0.0385, 0.0301]),\n",
      "indices=tensor([ 956, 1110, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0264, 0.0147, 0.0144]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0373, 0.0197, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0255, 0.0201, 0.0160]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0368, 0.0195, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0166, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0120, 0.0119]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0224, 0.0192, 0.0139]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0152, 0.0143]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0121, 0.0113]),\n",
      "indices=tensor([1400, 1416, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0229, 0.0200, 0.0165]),\n",
      "indices=tensor([1081, 1110, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0343, 0.0182, 0.0169]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0164, 0.0161]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0140, 0.0139]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0300, 0.0162, 0.0158]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0127, 0.0122, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0328, 0.0176, 0.0165]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0203, 0.0192, 0.0179]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0133, 0.0123]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0177, 0.0146]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0139, 0.0128]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0220, 0.0211, 0.0152]),\n",
      "indices=tensor([1110, 1081, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0184, 0.0126]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0143, 0.0132]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0128, 0.0124]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0138, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0204, 0.0196, 0.0190]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0200, 0.0196, 0.0187]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0144, 0.0142]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0337, 0.0174, 0.0172]),\n",
      "indices=tensor([1346, 1134, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0473, 0.0389, 0.0322]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0188, 0.0167]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0401, 0.0224, 0.0217]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0166, 0.0129]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0166, 0.0129]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0133, 0.0132]),\n",
      "indices=tensor([1265, 1232, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0145, 0.0140]),\n",
      "indices=tensor([1327, 1425, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0381, 0.0269, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0292, 0.0198, 0.0174]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0366, 0.0194, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0644, 0.0418, 0.0385]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0545, 0.0422, 0.0291]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0166, 0.0165]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0129, 0.0127]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0165, 0.0163]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0635, 0.0381, 0.0367]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0183, 0.0176]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0323, 0.0193, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0136, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0203, 0.0194]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0146, 0.0136]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0267, 0.0203, 0.0175]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0242, 0.0198, 0.0151]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0130, 0.0129]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0150, 0.0147]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0359, 0.0191, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1370]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0232, 0.0137, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0598, 0.0430, 0.0287]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0203, 0.0196, 0.0189]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0131]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0133, 0.0124]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0293, 0.0183, 0.0171]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0124, 0.0123, 0.0120]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0217, 0.0189, 0.0135]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0168, 0.0168]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0363, 0.0192, 0.0174]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0316, 0.0170, 0.0162]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0271, 0.0164, 0.0163]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0363, 0.0254, 0.0211]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0140, 0.0139, 0.0124]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0186, 0.0165]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0381, 0.0209, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0152, 0.0143]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0186, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0154, 0.0143, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0131, 0.0122]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0137]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0463, 0.0338, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0578, 0.0273, 0.0268]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0251, 0.0168, 0.0165]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0137, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0161, 0.0156]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0203, 0.0196, 0.0189]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0221, 0.0134, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0123, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0352, 0.0187, 0.0171]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0142, 0.0140]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0186, 0.0166, 0.0165]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0485, 0.0358, 0.0214]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0216, 0.0189, 0.0134]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0336, 0.0174, 0.0171]),\n",
      "indices=tensor([1346, 1134, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0507, 0.0416, 0.0266]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0202, 0.0196, 0.0188]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0549, 0.0427, 0.0246]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0134, 0.0130]),\n",
      "indices=tensor([1265, 1355, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0181, 0.0173, 0.0125]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0425, 0.0281, 0.0245]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0133, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0235, 0.0196, 0.0146]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0477, 0.0351, 0.0216]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0217, 0.0189, 0.0135]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0147, 0.0137]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0277, 0.0203, 0.0189]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0485, 0.0377, 0.0327]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0257, 0.0180, 0.0171]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0148, 0.0138]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0160, 0.0131, 0.0119]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0188, 0.0171, 0.0170]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0173, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0177, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0133, 0.0124]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0230, 0.0194, 0.0143]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0288, 0.0156, 0.0155]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0149, 0.0146]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0198, 0.0133, 0.0126]),\n",
      "indices=tensor([1425, 1463, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0180, 0.0133, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0131, 0.0123]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0153, 0.0150]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0120, 0.0119]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0311, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0797, 0.0499, 0.0464]),\n",
      "indices=tensor([1359, 1387, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0144, 0.0134]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0357, 0.0203, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0386, 0.0205, 0.0200]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0648, 0.0451, 0.0399]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0139, 0.0137]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0240, 0.0161, 0.0156]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0184, 0.0177]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0335, 0.0232, 0.0197]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0143, 0.0141]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0135, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0365, 0.0206, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0144, 0.0143]),\n",
      "indices=tensor([1290, 1327, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0262, 0.0203, 0.0167]),\n",
      "indices=tensor([1081, 1252, 1031]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0620, 0.0343, 0.0336]),\n",
      "indices=tensor([ 956, 1155, 1086]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0154, 0.0148]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0161, 0.0131]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0453, 0.0329, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0413, 0.0296, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0307, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0132, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0155, 0.0151]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0147, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0509, 0.0382, 0.0209]),\n",
      "indices=tensor([1110, 1180, 1101]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0338, 0.0197, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0186, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0291, 0.0157, 0.0155]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0389, 0.0206, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0257, 0.0202, 0.0162]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0539, 0.0416, 0.0236]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0153, 0.0149]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0319, 0.0171, 0.0163]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0162, 0.0130]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0232, 0.0160, 0.0155]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0391, 0.0210, 0.0209]),\n",
      "indices=tensor([1346, 1311, 1350]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0279, 0.0203, 0.0193]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0150, 0.0145, 0.0141]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0133, 0.0132]),\n",
      "indices=tensor([1265, 1232, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0607, 0.0413, 0.0290]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0340, 0.0198, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0171, 0.0145, 0.0134]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0266, 0.0203, 0.0174]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0484, 0.0357, 0.0214]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0587, 0.0444, 0.0281]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0167, 0.0139, 0.0128]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0328, 0.0174, 0.0168]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0471, 0.0391, 0.0321]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0487, 0.0360, 0.0214]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0227, 0.0161, 0.0158]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0193, 0.0190]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0538, 0.0414, 0.0235]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0302, 0.0186, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0527, 0.0402, 0.0224]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0152, 0.0121, 0.0121]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0539, 0.0415, 0.0235]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0508, 0.0500, 0.0406]),\n",
      "indices=tensor([1359, 1350, 1373]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0217, 0.0159, 0.0154]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0184, 0.0162, 0.0158]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0574, 0.0281, 0.0261]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0121, 0.0117]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0144, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0144, 0.0138, 0.0131]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0262, 0.0203, 0.0168]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0174, 0.0172]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0145, 0.0143]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0151, 0.0134]),\n",
      "indices=tensor([1252, 1081, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0237, 0.0197, 0.0156]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0588, 0.0443, 0.0282]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0513, 0.0406, 0.0262]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0326, 0.0224, 0.0192]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0323, 0.0193, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0184, 0.0161]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0154, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0350, 0.0179, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0634, 0.0376, 0.0364]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0194, 0.0183]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0187, 0.0179]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0269, 0.0203, 0.0178]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0174, 0.0148, 0.0138]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0297, 0.0253]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1045, 0.0748, 0.0585]),\n",
      "indices=tensor([1359, 1387, 1369]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0155, 0.0144, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0283, 0.0191, 0.0168]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0130, 0.0128, 0.0118]),\n",
      "indices=tensor([1425, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0173, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0304, 0.0187, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0290, 0.0182, 0.0171]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0131, 0.0123]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0548, 0.0425, 0.0245]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0499, 0.0371, 0.0210]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0251, 0.0200, 0.0157]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0351, 0.0201, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0129, 0.0129]),\n",
      "indices=tensor([1355, 1244, 1265]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0539, 0.0415, 0.0236]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0216, 0.0215, 0.0155]),\n",
      "indices=tensor([1110, 1081, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0194, 0.0189, 0.0180]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0128, 0.0121, 0.0121]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0444, 0.0322, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0124, 0.0123, 0.0120]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0471, 0.0345, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0121, 0.0114]),\n",
      "indices=tensor([1400, 1416, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0156, 0.0125, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0236, 0.0139, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0187, 0.0152, 0.0146]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0587, 0.0287, 0.0252]),\n",
      "indices=tensor([1110, 1180,  956]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0169, 0.0137]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0325, 0.0193, 0.0176]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0575, 0.0279, 0.0263]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0156, 0.0148]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0213, 0.0158, 0.0153]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0179, 0.0155, 0.0147]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0573, 0.0285, 0.0258]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0148, 0.0137, 0.0136]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0470, 0.0392, 0.0321]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0241, 0.0140, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0152, 0.0143]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0268, 0.0179, 0.0172]),\n",
      "indices=tensor([1110, 1180, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0153, 0.0144]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0276, 0.0203, 0.0187]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0303, 0.0186, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0313, 0.0171, 0.0167]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0475, 0.0348, 0.0217]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0139, 0.0138]),\n",
      "indices=tensor([1327, 1425, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0165, 0.0162]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0395, 0.0215, 0.0213]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0137]),\n",
      "indices=tensor([1327, 1425, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0461, 0.0336, 0.0219]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0492, 0.0443, 0.0274]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0527, 0.0377, 0.0253]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0185, 0.0175, 0.0123]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0310, 0.0189, 0.0173]),\n",
      "indices=tensor([1425, 1420, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0142, 0.0138, 0.0127]),\n",
      "indices=tensor([1252, 1355, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0476, 0.0472, 0.0282]),\n",
      "indices=tensor([ 956, 1110,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0541, 0.0351, 0.0243]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0157, 0.0127, 0.0120]),\n",
      "indices=tensor([1400, 1319, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0263, 0.0203, 0.0169]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0212, 0.0184]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0209, 0.0195, 0.0190]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0250, 0.0162, 0.0158]),\n",
      "indices=tensor([1346, 1290, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0135, 0.0133, 0.0130]),\n",
      "indices=tensor([1355, 1265, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0393, 0.0208, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0339, 0.0198, 0.0178]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0652, 0.0512, 0.0423]),\n",
      "indices=tensor([ 956, 1086, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0148, 0.0130, 0.0119]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0418, 0.0300, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0265, 0.0203, 0.0172]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0208, 0.0158, 0.0153]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0402, 0.0227, 0.0219]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0183, 0.0180, 0.0153]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0206, 0.0196, 0.0192]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0420, 0.0264, 0.0236]),\n",
      "indices=tensor([1346, 1350, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0146, 0.0132, 0.0132]),\n",
      "indices=tensor([1265, 1355, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0363, 0.0188, 0.0175]),\n",
      "indices=tensor([1346, 1311, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0528, 0.0402, 0.0224]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0190, 0.0153, 0.0147]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0396, 0.0211, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0167, 0.0129]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0471, 0.0391, 0.0321]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0170, 0.0166, 0.0133]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0173, 0.0171]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0206, 0.0196, 0.0192]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0177, 0.0173]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0153, 0.0146]),\n",
      "indices=tensor([1425, 1435, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0134, 0.0122]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0148, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0468, 0.0342, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0187, 0.0178]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0263, 0.0203, 0.0169]),\n",
      "indices=tensor([1081, 1252, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0189, 0.0172, 0.0170]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0193, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0136, 0.0129, 0.0128]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1053, 0.0552, 0.0518]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0454, 0.0330, 0.0220]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0500, 0.0429, 0.0270]),\n",
      "indices=tensor([1110,  956,  984]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0298, 0.0169, 0.0166]),\n",
      "indices=tensor([1346, 1134, 1290]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0367, 0.0206, 0.0182]),\n",
      "indices=tensor([1425, 1420, 1370]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.0162, 0.0154, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0134, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0388, 0.0211, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0328, 0.0226, 0.0193]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0150, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0259, 0.0188, 0.0186]),\n",
      "indices=tensor([1081, 1031, 1078]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0128, 0.0124]),\n",
      "indices=tensor([1355, 1252, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0137, 0.0128, 0.0122]),\n",
      "indices=tensor([1355, 1244, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0137, 0.0120]),\n",
      "indices=tensor([1355, 1252, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0182, 0.0176]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0226, 0.0161, 0.0158]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0318, 0.0191, 0.0175]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0578, 0.0451, 0.0276]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0151, 0.0138, 0.0131]),\n",
      "indices=tensor([1265, 1232, 1244]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0224, 0.0161, 0.0157]),\n",
      "indices=tensor([1425, 1435, 1420]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0683, 0.0634, 0.0471]),\n",
      "indices=tensor([1086,  956, 1155]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.1921, 0.1013, 0.0659]),\n",
      "indices=tensor([287, 435, 272]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0371, 0.0261, 0.0215]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0582, 0.0276, 0.0264]),\n",
      "indices=tensor([1110, 1180,  956]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0205, 0.0193, 0.0184]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0388, 0.0211, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0124, 0.0124, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0122, 0.0120]),\n",
      "indices=tensor([1400, 1463, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0227, 0.0136, 0.0132]),\n",
      "indices=tensor([1425, 1370, 1463]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0238, 0.0197, 0.0148]),\n",
      "indices=tensor([1081, 1252, 1197]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0428, 0.0414, 0.0308]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0192, 0.0183, 0.0177]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0462, 0.0397, 0.0319]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0182, 0.0180, 0.0151]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0138, 0.0126, 0.0122]),\n",
      "indices=tensor([1355, 1244, 1252]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0193, 0.0184, 0.0177]),\n",
      "indices=tensor([1400, 1232, 1319]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0391, 0.0207, 0.0181]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0149, 0.0145, 0.0141]),\n",
      "indices=tensor([1425, 1327, 1435]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0330, 0.0227, 0.0194]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0468, 0.0342, 0.0218]),\n",
      "indices=tensor([1110, 1180,  927]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0249, 0.0162, 0.0157]),\n",
      "indices=tensor([1346, 1290, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0263, 0.0163, 0.0162]),\n",
      "indices=tensor([1346, 1290, 1134]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0250, 0.0186, 0.0166]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0200, 0.0196, 0.0187]),\n",
      "indices=tensor([1232, 1400, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0147, 0.0130, 0.0119]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0233, 0.0197, 0.0168]),\n",
      "indices=tensor([1081, 1110, 1031]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0126, 0.0120, 0.0119]),\n",
      "indices=tensor([1463, 1400, 1416]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0182, 0.0159, 0.0153]),\n",
      "indices=tensor([1400, 1319, 1232]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0195, 0.0193, 0.0182]),\n",
      "indices=tensor([1400, 1232, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0169, 0.0137]),\n",
      "indices=tensor([1265, 1232, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0213, 0.0158, 0.0154]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0609, 0.0402, 0.0288]),\n",
      "indices=tensor([1110, 1180, 1049]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0139, 0.0138, 0.0121]),\n",
      "indices=tensor([1355, 1252, 1081]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0145, 0.0138, 0.0136]),\n",
      "indices=tensor([1327, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0481, 0.0382, 0.0325]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0178, 0.0121]),\n",
      "indices=tensor([1081, 1252, 1355]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0172, 0.0146, 0.0136]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0387, 0.0210, 0.0183]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0191, 0.0155, 0.0151]),\n",
      "indices=tensor([1346, 1290, 1406]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0163, 0.0132, 0.0120]),\n",
      "indices=tensor([1425, 1463, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0487, 0.0374, 0.0328]),\n",
      "indices=tensor([1350, 1346, 1311]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0570, 0.0290, 0.0254]),\n",
      "indices=tensor([1110,  956, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0239, 0.0195, 0.0158]),\n",
      "indices=tensor([1110, 1081, 1180]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0176, 0.0149, 0.0145]),\n",
      "indices=tensor([1425, 1435, 1327]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0210, 0.0195, 0.0192]),\n",
      "indices=tensor([1232, 1265, 1400]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0387, 0.0205, 0.0180]),\n",
      "indices=tensor([1425, 1420, 1370]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0177, 0.0153, 0.0144]),\n",
      "indices=tensor([1400, 1319, 1265]))\n",
      "--------------------------------------------------\n",
      "tensor([0.9982])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "validate(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3866e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.handlers\n",
    "\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(logging.INFO)\n",
    "\n",
    "# Some libraries attempt to add their own root logger handlers. This is\n",
    "# annoying and so we get rid of them.\n",
    "for handler in list(root_logger.handlers):\n",
    "    root_logger.removeHandler(handler)\n",
    "\n",
    "logfmt_str = \"%(asctime)s %(levelname)-8s pid:%(process)d %(name)s:%(lineno)03d:%(funcName)s %(message)s\"\n",
    "formatter = logging.Formatter(logfmt_str)\n",
    "\n",
    "streamHandler = logging.StreamHandler()\n",
    "streamHandler.setFormatter(formatter)\n",
    "streamHandler.setLevel(logging.DEBUG)\n",
    "\n",
    "root_logger.addHandler(streamHandler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5a66406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b0dafd",
   "metadata": {},
   "source": [
    "差分行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac0c5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "class FXDiffBoaderDataset:\n",
    "    def __init__(self, isTraining = True, seed=0, mode=\"default\"):\n",
    "        random.seed(seed)\n",
    "        rates = pd.read_csv('/mnt/landisk/data/fx/NextBoaderPossibility/fx_USDJPY_5_2020-08-03T23-05-00_to_2021-12-04T07-50-00.csv', header=0, index_col=0, parse_dates=True)\n",
    "        diff_array = rates.iloc[1:].values - rates.iloc[0:-1].values\n",
    "        data = pd.DataFrame(diff_array, columns=['time', 'open', 'high', 'low', 'close', 'tick_volume', 'spread', 'real_volume'])#, 'EMA', 'BoaderValue'])\n",
    "        data.tick_volume = rates.tick_volume\n",
    "        data.spread = rates.spread\n",
    "        rollingWindow = 10\n",
    "        boaders, nan_index_head, nan_index_last = self.BoaderValueDiff(rates, rollingWindow, False)\n",
    "        data[\"BoaderValue\"] = boaders[1:]\n",
    "        print(f\"{nan_index_head} to {nan_index_last}\")\n",
    "        self.all_data = data[nan_index_head:nan_index_last]\n",
    "        length = len(self.all_data)\n",
    "        print(length)\n",
    "            \n",
    "        self.dataRange = datetime.timedelta(days=2)\n",
    "        self.dims = 5\n",
    "        self.mode = mode\n",
    "        INTERVAL_DAYS = 2\n",
    "        MINUTES_SPAN = 5\n",
    "\n",
    "        totalMinutes = INTERVAL_DAYS * 24 * 60\n",
    "        self.span  = int(totalMinutes/MINUTES_SPAN)+1\n",
    "        \n",
    "        ##select random indices.\n",
    "        self.indices = random.sample(range(0, length - self.span -1), k=length - self.span -1)\n",
    "        if isTraining:\n",
    "            self.fromIndex = 0\n",
    "            self.toIndex = int(length*0.7)\n",
    "        else:\n",
    "            self.fromIndex = int(length*0.7)+1\n",
    "            self.toIndex = length+1\n",
    "        \n",
    "        if self.mode == \"nrate\":\n",
    "            self.outputFunc = self.__getNormalizedAnsRates__\n",
    "        elif self.mode == \"default\":\n",
    "            self.outputFunc = self.__getAnsRates__\n",
    "        elif self.mode == \"array\":\n",
    "            self.outputFunc = self.__getAnsArray__\n",
    "            \n",
    "    def __getDiffArray__(self, data):\n",
    "        for i in range(1,len(data)):\n",
    "            data[i] - data[i-1]\n",
    "        \n",
    "    def __rateToArray__(self, value):\n",
    "        output = [0 for i in range(0,3000)]\n",
    "        i = round((value -0.85)*10000)\n",
    "        if i >= 3000:\n",
    "            i = 2999\n",
    "        elif i < 0:\n",
    "            i = 0\n",
    "        output[i] = 1\n",
    "        return output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.toIndex - self.fromIndex\n",
    "    \n",
    "    def __getAnsRates__(self,ndx):\n",
    "        ans = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                currentValue = self.all_data['close'].iloc[index]\n",
    "                ans.append(currentValue - self.all_data['BoaderValue'].iloc[index])\n",
    "        else:\n",
    "            index = ndx\n",
    "            currentValue = self.all_data['close'].iloc[index]\n",
    "            ans = [currentValue - self.all_data['BoaderValue'].iloc[index]]\n",
    "        return ans\n",
    "    \n",
    "    def __getNormalizedAnsRates__(self,ndx):\n",
    "        ans = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                maxValue = self.all_data['high'].iloc[index:index+self.span].values.max()\n",
    "                ans.append(self.all_data['BoaderValue'].iloc[index]/maxValue)\n",
    "        else:\n",
    "            index = ndx\n",
    "            maxValue = self.all_data['high'].iloc[index:index+self.span].values.max()\n",
    "            ans = [self.all_data['BoaderValue'].iloc[index]/maxValue]\n",
    "        return ans\n",
    "    \n",
    "    def __getAnsArray__(self, ndx):\n",
    "        ans = []\n",
    "        for value in self.__getNormalizedAnsRates__(ndx):\n",
    "            ans.append(\n",
    "                self.__rateToArray__(value)\n",
    "            )\n",
    "        return ans\n",
    "    \n",
    "    def __getInputs__(self, ndx):\n",
    "        inputs = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                print(index)\n",
    "                inputs.append([\n",
    "                    self.all_data.high[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.low[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.open[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.close[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.tick_volume[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.spread[index:index+self.span].values.tolist()\n",
    "                ])\n",
    "        else:\n",
    "            index = ndx\n",
    "            inputs = [\n",
    "                    self.all_data.high[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.low[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.open[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.close[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.tick_volume[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.spread[index:index+self.span].values.tolist()\n",
    "            ]\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "    def BoaderValueDiff(self, rates, frame, removeNan=True):\n",
    "        def updateNextBoaders(start, end, value, previouseValue):\n",
    "            if previouseValue != -1:\n",
    "                for i in range(start, end+1):\n",
    "                    nextBoaders.append(value - previouseValue)\n",
    "                \n",
    "                return 0\n",
    "            else:\n",
    "                for i in range(start, end+1):\n",
    "                    nextBoaders.append(numpy.NaN)\n",
    "                return end - start\n",
    "\n",
    "        data = rates.copy()\n",
    "        ma = data.close.rolling(frame).mean()\n",
    "        if ma[frame-1] == numpy.NaN:\n",
    "            print(\"invalid\")\n",
    "            return None\n",
    "        data[\"EMA\"] = ma\n",
    "        initial = frame\n",
    "        startIndex = initial\n",
    "        lastNanIndex = initial\n",
    "        nextBoaders = [numpy.NaN for i in range(0,initial)]\n",
    "        trend = 0\n",
    "        previouseValue = -1\n",
    "\n",
    "        for index in range(initial, len(data)):\n",
    "            diff = data.EMA[index-1] - data.EMA[index]\n",
    "            if diff >= 0:\n",
    "                if trend == -1:\n",
    "                    lastNanIndex += updateNextBoaders(startIndex, index, data.EMA[index], previouseValue)\n",
    "                    startIndex = index+1\n",
    "                    previouseValue = data.EMA[index]\n",
    "                trend = 1\n",
    "            else:\n",
    "                if trend == 1:\n",
    "                    lastNanIndex += updateNextBoaders(startIndex, index, data.EMA[index], previouseValue)\n",
    "                    startIndex = index+1\n",
    "                    previouseValue = data.EMA[index]\n",
    "                trend = -1\n",
    "                \n",
    "\n",
    "        updateNextBoaders(startIndex, len(data)-1, numpy.NaN, numpy.NaN)\n",
    "        result = len(data) == len(nextBoaders)\n",
    "        print(f\"Result:{result}\")\n",
    "        if result:\n",
    "            if removeNan:\n",
    "                return nextBoaders[lastNanIndex:startIndex]\n",
    "            else:\n",
    "                return nextBoaders, lastNanIndex, startIndex\n",
    "        else:\n",
    "            print(f\"{len(data)} !== {len(nextBoaders)}\")\n",
    "    \n",
    "    def __getitem__(self, ndx):\n",
    "        ins = numpy.array(self.__getInputs__(ndx), dtype=numpy.dtype('float32'))\n",
    "        outputs = numpy.array(self.outputFunc(ndx), dtype=numpy.dtype('float32'))\n",
    "        return torch.tensor(ins, device=device).to(dtype=dtype), torch.tensor(outputs, device=device).to(dtype=dtype)\n",
    "        return ins, outputs\n",
    "    \n",
    "    def changeMode(self, mode):\n",
    "        self.mode = mode\n",
    "        if self.mode == \"nrate\":\n",
    "            self.outputFunc = self.__getNormalizedAnsRates__\n",
    "        elif self.mode == \"default\":\n",
    "            self.outputFunc = self.__getAnsRates__\n",
    "        elif self.mode == \"array\":\n",
    "            self.outputFunc = self.__getAnsArray__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1258f3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:True\n",
      "35 to 99921\n",
      "99886\n"
     ]
    }
   ],
   "source": [
    "train_ds = FXDiffBoaderDataset(True, 1017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "302ad248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63087\n",
      "83256\n",
      "55961\n",
      "25005\n",
      "12332\n",
      "46291\n",
      "40948\n",
      "13345\n",
      "38308\n",
      "35650\n"
     ]
    }
   ],
   "source": [
    "i,o = train_ds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7cd7d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(6,12, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(12,8, kernel_size=5, padding=2)\n",
    "        self.fc6 = nn.Linear(8*size, 4*size)\n",
    "        self.fc7 = nn.Linear(4*size, size)\n",
    "        self.fc8 = nn.Linear(size, 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        out = torch.tanh(self.conv1(x))\n",
    "        out = torch.tanh(self.conv2(out))\n",
    "        out = out.view(-1, 8*size)\n",
    "        out = F.relu(self.fc6(out))\n",
    "        out = F.relu(self.fc7(out))\n",
    "        out = torch.tanh(self.fc8(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c21a1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size,  drop_last = True, shuffle=True)\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7948126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d38ba793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63087\n",
      "83256\n",
      "55961\n",
      "25005\n",
      "12332\n",
      "46291\n",
      "40948\n",
      "13345\n",
      "38308\n",
      "35650\n",
      "tensor([ 0.0135,  0.0132,  0.1255,  0.0974,  0.0271,  0.0464, -0.0960, -0.0265,\n",
      "        -0.0011,  0.1006], device='cuda:0')\n",
      "tensor([[ 0.0135],\n",
      "        [-0.0505],\n",
      "        [ 0.1255],\n",
      "        [ 0.0974],\n",
      "        [ 0.0271],\n",
      "        [ 0.0464],\n",
      "        [-0.0960],\n",
      "        [-0.0265],\n",
      "        [-0.0011],\n",
      "        [ 0.1006]], device='cuda:0', grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputData, outputData = train_ds[0:10]\n",
    "out = model(inputData)\n",
    "print(outputData)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ebb6eff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('fx_boarderDiff_5_2days_adam_v1', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ee280572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loop(n_epochs =300, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4a823475",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fx_boarderDiff_5_2days_adam_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "19c79b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63087\n"
     ]
    }
   ],
   "source": [
    "dummy_input, dummy_output = train_ds[0:1]\n",
    "torch.onnx.export(model, dummy_input, 'fx_boarderDiff_5_2days_adam_v2.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07c7b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4011a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "class FXNextNDataset:\n",
    "    def __init__(self,n,isTraining = True, seed=0, datatype=\"diff\",mode=\"default\"):\n",
    "        random.seed(seed)\n",
    "        rates = pd.read_csv('/mnt/landisk/data/fx/NextBoaderPossibility/fx_USDJPY_5_2020-08-03T23-05-00_to_2021-12-04T07-50-00.csv', header=0, index_col=0, parse_dates=True)\n",
    "        \n",
    "        self.next = n\n",
    "        if datatype == \"diff\":\n",
    "            diff_array = rates.iloc[1:].values - rates.iloc[0:-1].values\n",
    "            data = pd.DataFrame(diff_array, columns=['time', 'open', 'high', 'low', 'close', 'tick_volume', 'spread', 'real_volume'])#, 'EMA', 'BoaderValue'])\n",
    "            data.tick_volume = rates.tick_volume\n",
    "            data.spread = rates.spread\n",
    "            self.all_data = data\n",
    "        else:\n",
    "            self.all_data = rates.sort_index()\n",
    "            \n",
    "        length = len(self.all_data)\n",
    "        \n",
    "        ##select random indices.\n",
    "        self.indices = random.sample(range(n, length-1), k=length-1-n)\n",
    "        if isTraining:\n",
    "            self.fromIndex = n\n",
    "            self.toIndex = int(length*0.7)\n",
    "        else:\n",
    "            self.fromIndex = int(length*0.7)+1\n",
    "            self.toIndex = length+1\n",
    "            \n",
    "        self.dataRange = datetime.timedelta(days=2)\n",
    "        self.dims = 5\n",
    "        self.mode = mode\n",
    "        INTERVAL_DAYS = 2\n",
    "        MINUTES_SPAN = 5\n",
    "\n",
    "        totalMinutes = INTERVAL_DAYS * 24 * 60\n",
    "        self.span  = int(totalMinutes/MINUTES_SPAN)+1\n",
    "        self.outputFunc = self.__getAnsBinary__\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.toIndex - self.fromIndex\n",
    "        \n",
    "    def __getAnsBinary__(self,ndx):\n",
    "        if type(ndx) == slice:\n",
    "            ans = []\n",
    "            for index in self.indices[ndx]:\n",
    "                ans_temp = self.all_data.close.iloc[index+self.next] - self.all_data.close.iloc[index]\n",
    "                ans_i = numpy.zeros_like(ans_temp)\n",
    "                ans_i[ans_temp > 0] = 1\n",
    "                ans.append(ans_i)\n",
    "        else:\n",
    "            index = ndx\n",
    "            ans = [0]\n",
    "            if self.all_data.close.iloc[index+self.next] - self.all_data.close.iloc[index] > 0:\n",
    "                ans = [1]\n",
    "        return ans\n",
    "    \n",
    "    def __getAnsArray__(self, ndx):\n",
    "        ans = []\n",
    "        for value in self.__getNormalizedAnsRates__(ndx):\n",
    "            ans.append(\n",
    "                self.__rateToArray__(value)\n",
    "            )\n",
    "        return ans\n",
    "    \n",
    "    def __getInputs__(self, ndx):\n",
    "        inputs = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self.indices[ndx]:\n",
    "                print(index)\n",
    "                inputs.append([\n",
    "                    self.all_data.high[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.low[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.open[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.close[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.tick_volume[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.spread[index:index+self.span].values.tolist()\n",
    "                ])\n",
    "        else:\n",
    "            index = ndx\n",
    "            inputs = [\n",
    "                    self.all_data.high[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.low[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.open[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.close[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.tick_volume[index:index+self.span].values.tolist(),\n",
    "                    self.all_data.spread[index:index+self.span].values.tolist()\n",
    "            ]\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "    def __getitem__(self, ndx):\n",
    "        inputs = numpy.array(self.__getInputs__(ndx),  dtype=numpy.dtype('float32'))\n",
    "        outputs = numpy.array(self.outputFunc(ndx), dtype=numpy.dtype('float32'))\n",
    "        return torch.tensor(inputs, device=device).to(dtype=dtype), torch.tensor(outputs, device=device).to(dtype=dtype)\n",
    "        return inputs, outputs\n",
    "        #return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "548bf534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(6,12, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(12,8, kernel_size=5, padding=2)\n",
    "        self.fc6 = nn.Linear(8*size, 4*size)\n",
    "        self.fc7 = nn.Linear(4*size, size)\n",
    "        self.fc8 = nn.Linear(size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.tanh(self.conv1(x))\n",
    "        out = torch.tanh(self.conv2(out))\n",
    "        out = out.view(-1, 8*size)\n",
    "        out = F.relu(self.fc6(out))\n",
    "        out = F.relu(self.fc7(out))\n",
    "        out = torch.sigmoid(self.fc8(out))\n",
    "        #out = out.view(-1, 8*size)\n",
    "        #out = F.relu(self.fc2(out))\n",
    "        #out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0364403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=32\n",
    "train_ds = FXNextNDataset(1)\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size,  drop_last = True, shuffle=True)\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c01925f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e4f4bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66151\n",
      "18255\n",
      "36942\n",
      "tensor([[0.4975],\n",
      "        [0.5023],\n",
      "        [0.5056]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([1., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputData, outputData = train_ds[13:16]\n",
    "out = model(inputData)\n",
    "print(out)\n",
    "print(outputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb6e4bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loop(n_epochs =100, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c32217e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-910ead4f7c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-b89db91ce93d>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_loader, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss_train\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mansValue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#print(f'output {outputs.shape}, ansValue {ansValue.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-fc65c0b27dae>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, ndx)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getInputs__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m#return inputs, outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs =300, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a83fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fx_next1UD_5_2days_adam_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4897799",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('fx_next1UD_5_2days_adam_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8394e20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50495\n"
     ]
    }
   ],
   "source": [
    "dummy_input, dummy_output = train_ds[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "45552ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c366b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, dummy_input, 'fx_next1UD_5_2days_adam_temp.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a73b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
